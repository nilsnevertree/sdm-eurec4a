{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to share our initial data with Mampi\n",
    "\n",
    "To share the initial data with Mampi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import textwrap\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sdm_eurec4a import RepositoryPath\n",
    "\n",
    "from sdm_eurec4a.visulization import label_from_attrs, save_figure, set_custom_rcParams, plot_one_one\n",
    "\n",
    "from sdm_eurec4a.reductions import mean_and_stderror_of_mean\n",
    "\n",
    "set_custom_rcParams()\n",
    "\n",
    "RepoPaths = RepositoryPath(\"levante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Share data with mampi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_data_dir = RepoPaths.data_dir\n",
    "input_data_dir = OBS_data_dir / Path(\"model/input_v4.1\")\n",
    "CLEO_data_dir = RepoPaths.CLEO_data_dir / Path(\"output_v4.1\")\n",
    "\n",
    "sharing_dir = RepoPaths.data_dir / Path(\"sharing/\")\n",
    "sharing_dir.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "fig_dir = sharing_dir / Path(\"figures\")\n",
    "fig_dir.mkdir(exist_ok=True, parents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_clusters = xr.open_dataset(\n",
    "    OBS_data_dir\n",
    "    / Path(\n",
    "        \"observation/cloud_composite/processed/identified_clusters/identified_clusters_rain_mask_5.nc\"\n",
    "    )\n",
    ")\n",
    "identified_clusters = identified_clusters.swap_dims({\"time\": \"cloud_id\"})\n",
    "\n",
    "ds_cleo = xr.open_dataset(\n",
    "    CLEO_data_dir / Path(\"null_microphysics/combined/eulerian_dataset_combined.nc\")\n",
    ")\n",
    "ds_cleo_condensation = xr.open_dataset(\n",
    "    CLEO_data_dir / Path(\"condensation/combined/eulerian_dataset_combined.nc\")\n",
    ")\n",
    "ds_box_model = xr.open_dataset(\n",
    "    CLEO_data_dir / Path(\"condensation/combined/conservation_dataset_combined.nc\")\n",
    ")\n",
    "\n",
    "cloud_ids = np.intersect1d(identified_clusters.cloud_id, ds_cleo.cloud_id)\n",
    "\n",
    "ds_cleo = ds_cleo.sel(cloud_id=cloud_ids)\n",
    "identified_clusters = identified_clusters.sel(cloud_id=cloud_ids)\n",
    "ds_cleo_condensation = ds_cleo_condensation.sel(cloud_id=cloud_ids)\n",
    "\n",
    "ds_cloud = ds_cleo.sel(gridbox=ds_cleo[\"max_gridbox\"])\n",
    "\n",
    "cloud_composite = xr.open_dataset(\n",
    "    OBS_data_dir / Path(\"observation/cloud_composite/processed/cloud_composite_SI_units_20241025.nc\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store information in README.md\n",
    "def ds_to_readme(ds: xr.Dataset, filepath: Path) -> None:\n",
    "    \"\"\"\n",
    "    This function writes the attributes of a xarray.Dataset to a README.md file.\n",
    "    Here an example of the output:\n",
    "    - var1\n",
    "        - attr1: value1\n",
    "        - attr2: value2\n",
    "    - var2\n",
    "        - attr1: value1\n",
    "        - attr2: value2\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "\n",
    "        f.write(f\"### Description of the dataset:\\n\")\n",
    "        for k, v in ds.attrs.items():\n",
    "            f.write(f\"- {(k + ':').ljust(15)} {v.replace('\\n', ' ')}\\n\")\n",
    "\n",
    "        f.write(f\"\\n===============================\\n\\n\")\n",
    "        f.write(f\"### More information about the variables in the dataset:\\n\")\n",
    "        for key in ds.variables:\n",
    "            f.write(f\"- {key}\\n\")\n",
    "            for k, v in ds[key].attrs.items():\n",
    "                f.write(f\"  - {(k + ':').ljust(15)} {v.replace('\\n', ' ')}\\n\")\n",
    "\n",
    "        f.write(f\"\\n===============================\\n\\n\")\n",
    "        f.write(f\"### Xarray NETCDF dataset information:\\n\")\n",
    "\n",
    "        f.write(\"````python\\n\" + str(ds) + \"\\n````\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate observations rwc and sem\n",
    "\n",
    "cloud_composite[\"mass_size_distribution_non_normalized\"] = (\n",
    "    1e3 * cloud_composite[\"mass_size_distribution\"] * cloud_composite[\"bin_width\"]\n",
    ")\n",
    "cloud_composite[\"mass_size_distribution_non_normalized\"].attrs.update(\n",
    "    long_name=\"mass size distribution non normalized\", units=\"g m^{-3}\"\n",
    ")\n",
    "\n",
    "\n",
    "list_liquid_water_content_mean = list()\n",
    "list_liquid_water_content_sem = list()\n",
    "list_rwc_50µm_mean = list()\n",
    "list_rwc_50µm_sem = list()\n",
    "\n",
    "for cloud_id in identified_clusters[\"cloud_id\"]:\n",
    "    start = identified_clusters[\"start\"].sel(cloud_id=cloud_id).values\n",
    "    stop = identified_clusters[\"end\"].sel(cloud_id=cloud_id).values\n",
    "\n",
    "    _ds = cloud_composite.sel(time=slice(start, stop))\n",
    "    _ds_50µm = _ds.sel(radius=slice(50e-6, None))\n",
    "\n",
    "    rwc = _ds[\"mass_size_distribution_non_normalized\"].sum(\"radius\", keep_attrs=True)\n",
    "    rwc.attrs.update(\n",
    "        long_name=\"Liquid Water Content\\n(All water droplets)\",\n",
    "    )\n",
    "    attrs = rwc.attrs.copy()\n",
    "\n",
    "    lwc_mean, lwc_sem = mean_and_stderror_of_mean(rwc, dims=\"time\")\n",
    "    lwc_mean = lwc_mean.expand_dims(cloud_id=[cloud_id])\n",
    "    lwc_mean.attrs.update(**attrs)\n",
    "    lwc_mean.attrs.update(\n",
    "        description=textwrap.dedent(\n",
    "            \"\"\"\n",
    "            The liquid water content (LWC) is calculated by summing the mass of all water droplets in the cloud.\n",
    "            The values are the temporal means of all measurements within an individual cloud.\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    lwc_sem = lwc_sem.expand_dims(cloud_id=[cloud_id])\n",
    "    lwc_sem.attrs.update(**attrs)\n",
    "    lwc_sem.attrs.update(\n",
    "        description=textwrap.dedent(\n",
    "            \"\"\"\n",
    "            This standard error of the mean correponds to the temporal mean of all individual measurements within an individual cloud.\n",
    "            Which is given as variable `liquid_water_content_mean`.\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    list_liquid_water_content_mean.append(lwc_mean)\n",
    "    list_liquid_water_content_sem.append(lwc_sem)\n",
    "\n",
    "    rwc_50µm = _ds_50µm[\"mass_size_distribution_non_normalized\"].sum(\"radius\", keep_attrs=True)\n",
    "    rwc_50µm.attrs.update(\n",
    "        long_name=\"Rain Water Content\\n(Drops radii > 50µm)\",\n",
    "    )\n",
    "    attrs = rwc_50µm.attrs.copy()\n",
    "\n",
    "    rwc_50µm_mean, rwc_50µm_sem = mean_and_stderror_of_mean(rwc_50µm, dims=\"time\")\n",
    "    rwc_50µm_mean = rwc_50µm_mean.expand_dims(cloud_id=[cloud_id])\n",
    "    rwc_50µm_mean.attrs.update(**attrs)\n",
    "    rwc_50µm_mean.attrs.update(\n",
    "        description=textwrap.dedent(\n",
    "            \"\"\"\n",
    "            The rain water content (RWC) is calculated by summing the mass of all rain droplets in the cloud.\n",
    "            Rain drops have radius above 50µm.\n",
    "            The values are the temporal means of all measurements within an individual cloud.\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "    rwc_50µm_sem = rwc_50µm_sem.expand_dims(cloud_id=[cloud_id])\n",
    "    rwc_50µm_sem.attrs.update(**attrs)\n",
    "    rwc_50µm_sem.attrs.update(\n",
    "        description=textwrap.dedent(\n",
    "            \"\"\"\n",
    "            This standard error of the mean correponds to the temporal mean of all individual measurements within an individual cloud.\n",
    "            Which is given as variable `rain_water_content_mean`.\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    list_rwc_50µm_mean.append(rwc_50µm_mean)\n",
    "    list_rwc_50µm_sem.append(rwc_50µm_sem)\n",
    "\n",
    "ds_observations = xr.Dataset()\n",
    "ds_observations[\"liquid_water_content_mean\"] = xr.concat(list_liquid_water_content_mean, dim=\"cloud_id\")\n",
    "ds_observations[\"liquid_water_content_sem\"] = xr.concat(list_liquid_water_content_sem, dim=\"cloud_id\")\n",
    "ds_observations[\"rain_water_content_mean\"] = xr.concat(list_rwc_50µm_mean, dim=\"cloud_id\")\n",
    "ds_observations[\"rain_water_content_sem\"] = xr.concat(list_rwc_50µm_sem, dim=\"cloud_id\")\n",
    "ds_observations.attrs.update(\n",
    "    creator=\"Nils Niebaum\",\n",
    "    description=textwrap.dedent(\n",
    "        \"\"\"\n",
    "        This dataset provides the in situ RWC for all clouds used for the CLEO analysis.\n",
    "        The liquid water content (LWC) and the rain water content (RWC) for an individual cloud is calculated as the mean over all measurements within the cloud.\n",
    "        For the LWC all droplets are considered.\n",
    "        For the RWC only droplets with a radius above 50µm are considered.\n",
    "    \"\"\"\n",
    "    ),\n",
    ")\n",
    "ds_observations.to_netcdf(sharing_dir / \"datasets\" / \"observations-clouds-lwc-rwc.nc\")\n",
    "ds_observations.to_dataframe().to_csv(sharing_dir / \"datasets\" / \"observations-clouds-lwc-rwc.csv\")\n",
    "ds_to_readme(ds_observations, sharing_dir / \"datasets\" / \"observations-clouds-lwc-rwc_README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Rain Water Content\\n(Drops radii > 50µm) $\\\\left[  g m^{-3}  \\\\right]$')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.errorbar(\n",
    "    x=ds_observations[\"liquid_water_content_mean\"],\n",
    "    xerr=ds_observations[\"liquid_water_content_sem\"],\n",
    "    y=ds_observations[\"rain_water_content_mean\"],\n",
    "    yerr=ds_observations[\"rain_water_content_sem\"],\n",
    "    fmt=\".\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plot_one_one(plt.gca(), N=100, color=\"k\")\n",
    "plt.xlim(1e-3, 1e1)\n",
    "plt.ylim(1e-3, 1e1)\n",
    "plt.xlabel(label_from_attrs(ds_observations[\"liquid_water_content_mean\"]))\n",
    "plt.ylabel(label_from_attrs(ds_observations[\"rain_water_content_mean\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = sharing_dir / \"datasets/identified-clusters-simulated\"\n",
    "identified_clusters.to_netcdf(filepath.with_suffix(\".nc\"))\n",
    "identified_clusters.to_dataframe().to_csv(filepath.with_suffix(\".csv\"), sep=\";\")\n",
    "ds_to_readme(identified_clusters, filepath.with_suffix(\".md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all parameter files as csv too and a README too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = sharing_dir / \"distribution-and-thermodynamic-fits\"\n",
    "parent_dir.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "for filepath in list((RepoPaths.data_dir / Path(\"model/input_v4.1/\")).glob(\"*.nc\")):\n",
    "    new_filepath = parent_dir / filepath.name\n",
    "\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    df = ds.to_dataframe()\n",
    "    try:\n",
    "        ds.to_netcdf(new_filepath)\n",
    "    except PermissionError:\n",
    "        print(f\"PermissionError: {new_filepath}\")\n",
    "        continue\n",
    "    ds.close()\n",
    "\n",
    "    df.to_csv(new_filepath.with_suffix(\".csv\"), sep=\";\")\n",
    "\n",
    "    ds_to_readme(ds, new_filepath.with_suffix(\".md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd = xr.open_dataset(parent_dir / \"particle_size_distribution_parameters_linear_space.nc\")\n",
    "ds_psd = ds_psd.sel(cloud_id=cloud_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file which contains the dsd, the relative humiditz\n",
    "\n",
    "from pySD.initsuperdropsbinary_src.probdists import DoubleLogNormal\n",
    "from pySD.initsuperdropsbinary_src.attrsgen import AttrsGeneratorBinWidth\n",
    "from pySD.initsuperdropsbinary_src.rgens import SampleLog10RadiiWithBinWidth\n",
    "from pySD.initsuperdropsbinary_src.rgens import MonoAttrGen\n",
    "\n",
    "keys = DoubleLogNormal.__init__.__annotations__\n",
    "mapping = dict([(k, ds_psd[k]) for k in keys])\n",
    "xiprobdist = DoubleLogNormal(**mapping)\n",
    "\n",
    "\n",
    "# attrsgen = AttrsGeneratorBinWidth(\n",
    "#     radiigen=SampleLog10RadiiWithBinWidth(rspan=(0.5, 3.5), n=100),\n",
    "#     dryradiigen=MonoAttrGen(1e-9),\n",
    "#     xiprobdist=DoubleLogNormal("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_niebaum = xr.Dataset()\n",
    "\n",
    "ds_niebaum[\"radius\"] = ds_cleo[\"radius_bins\"] * 1e-3  # mm\n",
    "ds_niebaum[\"radius\"].attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"radius\",\n",
    "        \"units\": \"mm\",\n",
    "    }\n",
    ")\n",
    "ds_niebaum[\"radius_SI\"] = ds_niebaum[\"radius\"] * 1e-3  # m\n",
    "ds_niebaum[\"radius_SI\"].attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"radius in SI\",\n",
    "        \"units\": \"m\",\n",
    "    }\n",
    ")\n",
    "\n",
    "ds_niebaum[\"radius_bin_width\"] = 0.5 * (\n",
    "    ds_niebaum[\"radius\"].shift(radius_bins=-1) - ds_niebaum[\"radius\"].shift(radius_bins=1)\n",
    ")\n",
    "ds_niebaum[\"radius_bin_width\"].attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"width of each radius bin\",\n",
    "        \"units\": \"mm\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# print(ds_niebaum.cloud_id.size)\n",
    "# create the theoretical psd fromt he xiprobdist\n",
    "ds_niebaum[\"psd\"] = xiprobdist(ds_niebaum[\"radius_SI\"]).T\n",
    "# now psd is given in m^-3 m^-1\n",
    "# to get it in m^-3 mm^-1 we need to multiply by 1e-3\n",
    "ds_niebaum[\"psd\"] = ds_niebaum[\"psd\"] * 1e-3\n",
    "ds_niebaum[\"psd\"].attrs.update(\n",
    "    long_name=\"N\",\n",
    "    units=\"m^{-3} mm^{-1}\",\n",
    "    description=textwrap.dedent(\n",
    "        \"\"\"\n",
    "            Theoretical particle size distribution (PSD) calculated from the DoubleLogNormal distribution.\n",
    "            This is the fitted distribution to the observational data.\n",
    "            \"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "ds_niebaum[\"psd_cleo\"] = ds_cloud[\"xi_temporal_mean\"] / ds_cloud[\"gridbox_volume\"]\n",
    "ds_niebaum[\"psd_cleo\"].attrs.update(\n",
    "    long_name=\"N in CLEO\",\n",
    "    units=\"m^{-3}\",\n",
    "    description=textwrap.dedent(\n",
    "        \"\"\"\n",
    "        The particle size distribution (PSD) which is used in the CLEO model.\n",
    "        Please note, that this is not a normalized distribution.\n",
    "        It counts the multiplicities of all superdroplets within a radius bin.\n",
    "        To normalize the distribution, please use the `bin_width` variable.\n",
    "        \"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "ds_niebaum[\"air_temperature\"] = ds_cleo[\"air_temperature\"]\n",
    "ds_niebaum[\"relative_humidity\"] = ds_cleo[\"relative_humidity\"]\n",
    "\n",
    "ds_niebaum[\"altitude\"] = ds_cleo[\"gridbox_coord3\"]\n",
    "\n",
    "ds_niebaum = ds_niebaum.transpose(\"radius_bins\", \"gridbox\", \"cloud_id\", ...)\n",
    "\n",
    "\n",
    "lwc_cleo = (1e3 * ds_cloud[\"mass_represented_temporal_mean\"] / ds_cloud[\"gridbox_volume\"]).sum(\n",
    "    \"radius_bins\"\n",
    ")\n",
    "lwc_cleo.attrs.update(\n",
    "    long_name=\"Rain water content in CLEO\",\n",
    "    units=\"g m^{-3}\",\n",
    "    description=\"Rain water content, which CLEO simulates for the cloud layer. It is the sum of mass represented by all superdroplets in the cloud.\",\n",
    ")\n",
    "ds_niebaum[\"rain_water_content_cleo\"] = lwc_cleo\n",
    "\n",
    "\n",
    "time_slice = slice(1500, 3490)\n",
    "# add the evaporation fraction\n",
    "ds_niebaum[\"evaporation_fraction\"] = -ds_box_model[\"source\"].sel(time=time_slice).mean(\n",
    "    \"time\", keep_attrs=True\n",
    ") / ds_box_model[\"inflow\"].sel(time=time_slice).mean(\"time\", keep_attrs=True)\n",
    "# ds_niebaum['evaporation_fraction_median'] = - ds_box_model['source'].sel(time = time_slice).median('time', keep_attrs = True) / ds_box_model['inflow'].sel(time = time_slice).median('time', keep_attrs = True)\n",
    "ds_niebaum[\"evaporation_fraction\"].attrs.update(\n",
    "    long_name=\"Evaporation fraction\",\n",
    "    units=\"1\",\n",
    "    description=textwrap.dedent(\n",
    "        \"\"\"\n",
    "        The evaporation fraction is calculated as the ratio of the evaporated mass (E) within the whole domain to the inflow into the domain from the cloud (I).\n",
    "        Both E and I are averaged over the stationary state the their ratio is calculated.\n",
    "        \"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "ds_niebaum.attrs.update(\n",
    "    creator=\"Nils Niebaum\",\n",
    "    description=textwrap.dedent(\n",
    "        \"\"\"\n",
    "        This dataset provides the theoretical particle size distribution (PSD) for the CLEO analysis.\n",
    "        The PSD is calculated from the DoubleLogNormal distribution which is fitted to the observational data.\n",
    "        The dataset also contains the air temperature, the relative humidity, the altitude and the rain water content (RWC) for each gridbox and each cloud.\n",
    "        \n",
    "        Most of the variables are given for the setup with only evaporation enabled. No collisional effects are considered.\n",
    "        \"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# ds_niebaum.to_netcdf(sharing_dir / \"niebaum-CLEO.nc\")\n",
    "# ds_to_readme(ds_niebaum, sharing_dir / \"niebaum-CLEO.md\")\n",
    "\n",
    "ds_niebaum_cloud = ds_niebaum[\n",
    "    [\"radius\", \"psd\", \"psd_cleo\", \"rain_water_content_cleo\", \"evaporation_fraction\"]\n",
    "]\n",
    "ds_niebaum_cloud.to_netcdf(sharing_dir / \"datasets\" / \"niebaum-simulations.nc\")\n",
    "ds_niebaum_cloud.to_dataframe().to_csv(sharing_dir / \"datasets\" / \"niebaum-simulations.csv\")\n",
    "ds_to_readme(ds_niebaum_cloud, sharing_dir / \"datasets\" / \"niebaum-simulations.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds_niebaum[\"psd\"], ds_niebaum[\"psd_cleo\"] / ds_niebaum[\"radius_bin_width\"], marker=\"x\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.xlim(1e-3, None)\n",
    "# plt.ylim(1e-3, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m/m301096/repositories/sdm-eurec4a/src/sdm_eurec4a/visulization.py:1051: UserWarning: Got formats in tuple or list format. Converting to dict.\n",
      "  warnings.warn(\"Got formats in tuple or list format. Converting to dict.\")\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(\n",
    "    ds_niebaum[\"radius\"],\n",
    "    ds_niebaum[\"psd\"],\n",
    ")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(ds_niebaum[\"radius\"]))\n",
    "ax.set_ylabel(label_from_attrs(ds_niebaum[\"psd\"]))\n",
    "\n",
    "ax.set_ylim(1e-4, 1e8)\n",
    "\n",
    "fig.tight_layout()\n",
    "save_figure(\n",
    "    fig,\n",
    "    fig_dir / \"niebaum_raindrop_size_distribution\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "ax.set_xlim(1e-1, 3e0)\n",
    "ax.set_yticks([1e0, 1e5])\n",
    "ax.set_ylim(1e-4, 1e6)\n",
    "fig.tight_layout()\n",
    "save_figure(\n",
    "    fig,\n",
    "    fig_dir / \"niebaum_raindrop_size_distribution-zoom\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(\n",
    "    ds_niebaum[\"radius\"],\n",
    "    ds_niebaum[\"psd_cleo\"] / ds_niebaum[\"radius_bin_width\"],\n",
    ")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(ds_niebaum[\"radius\"]))\n",
    "ax.set_ylabel(label_from_attrs(ds_niebaum[\"psd\"]))\n",
    "\n",
    "ax.set_ylim(1e-4, 1e8)\n",
    "\n",
    "fig.tight_layout()\n",
    "save_figure(\n",
    "    fig,\n",
    "    fig_dir / \"niebaum_raindrop_size_distribution-cleo\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "ax.set_xlim(1e-1, 3e0)\n",
    "ax.set_yticks([1e0, 1e5])\n",
    "ax.set_ylim(1e-4, 1e6)\n",
    "fig.tight_layout()\n",
    "save_figure(\n",
    "    fig,\n",
    "    fig_dir / \"niebaum_raindrop_size_distribution-cleo-zoom\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = ds_niebaum[\"relative_humidity\"]\n",
    "y = ds_niebaum[\"altitude\"]\n",
    "ax.plot(\n",
    "    x,\n",
    "    y,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(x))\n",
    "ax.set_ylabel(label_from_attrs(y))\n",
    "\n",
    "fig.tight_layout()\n",
    "save_figure(\n",
    "    fig,\n",
    "    fig_dir / \"niebaum_relative_humidity\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = ds_niebaum[\"air_temperature\"]\n",
    "y = ds_niebaum[\"altitude\"]\n",
    "ax.plot(\n",
    "    x,\n",
    "    y,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(x))\n",
    "ax.set_ylabel(label_from_attrs(y))\n",
    "\n",
    "fig.tight_layout()\n",
    "save_figure(\n",
    "    fig,\n",
    "    fig_dir / \"niebaum_air_temperature\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.errorbar(\n",
    "    y=ds_observations[\"liquid_water_content_mean\"],\n",
    "    yerr=ds_observations[\"liquid_water_content_sem\"],\n",
    "    x=ds_niebaum[\"rain_water_content_cleo\"],\n",
    "    xerr=0,\n",
    "    fmt=\".\",\n",
    "    alpha=0.7,\n",
    "    label=label_from_attrs(ds_observations[\"liquid_water_content_mean\"], return_units=False),\n",
    ")\n",
    "\n",
    "plt.errorbar(\n",
    "    y=ds_observations[\"rain_water_content_mean\"],\n",
    "    yerr=ds_observations[\"rain_water_content_sem\"],\n",
    "    x=ds_niebaum[\"rain_water_content_cleo\"],\n",
    "    xerr=0,\n",
    "    fmt=\".\",\n",
    "    alpha=0.7,\n",
    "    label=label_from_attrs(ds_observations[\"rain_water_content_mean\"], return_units=False),\n",
    ")\n",
    "\n",
    "plt.xlabel(\"RWC (in CLEO) \" + label_from_attrs(ds_niebaum[\"rain_water_content_cleo\"], return_name=False))\n",
    "plt.ylabel(\n",
    "    \"RWC (in-situ) \" + label_from_attrs(ds_observations[\"liquid_water_content_mean\"], return_name=False)\n",
    ")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlim(4e-4, 1e2)\n",
    "plt.xticks([1e-2, 1e0])\n",
    "plt.ylim(2e-5, 7e1)\n",
    "plt.yticks([1e-4, 1e-2, 1e0])\n",
    "\n",
    "plot_one_one(plt.gca(), N=100, color=\"k\", linewidth=0.5)\n",
    "\n",
    "title = \"RWC comparsion between CLEO and in-situ values.\\n\" + textwrap.fill(\n",
    "    \"For in-situ: dots are the temporal mean for each individual cloud and errorbars are SEM\", 60\n",
    ")\n",
    "\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_figure(\n",
    "    plt.gcf(),\n",
    "    fig_dir / \"RWC_comparison\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2378708/2405918811.py:11: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    }
   ],
   "source": [
    "for var in [\n",
    "    \"evaporation_fraction\",\n",
    "]:\n",
    "    plt.hist(\n",
    "        ds_niebaum[var],\n",
    "        bins=np.arange(0, 1.1, 0.1),\n",
    "        edgecolor=\"k\",\n",
    "        alpha=0.5,\n",
    "        # label = var\n",
    "    )\n",
    "plt.legend()\n",
    "plt.xlabel(\"REF (fraction)\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.title(\"Evaporation fraction\")\n",
    "plt.tight_layout()\n",
    "save_figure(\n",
    "    plt.gcf(),\n",
    "    fig_dir / \"evaporation_fraction\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_ids = ds[\"cloud_id\"].sortby(ds_niebaum[\"evaporation_fraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ds = ds_niebaum\n",
    "\n",
    "y = ds[\"psd\"]\n",
    "x = ds[\"radius\"].expand_dims(cloud_id=ds[\"cloud_id\"])\n",
    "c = ds[\"evaporation_fraction\"].expand_dims(radius_bins=ds[\"radius_bins\"])\n",
    "\n",
    "x = x.transpose(\"cloud_id\", \"radius_bins\")\n",
    "y = y.transpose(\"cloud_id\", \"radius_bins\")\n",
    "c = c.transpose(\"cloud_id\", \"radius_bins\")\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap(\"plasma_r\")\n",
    "\n",
    "for cloud_id in ds[\"cloud_id\"]:\n",
    "    plt.plot(\n",
    "        x.sel(cloud_id=cloud_id),\n",
    "        y.sel(cloud_id=cloud_id),\n",
    "        c=cmap(ds[\"evaporation_fraction\"].sel(cloud_id=cloud_id)),\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "plt.scatter(x, y, c=c, cmap=cmap, s=0)\n",
    "\n",
    "plt.colorbar(label=label_from_attrs(ds[\"evaporation_fraction\"]))\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.xlabel(label_from_attrs(x))\n",
    "plt.ylabel(label_from_attrs(y))\n",
    "\n",
    "fig.tight_layout()\n",
    "save_figure(\n",
    "    fig,\n",
    "    fig_dir / \"niebaum_psd_evaporation_fraction\",\n",
    "    formats=[\n",
    "        \".png\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look into Sarkar distirbutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Dcb', 'Ncb', 'RH', 'R_radarret', 'cbh', 'sigcb', 'time', 'z_norm'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = sp.io.loadmat(sharing_dir / \"Sarkar2023-Rain_retrievals_9to13Feb2020.mat\")\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 540.,  560.,  575.,  620.,  650.,  665.,  680.,  740.,  755.,\n",
       "        800.,  815.,  845.,  860.,  890.,  905.,  920.,  935.,  950.,\n",
       "        965., 1010., 1025., 1070., 1085., 1130.,   nan])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mat[\"cbh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_mapping = {\n",
    "    \"Dcb\": \"geometric_mean\",\n",
    "    \"Ncb\": \"number_concentration\",\n",
    "    \"sigcb\": \"geometric_standard_deviation\",\n",
    "    \"time\": \"time\",\n",
    "    \"RH\": \"surface_relative_humidity\",\n",
    "    \"cbh\": \"cloud_base_height\",\n",
    "}\n",
    "\n",
    "ds_sarkar = xr.Dataset()\n",
    "\n",
    "for old_key, new_key in key_mapping.items():\n",
    "    # print(old_key, new_key)\n",
    "    v = mat[old_key]\n",
    "\n",
    "    assert np.max(v.shape) == np.size(v.squeeze())\n",
    "\n",
    "    if new_key == \"normalized_height\":\n",
    "        v = v.squeeze()\n",
    "        ds_sarkar[new_key] = xr.DataArray(v, dims=\"normalized_height\")\n",
    "    elif new_key == \"time\":\n",
    "        v = mat[\"time\"].squeeze()\n",
    "        v = v - v.min()\n",
    "        v = pd.to_datetime(v.squeeze(), unit=\"d\", origin=pd.Timestamp(\"2021-02-09\"))\n",
    "        ds_sarkar[new_key] = xr.DataArray(v, dims=\"time\")\n",
    "    elif v.shape[0] == 1:\n",
    "        v = v.squeeze()\n",
    "        ds_sarkar[new_key] = xr.DataArray(v, dims=\"time\")\n",
    "\n",
    "\n",
    "ds_sarkar_null = ~ds_sarkar.isnull()\n",
    "\n",
    "keys = list(ds_sarkar_null.keys())\n",
    "\n",
    "mask = ds_sarkar_null[keys[0]]\n",
    "for key in keys[1:]:\n",
    "    mask = mask & ds_sarkar_null[key]\n",
    "\n",
    "ds_sarkar = ds_sarkar.where(mask, drop=True)\n",
    "\n",
    "# Convert geometric mean from mm to µm\n",
    "\n",
    "ds_sarkar[\"geometric_mean\"] = ds_sarkar[\"geometric_mean\"] * 1e3  # Convert from mm to µm\n",
    "ds_sarkar[\"geometric_mean\"].attrs.update(\n",
    "    units=\"m\", long_name=\"Geometric Mean of Raindrop Size Distribution\"\n",
    ")\n",
    "ds_sarkar[\"number_concentration\"].attrs.update(\n",
    "    units=\"m^{-3}\", long_name=\"Number Concentration of Raindrops\"\n",
    ")\n",
    "ds_sarkar[\"geometric_standard_deviation\"].attrs.update(\n",
    "    units=\"1\", long_name=\"Geometric Standard Deviation of Raindrop Size Distribution\"\n",
    ")\n",
    "\n",
    "ds_sarkar[\"surface_relative_humidity\"].attrs.update(units=\"%\", long_name=\"Surface Relative Humidity\")\n",
    "\n",
    "ds_sarkar[\"cloud_base_temperature\"] = ds_sarkar[\"surface_relative_humidity\"] * 0 + 292  # K\n",
    "\n",
    "ds_sarkar[\"cloud_base_temperature\"].attrs.update(units=\"K\", long_name=\"Cloud Base Temperature\")\n",
    "\n",
    "\n",
    "# add altitude, air temperature and relative humidity fields_sarkar\n",
    "\n",
    "ds_sarkar[\"altitude\"] = xr.DataArray(np.linspace(0, 1300, 100), dims=\"altitude\")\n",
    "ds_sarkar[\"altitude\"].attrs.update(units=\"m\", long_name=\"Altitude\")\n",
    "\n",
    "\n",
    "ds_sarkar[\"surface_air_temperature\"] = (\n",
    "    9.8e-3 * ds_sarkar[\"cloud_base_height\"] + ds_sarkar[\"cloud_base_temperature\"]\n",
    ")\n",
    "ds_sarkar[\"surface_air_temperature\"].attrs.update(units=\"K\", long_name=\"Surface Air Temperature\")\n",
    "\n",
    "ds_sarkar[\"air_temperature\"] = ds_sarkar[\"surface_air_temperature\"] - 9.8e-3 * ds_sarkar[\"altitude\"]\n",
    "ds_sarkar[\"air_temperature\"] = ds_sarkar[\"air_temperature\"].where(\n",
    "    ds_sarkar[\"altitude\"] <= ds_sarkar[\"cloud_base_height\"]\n",
    ")\n",
    "ds_sarkar[\"air_temperature\"].attrs.update(units=\"K\", long_name=\"Air Temperature\")\n",
    "\n",
    "slope = (100 - ds_sarkar[\"surface_relative_humidity\"]) / ds_sarkar[\"cloud_base_height\"]\n",
    "ds_sarkar[\"relative_humidity\"] = ds_sarkar[\"surface_relative_humidity\"] + slope * ds_sarkar[\"altitude\"]\n",
    "ds_sarkar[\"relative_humidity\"] = ds_sarkar[\"relative_humidity\"].where(\n",
    "    ds_sarkar[\"altitude\"] <= ds_sarkar[\"cloud_base_height\"]\n",
    ")\n",
    "ds_sarkar[\"relative_humidity\"].attrs.update(units=r\"\\%\", long_name=\"Relative Humidity\")\n",
    "\n",
    "\n",
    "# add particle size distribution\n",
    "\n",
    "radius = 1e3 * np.geomspace(0.1, 3, int(1e3))\n",
    "\n",
    "ds_sarkar[\"radius\"] = xr.DataArray(radius, dims=\"radius\", attrs={\"units\": \"µm\", \"long_name\": \"Radius\"})\n",
    "\n",
    "\n",
    "def log_normal(r, mu, sigma, N) -> np.ndarray:\n",
    "    sigma = np.log(sigma)\n",
    "    mu = np.log(mu)\n",
    "    factor = N / (sigma**2 * np.sqrt(2 * np.pi))\n",
    "    exponent = -0.5 * ((np.log(r) - mu) / sigma) ** 2\n",
    "\n",
    "    return factor * np.exp(exponent)\n",
    "\n",
    "\n",
    "ds_sarkar[\"psd\"] = log_normal(\n",
    "    r=ds_sarkar[\"radius\"],\n",
    "    mu=ds_sarkar[\"geometric_mean\"],\n",
    "    sigma=ds_sarkar[\"geometric_standard_deviation\"],\n",
    "    N=ds_sarkar[\"number_concentration\"],\n",
    ")\n",
    "ds_sarkar[\"psd\"].attrs.update(\n",
    "    units=\"m^{-3} µm^{-1}\", long_name=\"Raindrop Size Distribution\\n Normalized by bin width\"\n",
    ")\n",
    "\n",
    "ds_sarkar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([53., 34., 23.,  6.,  1.,  2.,  0.,  0.,  0.,  7.]),\n",
       " array([0.00124258, 0.09821865, 0.19519472, 0.29217079, 0.38914686,\n",
       "        0.48612293, 0.583099  , 0.68007507, 0.77705114, 0.87402721,\n",
       "        0.97100328]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surface = ds_cleo_condensation[\"liquid_water_content\"].sel(gridbox=0).sel(time=time_slice).mean(\"time\")\n",
    "top = (\n",
    "    ds_cleo_condensation[\"liquid_water_content\"]\n",
    "    .sel(gridbox=ds_cleo_condensation[\"max_gridbox\"] - 1)\n",
    "    .sel(time=time_slice)\n",
    "    .mean(\"time\")\n",
    ")\n",
    "\n",
    "plt.hist((top - surface) / top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.plot(\n",
    "#     ds_sarkar['radius'],\n",
    "#     ds_sarkar['psd'].T,\n",
    "# )\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_ylim(1e-2, 1e4)\n",
    "\n",
    "# ax.set_xlabel(label_from_attrs(ds_sarkar['radius']))\n",
    "# ax.set_ylabel(label_from_attrs(ds_sarkar['psd']))\n",
    "# save_figure(fig, fig_dir / \"raindrop_size_distribution\", formats = ['.png',])\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# x = ds_sarkar['relative_humidity'].T\n",
    "# y = ds_sarkar['altitude']\n",
    "# ax.plot(\n",
    "#     x, y,\n",
    "# )\n",
    "# ax.set_xlabel(label_from_attrs(x))\n",
    "# ax.set_ylabel(label_from_attrs(y))\n",
    "# save_figure(fig, fig_dir / \"relative_humidity\", formats = ['.png',])\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# x = ds_sarkar['air_temperature'].T\n",
    "# y = ds_sarkar['altitude']\n",
    "# ax.plot(\n",
    "#     x, y,\n",
    "# )\n",
    "# ax.set_xlabel(label_from_attrs(x))\n",
    "# ax.set_ylabel(label_from_attrs(y))\n",
    "# save_figure(fig, fig_dir / \"air_temperature\", formats = ['.png',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdm_pysd_python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
