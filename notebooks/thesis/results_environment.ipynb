{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from typing_extensions import NotRequired, TypedDict\n",
    "from functools import reduce\n",
    "\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "from sdm_eurec4a.visulization import (\n",
    "    adjust_lightness_array,\n",
    "    set_custom_rcParams,\n",
    "    handler_map_alpha,\n",
    ")\n",
    "from sdm_eurec4a.reductions import mean_and_stderror_of_mean\n",
    "\n",
    "from sdm_eurec4a import RepositoryPath\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_xticks_time(ax):\n",
    "    xticks = [0, 500, 1000]\n",
    "    ax.set_xticks(xticks)\n",
    "\n",
    "\n",
    "def set_yticks_height(ax):\n",
    "    yticks = [0, 500, 1000, 1500, 2000]\n",
    "    ax.set_yticks(yticks)\n",
    "\n",
    "\n",
    "def set_yticks_height_km(ax):\n",
    "    yticks = [0, 0.5, 1, 1.5, 2]\n",
    "    ax.set_yticks(yticks)\n",
    "\n",
    "\n",
    "def set_logxticks_meter(ax):\n",
    "    xticks = [1e-6, 1e-3]\n",
    "    xticklabels = [r\"$10^{-6}$\", r\"$10^{-3}$\"]\n",
    "    ax.set_xticks(xticks, xticklabels)\n",
    "\n",
    "\n",
    "def set_logxticks_micrometer(ax):\n",
    "    xticks = [1e-3, 1e0, 1e3]\n",
    "    xticklabels = [r\"$10^{-3}$\", r\"$10^{0}$\", r\"$10^{3}$\"]\n",
    "    ax.set_xticks(xticks, xticklabels)\n",
    "\n",
    "\n",
    "def set_logtyticks_psd(ax):\n",
    "    yticks = [1e0, 1e6]\n",
    "    yticklabels = [r\"$10^0$\", r\"$10^6$\"]\n",
    "    ax.set_yticks(yticks, yticklabels)\n",
    "\n",
    "\n",
    "def set_yticks_lwc(ax):\n",
    "    ax.set_yticks([0, 0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def linear_fit(x: xr.DataArray, y: xr.DataArray):\n",
    "    x = x.values.flatten()\n",
    "    y = y.values.flatten()\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    idx = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    X = np.column_stack((x,))\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    corr = np.corrcoef(x, y)\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    return results, corr, x, y\n",
    "\n",
    "\n",
    "def linear_fit_new(x: Union[np.ndarray, xr.DataArray], y: Union[np.ndarray, xr.DataArray]):\n",
    "    if isinstance(x, xr.DataArray):\n",
    "        x = x.values.flatten()\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        x = x.flatten()\n",
    "    else:\n",
    "        raise ValueError(\"x and y must be either xr.DataArray or np.ndarray\")\n",
    "    if isinstance(y, xr.DataArray):\n",
    "        y = y.values.flatten()\n",
    "    elif isinstance(y, np.ndarray):\n",
    "        y = y.flatten()\n",
    "    else:\n",
    "        raise ValueError(\"x and y must be either xr.DataArray or np.ndarray\")\n",
    "\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    idx = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    X = np.column_stack((x,))\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    corr = np.corrcoef(x, y)\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    return results, corr\n",
    "\n",
    "\n",
    "def linear_fit_plot(ax, x: xr.DataArray, y: xr.DataArray, alpha: float = 0.05):\n",
    "    results, corr, x, y = linear_fit(x, y)\n",
    "\n",
    "    pred_ols = results.get_prediction()\n",
    "    iv_l = pred_ols.summary_frame(alpha=alpha)[\"obs_ci_lower\"]\n",
    "    iv_u = pred_ols.summary_frame(alpha=alpha)[\"obs_ci_upper\"]\n",
    "\n",
    "    ax.plot(x, results.fittedvalues, \"r-\", label=\"OLS fit ($\\\\rho$= {:.2f})\".format(corr[0, 1]))\n",
    "    ax.plot(x, iv_u, \"r:\", label=f\"CI with $\\\\alpha$ = {alpha}\")\n",
    "    ax.plot(x, iv_l, \"r:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_from_attrs(\n",
    "    da: xr.DataArray,\n",
    "    return_name: bool = True,\n",
    "    return_units: bool = True,\n",
    "    linebreak: bool = False,\n",
    "    name_width: Union[int, None] = None,\n",
    ") -> str:\n",
    "    try:\n",
    "        name = f\"{da.attrs['long_name']}\"\n",
    "    except KeyError:\n",
    "        name = f\"{da.name}\"\n",
    "\n",
    "    if \"units\" in da.attrs:\n",
    "        units = f\"{da.attrs['units']}\"\n",
    "        if \"$\" not in units:\n",
    "            units = f\"${units}$\"\n",
    "\n",
    "        units = units.replace(\"$\", \" \")\n",
    "        units = rf\"$\\left[ {units} \\right]$\"\n",
    "    else:\n",
    "        units = \"[???]\"\n",
    "\n",
    "    if return_name == True:\n",
    "        if name_width == None:\n",
    "            name = name\n",
    "        else:\n",
    "            name = textwrap.fill(name, name_width)\n",
    "\n",
    "    if return_name == True and return_units == True:\n",
    "        if linebreak == True:\n",
    "            return f\"{name}\\n{units}\"\n",
    "        else:\n",
    "            return f\"{name} {units}\"\n",
    "\n",
    "    elif return_name == True and return_units == False:\n",
    "        return f\"{name}\"\n",
    "    elif return_name == False and return_units == True:\n",
    "        return f\"{units}\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/m/m301096/repositories/sdm-eurec4a\n",
      "/home/m/m301096/repositories/sdm-eurec4a/notebooks/thesis/results\n",
      "/home/m/m301096/repositories/sdm-eurec4a/results/notebooks/thesis/results/output_v3.5/environment\n"
     ]
    }
   ],
   "source": [
    "plt.style.use(\"default\")\n",
    "default_colors = set_custom_rcParams()\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.spines.left\": False,\n",
    "        \"axes.spines.bottom\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "dark_colors = adjust_lightness_array(default_colors, amount=0.5)\n",
    "\n",
    "repo_path = RepositoryPath(\"levante\")()\n",
    "print(repo_path)\n",
    "\n",
    "subdata_dir = \"output_v3.5\"\n",
    "data_path = Path(\"/home/m/m301096/CLEO/data/\") / subdata_dir\n",
    "\n",
    "ds_subpath = \"combined/eulerian_dataset_combined_v2.nc\"\n",
    "\n",
    "# THE PATH TO THE SCRIPT DIRECTORY\n",
    "script_dir = Path(\"/home/m/m301096/repositories/sdm-eurec4a/notebooks/thesis/results/\")\n",
    "print(script_dir)\n",
    "\n",
    "\n",
    "fig_dir = repo_path / \"results\" / script_dir.relative_to(repo_path) / subdata_dir / \"environment\"\n",
    "print(fig_dir)\n",
    "\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set time slice to use for temporal mean and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = slice(1500, 3590)  # seconds\n",
    "radius_split = 45  # µm\n",
    "radius_slice = slice(1e0, None)  # µm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of radius bins: 76\n",
      "Fill value: nan\n"
     ]
    }
   ],
   "source": [
    "class MicrophysicDict(TypedDict):\n",
    "    dataset: xr.Dataset\n",
    "    microphysics: str\n",
    "    path: Path\n",
    "    # linestyle: Union[str, tuple]\n",
    "    color: str\n",
    "\n",
    "\n",
    "class OptionalDictOfMicrophysicDict(TypedDict):\n",
    "    null_microphysics: NotRequired[MicrophysicDict]\n",
    "    condensation: NotRequired[MicrophysicDict]\n",
    "    collision_condensation: NotRequired[MicrophysicDict]\n",
    "    coalbure_condensation_large: NotRequired[MicrophysicDict]\n",
    "    coalbure_condensation_small: NotRequired[MicrophysicDict]\n",
    "\n",
    "\n",
    "class DictOfMicrophysicDict(TypedDict):\n",
    "    null_microphysics: MicrophysicDict\n",
    "    condensation: MicrophysicDict\n",
    "    collision_condensation: MicrophysicDict\n",
    "    coalbure_condensation_cke: MicrophysicDict\n",
    "    coalbure_condensation_large: MicrophysicDict\n",
    "    coalbure_condensation_small: MicrophysicDict\n",
    "\n",
    "\n",
    "data_dict = DictOfMicrophysicDict(\n",
    "    null_microphysics=MicrophysicDict(\n",
    "        microphysics=\"Null microphysics\",\n",
    "        path=Path(),\n",
    "        dataset=xr.Dataset(),\n",
    "        color=\"k\",\n",
    "    ),\n",
    "    condensation=MicrophysicDict(\n",
    "        microphysics=\"Condensation/Evaporation\",\n",
    "        path=Path(),\n",
    "        dataset=xr.Dataset(),\n",
    "        color=\"k\",\n",
    "    ),\n",
    "    collision_condensation=MicrophysicDict(\n",
    "        microphysics=\"Coll-coal, cond./evap.\",\n",
    "        path=Path(),\n",
    "        dataset=xr.Dataset(),\n",
    "        color=\"k\",\n",
    "    ),\n",
    "    coalbure_condensation_cke=MicrophysicDict(\n",
    "        microphysics=\"Coll-coal-breakup n by CKE\\nand cond./evap.\",\n",
    "        path=Path(),\n",
    "        dataset=xr.Dataset(),\n",
    "        color=\"k\",\n",
    "    ),\n",
    "    coalbure_condensation_large=MicrophysicDict(\n",
    "        microphysics=\"Coll-coal-breakup (n=125)\\nand cond./evap.\",\n",
    "        path=Path(),\n",
    "        dataset=xr.Dataset(),\n",
    "        color=\"k\",\n",
    "    ),\n",
    "    coalbure_condensation_small=MicrophysicDict(\n",
    "        microphysics=\"Coll-coal-breakup (n=5)\\nand cond./evap.\",\n",
    "        path=Path(),\n",
    "        dataset=xr.Dataset(),\n",
    "        color=\"k\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "colors_dict = dict(\n",
    "    null_microphysics=\"grey\",\n",
    "    condensation=default_colors[0],\n",
    "    collision_condensation=default_colors[1],\n",
    "    coalbure_condensation_cke=default_colors[2],\n",
    "    coalbure_condensation_large=default_colors[3],\n",
    "    coalbure_condensation_small=default_colors[4],\n",
    ")\n",
    "\n",
    "for mp in data_dict:\n",
    "    data_dict[mp][\"path\"] = data_path / f\"{mp}\" / ds_subpath\n",
    "    data_dict[mp][\"color\"] = colors_dict[mp]\n",
    "\n",
    "for key in data_dict:\n",
    "    ds = xr.open_dataset(data_dict[key][\"path\"], chunks={\"cloud_id\": 2})\n",
    "    # ds = ds.sel(cloud_id = [18, 301])\n",
    "    ds.attrs.update(microphysics=data_dict[key][\"microphysics\"])\n",
    "    ds.attrs.update(microphysics_short=key)\n",
    "\n",
    "    data_dict[key][\"dataset\"] = ds\n",
    "\n",
    "# ---------------------------------------------------- #\n",
    "# Reindex the datasets to have the same radius bins\n",
    "# ---------------------------------------------------- #\n",
    "\n",
    "combined_radius_bins = reduce(\n",
    "    np.union1d, [data_dict[mp][\"dataset\"][\"radius_bins\"].values for mp in data_dict]\n",
    ")\n",
    "fill_value = np.nan\n",
    "print(\"Number of radius bins:\", len(combined_radius_bins))\n",
    "print(\"Fill value:\", fill_value)\n",
    "for mp in data_dict:\n",
    "    data_dict[mp][\"dataset\"] = data_dict[mp][\"dataset\"].reindex(\n",
    "        radius_bins=combined_radius_bins, fill_value=fill_value\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All clouds which are simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_microphysics 94\n",
      "condensation 78\n",
      "collision_condensation 83\n",
      "coalbure_condensation_cke 91\n",
      "coalbure_condensation_large 93\n",
      "coalbure_condensation_small 94\n",
      "\n",
      "Intersect: 66\n",
      "cloud_ids: [  9  11  18  20  21  22  65  67  68  71  72  73  74  88  94 110 113 114\n",
      " 130 135 136 142 194 197 198 199 201 203 205 207 208 211 212 213 214 215\n",
      " 217 218 219 220 221 222 223 224 230 233 235 236 237 292 293 295 296 301\n",
      " 303 305 306 307 308 309 311 312 314 359 361 362]\n"
     ]
    }
   ],
   "source": [
    "intersect_cloud_ids = reduce(\n",
    "    np.intersect1d, [data_dict[key][\"dataset\"][\"cloud_id\"].data for key in data_dict]\n",
    ")\n",
    "for mp in data_dict:\n",
    "    print(mp, len(data_dict[mp][\"dataset\"][\"cloud_id\"]))\n",
    "\n",
    "print(\"\\nIntersect:\", len(intersect_cloud_ids))\n",
    "print(\"cloud_ids:\", intersect_cloud_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222, null_microphysics, True\n",
      "142, null_microphysics, True\n",
      "222, condensation, True\n",
      "142, condensation, True\n",
      "222, collision_condensation, True\n",
      "142, collision_condensation, True\n",
      "222, coalbure_condensation_cke, True\n",
      "142, coalbure_condensation_cke, True\n",
      "222, coalbure_condensation_large, True\n",
      "142, coalbure_condensation_large, True\n",
      "222, coalbure_condensation_small, True\n",
      "142, coalbure_condensation_small, True\n"
     ]
    }
   ],
   "source": [
    "clouds_dict = {\n",
    "    \"222\": dict(\n",
    "        cloud_id=222,\n",
    "        color=\"r\",\n",
    "    ),\n",
    "    \"142\": dict(\n",
    "        cloud_id=142,\n",
    "        color=\"b\",\n",
    "    ),\n",
    "}\n",
    "for key in data_dict:\n",
    "    ds = data_dict[key][\"dataset\"]\n",
    "    for cloud_id in clouds_dict:\n",
    "        cloud_id = clouds_dict[cloud_id][\"cloud_id\"]\n",
    "        is_in = cloud_id in ds[\"cloud_id\"]\n",
    "        print(f\"{cloud_id}, {key}, {is_in}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add further variables e.g. latent cooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For now, it needs to be divided by 2 s to get values per second Bue to a bug.\n",
    "def add_variables(\n",
    "    ds: xr.Dataset, latent_heat_of_condensation: float = 2.265e6, time_slice=time_slice  # J kg-1\n",
    "):\n",
    "    # fix masks\n",
    "    ds[\"sub_cloud_layer_mask\"] = ds[\"sub_cloud_layer_mask\"].fillna(0).astype(bool)\n",
    "\n",
    "    # fix attributes\n",
    "    ds[\"mass_represented\"].attrs[\"long_name\"] = \"Mass\"\n",
    "\n",
    "    ds[\"radius_bins\"].attrs[\"long_name\"] = \"Radius\"\n",
    "    ds[\"radius_bins\"].attrs[\"units\"] = \"$\\\\mu m$\"\n",
    "\n",
    "    ds[\"relative_humidity\"].attrs[\"long_name\"] = \"Relative humidity\"\n",
    "    ds[\"relative_humidity\"].attrs[\"units\"] = \"$\\\\%$\"\n",
    "\n",
    "    ds[\"gridbox_thickness\"] = ds[\"gridbox_top\"] - ds[\"gridbox_bottom\"]\n",
    "    ds[\"cloud_altitude\"] = ds[\"gridbox_coord3\"].sel(gridbox=ds[\"max_gridbox\"])\n",
    "\n",
    "    # It seems that xi was stored as an integer. This is not wanted, because nan values will just be large integers.\n",
    "    ds[\"xi\"] = ds[\"xi\"].astype(float)\n",
    "    ds[\"xi\"] = ds[\"xi\"].where(ds[\"xi\"] < 1e12)\n",
    "\n",
    "    ds[\"xi\"].attrs[\"units\"] = \"$\\\\#$\"\n",
    "    ds[\"xi\"].attrs[\"long_name\"] = \"Real droplet num. conc.\"\n",
    "\n",
    "    ds[\"xi_per_volume\"] = ds[\"xi\"] / ds[\"gridbox_volume\"]\n",
    "    ds[\"xi_per_volume\"].attrs[\"long_name\"] = ds[\"xi\"].attrs[\"long_name\"]\n",
    "    ds[\"xi_per_volume\"].attrs[\"units\"] = \"$\\\\# m^{-3}$\"\n",
    "\n",
    "    ds[\"number_superdroplets_per_volume\"] = 1000 * ds[\"number_superdroplets\"] / ds[\"gridbox_volume\"]\n",
    "    ds[\"number_superdroplets_per_volume\"].attrs[\"units\"] = \"$10^3m^{-3}$\"\n",
    "    ds[\"number_superdroplets_per_volume\"].attrs[\"long_name\"] = \"Number of superdroplets per volume\"\n",
    "\n",
    "    ds[\"mass_represented_per_volume\"] = 1e3 * ds[\"mass_represented\"] / ds[\"gridbox_volume\"]\n",
    "    ds[\"mass_represented_per_volume\"].attrs[\"units\"] = \"$g m^{-3}$\"\n",
    "    ds[\"mass_represented_per_volume\"].attrs[\"long_name\"] = \"Mass\"\n",
    "\n",
    "    ds[\"evaporation_full\"] = 1e3 * ds[\"massdelta_condensation\"].sel(time=time_slice).where(\n",
    "        ds[\"sub_cloud_layer_mask\"]\n",
    "    )\n",
    "    ds[\"evaporation_full\"].attrs[\"units\"] = \"$g m^{-3} s^{-1}$\"\n",
    "    ds[\"evaporation_full\"].attrs[\"long_name\"] = \"Evaporation rate\"\n",
    "    ds[\"evaporation_full\"].attrs[\"description\"] = \"Evaporation rate for all timesteps\"\n",
    "\n",
    "    # ds[\"evaporation\"] = (\n",
    "    #     ds[\"evaporation_full\"].sel(time=time_slice).mean(\"time\", keep_attrs=True, skipna=True)\n",
    "    # )\n",
    "    # ds[\"evaporation\"].attrs[\"units\"] = \"$g m^{-3} s^{-1}$\"\n",
    "    # ds[\"evaporation\"].attrs[\"long_name\"] = \"Evaporation rate\"\n",
    "\n",
    "    # ds[\"evaporation\"].attrs[\"units\"] = \"$g m^{-3} s^{-1}$\"\n",
    "    # ds[\"evaporation\"].attrs[\"long_name\"] = \"Evaporation rate\"\n",
    "\n",
    "    ds[\"latent_heating\"] = (\n",
    "        1e-3\n",
    "        * ds[\"evaporation_full\"].sel(time=time_slice).mean(\"time\", keep_attrs=True, skipna=True)\n",
    "        * latent_heat_of_condensation\n",
    "    )  # kg m-3 s-1 * J kg-1 = W m-3\n",
    "    ds[\"latent_heating\"].attrs[\"units\"] = \"$W m^{-3}$\"\n",
    "    ds[\"latent_heating\"].attrs[\"long_name\"] = \"Latent heating\"\n",
    "\n",
    "    ds[\"latent_heating_full\"] = (\n",
    "        1e-3 * ds[\"evaporation_full\"].sel(time=time_slice) * latent_heat_of_condensation\n",
    "    )  # kg m-3 s-1 * J kg-1 = W m-3\n",
    "    ds[\"latent_heating_full\"].attrs[\"units\"] = \"$W m^{-3}$\"\n",
    "    ds[\"latent_heating_full\"].attrs[\"long_name\"] = \"Latent heating\"\n",
    "    ds[\"latent_heating_full\"].attrs[\"description\"] = \"Latent heating for all timesteps\"\n",
    "\n",
    "    ds[\"latent_heating_mean\"] = ds[\"latent_heating\"].mean(\"gridbox\", keep_attrs=True)\n",
    "    ds[\"latent_heating_sum\"] = (ds[\"latent_heating\"] * ds[\"gridbox_thickness\"]).sum(\n",
    "        \"gridbox\", keep_attrs=True\n",
    "    )\n",
    "    ds[\"latent_heating_sum\"].attrs[\"units\"] = \"$W m^{-2}$\"\n",
    "    ds[\"latent_heating_sum\"].attrs[\"long_name\"] = \"Column int. latent heating\"\n",
    "\n",
    "    ds[\"latent_heating_radius_bins\"] = (\n",
    "        ds[\"mass_difference_per_volume\"].sel(time=time_slice).where(ds[\"sub_cloud_layer_mask\"])\n",
    "        * latent_heat_of_condensation\n",
    "    )\n",
    "    ds[\"latent_heating_radius_bins\"].attrs[\"units\"] = \"$W m^{-3}$\"\n",
    "    ds[\"latent_heating_radius_bins\"].attrs[\"long_name\"] = \"Latent heating\"\n",
    "\n",
    "    # In order to mask out outliers in the latent heating field,\n",
    "    # the total latent heating at a timestep for a gridbox should not exceed\n",
    "    # the minimum or maximum value of the latent heating field from CLEOs monitor output.\n",
    "    ds[\"mask_latent_heating\"] = (\n",
    "        ds[\"latent_heating_radius_bins\"] > ds[\"latent_heating_radius_bins\"].quantile(0.05, \"time\")\n",
    "    ) & (ds[\"latent_heating_radius_bins\"] < ds[\"latent_heating_radius_bins\"].quantile(0.95, \"time\"))\n",
    "    ds[\"mask_latent_heating\"].attrs[\n",
    "        \"description\"\n",
    "    ] = \"In order to mask out outliers in the latent heating field, the total latent heating at a timestep for a gridbox should not exceed the minimum or maximum value of the latent heating field from CLEOs monitor output.\"\n",
    "\n",
    "    ds[\"latent_heating_radius_bins_masked\"] = ds[\"latent_heating_radius_bins\"].where(\n",
    "        ds[\"mask_latent_heating\"]\n",
    "    )\n",
    "\n",
    "    ds[\"latent_heating_radius_bins_time_median\"] = (\n",
    "        ds[\"latent_heating_radius_bins\"]\n",
    "        .sel(time=time_slice)\n",
    "        .median(\"time\", keep_attrs=True, skipna=True)\n",
    "    )\n",
    "    ds[\"latent_heating_radius_bins_time_median\"].attrs[\"units\"] = \"$W m^{-3}$\"\n",
    "    ds[\"latent_heating_radius_bins_time_median\"].attrs[\"long_name\"] = \"Latent heating\"\n",
    "    ds[\"latent_heating_radius_bins_time_median\"].attrs[\n",
    "        \"description\"\n",
    "    ] = \"Median latent heating for all timesteps\"\n",
    "\n",
    "\n",
    "for mp in data_dict:\n",
    "    ds = data_dict[mp][\"dataset\"]\n",
    "    add_variables(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the domain and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the outlier is cloud ``296``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_microphysics: xr.Dataset = data_dict[\"null_microphysics\"][\"dataset\"]\n",
    "condensation: xr.Dataset = data_dict[\"condensation\"][\"dataset\"]\n",
    "collision_condensation: xr.Dataset = data_dict[\"collision_condensation\"][\"dataset\"]\n",
    "coalbure_condensation_cke: xr.Dataset = data_dict[\"coalbure_condensation_cke\"][\"dataset\"]\n",
    "coalbure_condensation_large: xr.Dataset = data_dict[\"coalbure_condensation_large\"][\"dataset\"]\n",
    "coalbure_condensation_small: xr.Dataset = data_dict[\"coalbure_condensation_small\"][\"dataset\"]\n",
    "\n",
    "# fig, axs = plt.subplots(ncols=5, figsize=(15, 5))\n",
    "# null_microphysics[\"mass_represented\"].sel(gridbox = 0).sum(dim=\"radius_bins\").plot(ax = axs[0])\n",
    "# condensation[\"mass_represented\"].sel(gridbox = 0).sum(dim=\"radius_bins\").plot(ax = axs[1])\n",
    "# collision_condensation[\"mass_represented\"].sel(gridbox = 0).sum(dim=\"radius_bins\").plot(ax = axs[2])\n",
    "# coalbure_condensation_large[\"mass_represented\"].sel(gridbox = 0).sum(dim=\"radius_bins\").plot(ax = axs[3])\n",
    "# coalbure_condensation_small[\"mass_represented\"].sel(gridbox = 0).sum(dim=\"radius_bins\").plot(ax = axs[4])\n",
    "\n",
    "# remove outlier cloud_id 296\n",
    "cloud_id_selection = intersect_cloud_ids[intersect_cloud_ids != 296]\n",
    "\n",
    "null_microphysics = null_microphysics.sel(cloud_id=cloud_id_selection)\n",
    "condensation = condensation.sel(cloud_id=cloud_id_selection)\n",
    "collision_condensation = collision_condensation.sel(cloud_id=cloud_id_selection)\n",
    "coalbure_condensation_cke = coalbure_condensation_cke.sel(cloud_id=cloud_id_selection)\n",
    "coalbure_condensation_large = coalbure_condensation_large.sel(cloud_id=cloud_id_selection)\n",
    "coalbure_condensation_small = coalbure_condensation_small.sel(cloud_id=cloud_id_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud height impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(5, 5), sharey=False)\n",
    "\n",
    "# Vertical profiles\n",
    "ax.plot(\n",
    "    data[\"latent_heating\"].where(data[\"sub_cloud_layer_mask\"]).T,\n",
    "    data[\"gridbox_coord3\"].T,\n",
    "    linewidth=1.5,\n",
    "    alpha=0.5,\n",
    "    color=default_colors[0],\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(data[\"latent_heating\"]))\n",
    "ax.set_ylabel(\"Height [m]\")\n",
    "# ax.set_title(\"Latent heating profiles\")\n",
    "\n",
    "ax.set_yticks([0, 250, 500, 750, 1000])\n",
    "ax.set_ylim([0, 1100])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"profiles_latent_heating.svg\")\n",
    "fig.savefig(fig_dir / \"profiles_latent_heating.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(5, 5), sharey=False)\n",
    "\n",
    "lh_cumsum = (\n",
    "    ((data[\"latent_heating\"] * data[\"gridbox_thickness\"]).sortby(-data[\"gridbox\"]))\n",
    "    .cumsum(\"gridbox\", skipna=True)\n",
    "    .where(data[\"sub_cloud_layer_mask\"])\n",
    "    .T\n",
    ")\n",
    "lh_cumsum = lh_cumsum.sortby(lh_cumsum[\"gridbox\"])\n",
    "\n",
    "lh_cumsum.attrs[\"long_name\"] = \"Column int. latent heating\"\n",
    "lh_cumsum.attrs[\"units\"] = \"$W m^{-2}$\"\n",
    "\n",
    "# Vertical profiles\n",
    "ax.plot(\n",
    "    lh_cumsum.sel(gridbox=slice(1, None)),\n",
    "    data[\"gridbox_coord3\"].sel(gridbox=slice(1, None)).T,\n",
    "    linewidth=1.5,\n",
    "    alpha=0.5,\n",
    "    color=default_colors[0],\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(lh_cumsum))\n",
    "ax.set_ylabel(\"Height [m]\")\n",
    "# ax.set_title(\"Profiles of column int. latent heating\")\n",
    "\n",
    "ax.set_yticks([0, 250, 500, 750, 1000])\n",
    "ax.set_ylim([0, 1100])\n",
    "ax.set_xlim([-60, 0])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"profiles_column_integrated_latent_heating.svg\")\n",
    "fig.savefig(fig_dir / \"profiles_column_integrated_latent_heating.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of column integrated latent heating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation.sel(time=time_slice)\n",
    "ylim = [0, 12]\n",
    "da = (data[\"latent_heating_full\"] * data[\"gridbox_thickness\"]).sum(\"gridbox\")\n",
    "da.attrs[\"units\"] = \"Wm^{-2}\"\n",
    "da.attrs[\"long_name\"] = \"Column int. latent heating\"\n",
    "\n",
    "da_time_mean, da_time_sem = mean_and_stderror_of_mean(\n",
    "    data=da,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "da_cloud_mean, da_cloud_sem = mean_and_stderror_of_mean(\n",
    "    data=da_time_mean,\n",
    "    dims=(\"cloud_id\",),\n",
    "    data_std=da_time_sem,\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(\n",
    "    da_time_mean,\n",
    "    bins=np.arange(-60, -10, 2),\n",
    "    color=\"k\",\n",
    "    alpha=0.5,\n",
    "    density=False,\n",
    ")\n",
    "ax.axvline(\n",
    "    da_cloud_mean,\n",
    "    color=\"darkorange\",\n",
    "    label=f\"Mean: {da_cloud_mean.values:.1f} $\\pm$ {da_cloud_sem.values:.1f} \" + \"$Wm^{-2}$\",\n",
    ")\n",
    "\n",
    "ax.fill_betweenx(\n",
    "    ylim,\n",
    "    da_cloud_mean - 2 * da_cloud_sem,\n",
    "    da_cloud_mean + 2 * da_cloud_sem,\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    "    label=\"2 SEM\",\n",
    ")\n",
    "\n",
    "# ax.axvline(\n",
    "#     lh_sum_time_mean.compute().median(\"cloud_id\"),\n",
    "#     color=\"red\",\n",
    "#     label=\"Median\",\n",
    "#     linestyle = \"--\"\n",
    "# )\n",
    "\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(da))\n",
    "ax.set_ylabel(\"Occurence\")\n",
    "# ax.set_title(f\"Histogram of {label_from_attrs(da, return_units=False).lower()}\")\n",
    "ax.legend()\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim([-60, -10])\n",
    "\n",
    "fig.savefig(fig_dir / \"histogram_column_integreate_latent_heating.svg\")\n",
    "fig.savefig(fig_dir / \"histogram_column_integreate_latent_heating.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column integrated latent heating vs. LWC at cloud base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation.sel(time=time_slice)\n",
    "ylim = [0, 12]\n",
    "\n",
    "lhci = (data[\"latent_heating_full\"] * data[\"gridbox_thickness\"]).sum(\"gridbox\")\n",
    "# lhci = (data[\"latent_heating_full\"]).mean(\"gridbox\")\n",
    "lhci.attrs[\"units\"] = \"Wm^{-2}\"\n",
    "lhci.attrs[\"long_name\"] = \"Column int. latent heating\"\n",
    "lhci = lhci.compute()\n",
    "lwc = (\n",
    "    data[\"mass_represented_per_volume\"]\n",
    "    .sel(gridbox=data[\"max_gridbox\"])\n",
    "    .sum(\"radius_bins\", keep_attrs=True)\n",
    ")\n",
    "lwc = lwc.compute()\n",
    "lwc.attrs[\"units\"] = \"g m^{-3}\"\n",
    "lwc.attrs[\"long_name\"] = \"Liquid water content\"\n",
    "\n",
    "\n",
    "lhci_time_mean, lhci_time_sem = mean_and_stderror_of_mean(\n",
    "    data=lhci,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "lwc_time_mean, lwc_time_sem = mean_and_stderror_of_mean(\n",
    "    data=lwc,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "\n",
    "lhci_time_mean = lhci_time_mean.compute()\n",
    "lhci_time_mean.attrs[\"units\"] = \"Wm^{-2}\"\n",
    "lhci_time_mean.attrs[\"long_name\"] = \"Column int. latent heating\"\n",
    "lhci_time_sem = lhci_time_sem.compute()\n",
    "\n",
    "lwc_time_mean = lwc_time_mean.compute()\n",
    "lwc_time_mean.attrs[\"units\"] = \"g m^{-3}\"\n",
    "lwc_time_mean.attrs[\"long_name\"] = \"Liquid water content\"\n",
    "lwc_time_sem = lwc_time_sem.compute()\n",
    "\n",
    "\n",
    "lhci_cloud_mean, lhci_cloud_sem = mean_and_stderror_of_mean(\n",
    "    data=lhci_time_mean,\n",
    "    dims=(\"cloud_id\",),\n",
    "    data_std=lhci_time_sem,\n",
    ")\n",
    "lwc_cloud_mean, lwc_cloud_sem = mean_and_stderror_of_mean(\n",
    "    data=lwc_time_mean,\n",
    "    dims=(\"cloud_id\",),\n",
    "    data_std=None,\n",
    ")\n",
    "\n",
    "lhci_cloud_mean = lhci_cloud_mean.compute()\n",
    "lhci_cloud_sem = lhci_cloud_sem.compute()\n",
    "lwc_cloud_mean = lwc_cloud_mean.compute()\n",
    "lwc_cloud_sem = lwc_cloud_sem.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4.5))\n",
    "\n",
    "# ax.errorbar(\n",
    "#     x = lwc_cloud_mean,\n",
    "#     y = lhci_cloud_mean,\n",
    "#     xerr = lwc_cloud_sem,\n",
    "#     yerr = lhci_cloud_sem,\n",
    "#     marker = \"\",\n",
    "#     linestyle = \"\",\n",
    "#     color = \"k\",\n",
    "#     label = \"Mean of all clouds\",\n",
    "# )\n",
    "\n",
    "ax.scatter(\n",
    "    x=lwc_time_mean,\n",
    "    y=lhci_time_mean,\n",
    "    # xerr = lwc_time_sem,\n",
    "    # yerr = lhci_time_sem,\n",
    "    marker=\".\",\n",
    "    linestyle=\"\",\n",
    "    label=\"Individual cloud\",\n",
    ")\n",
    "\n",
    "linear_fit_plot(\n",
    "    ax,\n",
    "    lwc_time_mean,\n",
    "    lhci_time_mean,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(lwc_time_mean))\n",
    "ax.set_ylabel(label_from_attrs(lhci_time_mean))\n",
    "ax.set_xlim([0, 0.17])\n",
    "ax.set_xticks([0, 0.05, 0.1, 0.15])\n",
    "ax.set_ylim([-60, -10])\n",
    "ax.legend()\n",
    "# fig.suptitle(f\"{label_from_attrs(lhci, return_units=False)} against the LWC in the cloud layer\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"scatter-column_integrated_latent_heating-liquid_water_content.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermodynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_heating = 1e3 * condensation[\"latent_heating\"]\n",
    "latent_heating.attrs[\"units\"] = \"m\" + condensation[\"latent_heating\"].attrs[\"units\"].replace(\"$\", \"\")\n",
    "latent_heating.attrs[\"long_name\"] = condensation[\"latent_heating\"].attrs[\"long_name\"]\n",
    "\n",
    "liquid_water_content = (\n",
    "    data[\"mass_represented_per_volume\"]\n",
    "    .sum(\"radius_bins\")\n",
    "    .sel(time=time_slice)\n",
    "    .mean(\"time\", keep_attrs=True)\n",
    "    .astype(float)\n",
    ")\n",
    "liquid_water_content = liquid_water_content.where(data[\"sub_cloud_layer_mask\"]).compute()\n",
    "liquid_water_content.attrs.update(\n",
    "    units=\"g m^{-3}\",\n",
    "    long_name=\"Liquid water content\",\n",
    ")  #\n",
    "liquid_water_content_init_1d = liquid_water_content.sel(gridbox=data[\"max_gridbox\"] - 1).compute()\n",
    "liquid_water_content_init = liquid_water_content_init_1d.drop(\"gridbox\").expand_dims(\n",
    "    gridbox=data[\"gridbox\"]\n",
    ")\n",
    "\n",
    "relative_humidity = data[\"relative_humidity\"]\n",
    "relative_humidity = relative_humidity.where(data[\"sub_cloud_layer_mask\"]).compute()\n",
    "\n",
    "coord3 = data[\"gridbox_coord3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculat the slope of a linear regression for the relative humidity for all clouds\n",
    "\n",
    "\n",
    "def slope_intercept(x, y, **kwargs):\n",
    "    # print(f\"received {type(x)} shape: {x.shape}\")\n",
    "    # print(f\"received {type(y)} shape: {y.shape}\")\n",
    "    try:\n",
    "        idx = np.isfinite(x) & np.isfinite(y)\n",
    "        slope, intercept = np.polyfit(x[idx], y[idx], **kwargs)\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "    return slope, intercept\n",
    "\n",
    "\n",
    "relative_humidity_slopes, rh_inter = xr.apply_ufunc(\n",
    "    slope_intercept,\n",
    "    1e-3 * data[\"gridbox_coord3\"].chunk(dict(cloud_id=-1)).compute(),\n",
    "    relative_humidity.chunk(dict(cloud_id=-1)).compute(),\n",
    "    input_core_dims=[[\"gridbox\"], [\"gridbox\"]],\n",
    "    output_core_dims=[[], []],\n",
    "    exclude_dims={\"gridbox\"},\n",
    "    # output_sizes={\"slope\": 1, \"intercept\": 1},\n",
    "    # output_dtypes=[[float], [float]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    kwargs=dict(deg=1),\n",
    ")\n",
    "relative_humidity_slopes.attrs[\"units\"] = rh.attrs[\"units\"] + \" (km)^{-1}\"\n",
    "relative_humidity_slopes.attrs[\"long_name\"] = \"Relative humidity vertical gradient\"\n",
    "relative_humidity_slopes = relative_humidity_slopes.compute()\n",
    "\n",
    "latent_heating_slopes, latent_heating_inter = xr.apply_ufunc(\n",
    "    slope_intercept,\n",
    "    1e-3 * data[\"gridbox_coord3\"].chunk(dict(cloud_id=-1)).compute(),\n",
    "    latent_heating.chunk(dict(cloud_id=-1)).compute(),\n",
    "    input_core_dims=[[\"gridbox\"], [\"gridbox\"]],\n",
    "    output_core_dims=[[], []],\n",
    "    exclude_dims={\"gridbox\"},\n",
    "    # output_sizes={\"slope\": 1, \"intercept\": 1},\n",
    "    # output_dtypes=[[float], [float]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    kwargs=dict(deg=1),\n",
    ")\n",
    "\n",
    "latent_heating_slopes.attrs[\"units\"] = latent_heating.attrs[\"units\"] + \" (km)^{-1}\"\n",
    "latent_heating_slopes.attrs[\"long_name\"] = \"Latent heating vertical gradient\"\n",
    "latent_heating_slopes = latent_heating_slopes.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4.5))\n",
    "sc = ax.scatter(\n",
    "    liquid_water_content,\n",
    "    relative_humidity,\n",
    "    c=latent_heating,\n",
    "    marker=\".\",\n",
    "    alpha=0.8,\n",
    "    cmap=\"inferno\",\n",
    "    vmin=-100,\n",
    "    vmax=0,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(liquid_water_content))\n",
    "ax.set_ylabel(label_from_attrs(relative_humidity))\n",
    "fig.colorbar(sc, ax=ax, label=label_from_attrs(latent_heating))\n",
    "\n",
    "# fig.suptitle(\"Latent heating against mass in gridbox and relative humidity\")\n",
    "fig.savefig(fig_dir / \"scatter_latent_heating_mass_rh.svg\")\n",
    "fig.savefig(fig_dir / \"scatter_latent_heating_mass_rh.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(10, 6.5), sharey=True, nrows=2)\n",
    "\n",
    "sc = axs[0].scatter(\n",
    "    latent_heating,\n",
    "    coord3,\n",
    "    c=liquid_water_content,\n",
    "    marker=\".\",\n",
    "    alpha=0.8,\n",
    "    cmap=\"inferno\",\n",
    ")\n",
    "fig.colorbar(sc, ax=axs[0], label=label_from_attrs(liquid_water_content))\n",
    "axs[0].set_xlabel(label_from_attrs(latent_heating))\n",
    "\n",
    "# Impact of relative humidity slope\n",
    "sc = axs[1].scatter(\n",
    "    latent_heating - latent_heating.sel(gridbox=data[\"max_gridbox\"] - 2),\n",
    "    coord3,\n",
    "    c=(relative_humidity_slopes.expand_dims(gridbox=data[\"gridbox\"])).T,\n",
    "    marker=\".\",\n",
    "    alpha=0.8,\n",
    "    cmap=\"inferno\",\n",
    ")\n",
    "fig.colorbar(sc, ax=axs[1], label=label_from_attrs(relative_humidity_slopes, name_width=25))\n",
    "axs[1].set_xlabel(f\"Difference to cloud layer of {label_from_attrs(latent_heating)}\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylabel(\"Height [m]\")\n",
    "    ax.set_ylim([0, 1100])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"scatter_latent_heating.svg\")\n",
    "fig.savefig(fig_dir / \"scatter_latent_heating.pdf\")\n",
    "# fig.suptitle(\"Latent heating against mass in gridbox and relative humidity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4.5))\n",
    "\n",
    "ax.scatter(\n",
    "    x=relative_humidity_slopes,\n",
    "    y=latent_heating_slopes,\n",
    "    # xerr = lwc_time_sem,\n",
    "    # yerr = lhci_time_sem,\n",
    "    marker=\".\",\n",
    "    linestyle=\"\",\n",
    "    label=\"Individual cloud\",\n",
    ")\n",
    "\n",
    "linear_fit_plot(\n",
    "    ax,\n",
    "    relative_humidity_slopes,\n",
    "    latent_heating_slopes,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(relative_humidity_slopes))\n",
    "ax.set_ylabel(label_from_attrs(latent_heating_slopes, linebreak=True))\n",
    "ax.legend(loc=\"upper left\")\n",
    "# fig.suptitle(f\"{label_from_attrs(lhci, return_units=False)} against the LWC in the cloud layer\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"scatter-latent_heating_slope-relative_humidity_slope.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination RH slope and LWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varibles = [lwc_time_mean, relative_humidity_slopes]\n",
    "y_variables = [lhci_time_mean, latent_heating_slopes]\n",
    "fig, axs = plt.subplots(figsize=(10, 4.5), ncols=len(varibles))\n",
    "\n",
    "for i, (var, y_var) in enumerate(zip(varibles, y_variables)):\n",
    "    axs[i].scatter(\n",
    "        var,\n",
    "        y_var,\n",
    "        marker=\".\",\n",
    "        alpha=1,\n",
    "        label=\"Individual clouds\",\n",
    "    )\n",
    "    linear_fit_plot(\n",
    "        ax=axs[i],\n",
    "        x=var,\n",
    "        y=y_var,\n",
    "        alpha=0.05,\n",
    "    )\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(y_var))\n",
    "    # axs[i].set_title(f\"{label_from_attrs(latent_heating_slopes)} against {label_from_attrs(var)}\")\n",
    "\n",
    "axs[0].set_xlim([0, 0.17])\n",
    "axs[0].set_xticks([0, 0.05, 0.1, 0.15])\n",
    "\n",
    "axs[1].set_ylabel(label_from_attrs(latent_heating_slopes, linebreak=True))\n",
    "\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "axs[1].legend(loc=\"upper left\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(fig_dir / \"scatter-cloud_properties-thermodynamics.svg\")\n",
    "fig.savefig(fig_dir / \"scatter-cloud_properties-thermodynamics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varibles = [lwc_time_mean, relative_humidity_slopes]\n",
    "y_variables = [lhci_time_mean, latent_heating_slopes]\n",
    "fig, axs = plt.subplots(figsize=(10, 4.5), ncols=len(varibles))\n",
    "\n",
    "for i, (var, y_var) in enumerate(zip(varibles, y_variables)):\n",
    "    axs[i].scatter(\n",
    "        var,\n",
    "        y_var,\n",
    "        marker=\".\",\n",
    "        alpha=0.5,\n",
    "        label=\"Individual clouds\",\n",
    "    )\n",
    "    linear_fit_plot(\n",
    "        ax=axs[i],\n",
    "        x=var,\n",
    "        y=y_var,\n",
    "        alpha=0.05,\n",
    "    )\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(y_var))\n",
    "    # axs[i].set_title(f\"{label_from_attrs(latent_heating_slopes)} against {label_from_attrs(var)}\")\n",
    "\n",
    "axs[0].set_xlim([0, 0.17])\n",
    "axs[0].set_xticks([0, 0.05, 0.1, 0.15])\n",
    "\n",
    "axs[1].set_ylabel(label_from_attrs(latent_heating_slopes, linebreak=True))\n",
    "\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "axs[1].legend(loc=\"upper left\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(fig_dir / \"scatter-cloud_properties-thermodynamics.svg\")\n",
    "fig.savefig(fig_dir / \"scatter-cloud_properties-thermodynamics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fit_uncertainty(x: xr.DataArray, y: xr.DataArray):\n",
    "    results, corr = linear_fit_new(\n",
    "        x=x,\n",
    "        y=y,\n",
    "    )\n",
    "\n",
    "    x0 = results.params[0]\n",
    "    x0_error = results.bse[0]\n",
    "    x1 = results.params[1]\n",
    "    x1_error = results.bse[1]\n",
    "\n",
    "    return x0, x0_error, x1, x1_error, corr[1, 0]\n",
    "\n",
    "\n",
    "_, _, rh_slopes, rh_slopes_error, rh_corr = xr.apply_ufunc(\n",
    "    linear_fit_uncertainty,\n",
    "    1e-3 * data[\"gridbox_coord3\"].chunk(dict(cloud_id=-1)).compute(),\n",
    "    relative_humidity.chunk(dict(cloud_id=-1)).compute(),\n",
    "    input_core_dims=[[\"gridbox\"], [\"gridbox\"]],\n",
    "    output_core_dims=[[], [], [], [], []],\n",
    "    exclude_dims={\"gridbox\"},\n",
    "    # output_sizes={\"slope\": 1, \"intercept\": 1},\n",
    "    # output_dtypes=[[float], [float]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    ")\n",
    "\n",
    "\n",
    "_, _, lh_slopes, lh_slopes_error, lh_corr = xr.apply_ufunc(\n",
    "    linear_fit_uncertainty,\n",
    "    1e-3 * data[\"gridbox_coord3\"].chunk(dict(cloud_id=-1)).compute(),\n",
    "    latent_heating.chunk(dict(cloud_id=-1)).compute(),\n",
    "    input_core_dims=[[\"gridbox\"], [\"gridbox\"]],\n",
    "    output_core_dims=[[], [], [], [], []],\n",
    "    exclude_dims={\"gridbox\"},\n",
    "    # output_sizes={\"slope\": 1, \"intercept\": 1},\n",
    "    # output_dtypes=[[float], [float]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of linear regression with uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ffe044be510>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, ie, s, se, corr = linear_fit_uncertainty(\n",
    "    x=rh_slopes,\n",
    "    y=lh_slopes,\n",
    ")\n",
    "x = np.arange(0, 30)\n",
    "plt.fill_between(\n",
    "    x=x,\n",
    "    y1=(s - 2 * se) * x + i - 2 * ie,\n",
    "    y2=(s + 2 * se) * x + i + 2 * ie,\n",
    "    alpha=0.3,\n",
    "    color=\"grey\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    x,\n",
    "    s * x + i,\n",
    "    label=f\"y = {s:.2f}x + {i:.2f}\",\n",
    "    color=\"k\",\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    x=rh_slopes,\n",
    "    y=lh_slopes,\n",
    ")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of LWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwc_bins = np.arange(0, 171, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud LWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation.sel(time=time_slice)\n",
    "ylim = (0, 12)\n",
    "\n",
    "da = 1e6 * data[\"liquid_water_content\"].sum(\"radius_bins\")\n",
    "da.attrs[\"units\"] = \"$mg m^{-3}$\"\n",
    "da.attrs[\"long_name\"] = \"Liquid water content\"\n",
    "\n",
    "da = da.sel(gridbox=data[\"max_gridbox\"])\n",
    "\n",
    "da_time_mean, da_time_sem = mean_and_stderror_of_mean(\n",
    "    data=da,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "da_time_mean = da_time_mean.compute()\n",
    "da_time_sem = da_time_sem.compute()\n",
    "\n",
    "da_cloud_mean, da_cloud_sem = mean_and_stderror_of_mean(\n",
    "    data=da_time_mean,\n",
    "    dims=(\"cloud_id\",),\n",
    "    data_std=da_time_sem,\n",
    ")\n",
    "da_cloud_mean = da_cloud_mean.compute()\n",
    "da_cloud_sem = da_cloud_sem.compute()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(\n",
    "    da_time_mean,\n",
    "    bins=lwc_bins,\n",
    "    color=\"k\",\n",
    "    alpha=0.5,\n",
    "    density=False,\n",
    ")\n",
    "ax.axvline(\n",
    "    da_cloud_mean,\n",
    "    color=\"darkorange\",\n",
    "    label=f\"Mean: {da_cloud_mean.values:.2f} $\\pm$ {da_cloud_sem.values:.2f} \"\n",
    "    + label_from_attrs(da, return_name=False),\n",
    ")\n",
    "\n",
    "ax.fill_betweenx(\n",
    "    ylim,\n",
    "    da_cloud_mean - 2 * da_cloud_sem,\n",
    "    da_cloud_mean + 2 * da_cloud_sem,\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    "    label=\"2 SEM\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(da))\n",
    "ax.set_ylabel(\"Occurence\")\n",
    "ax.set_title(f\"Histogram of {label_from_attrs(da, return_units=False).lower()} in cloud layer\")\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim([lwc_bins[0], lwc_bins[-1]])\n",
    "fig.savefig(fig_dir / \"liquid_water_content_histogram_cloud.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top sub cloud layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation.sel(time=time_slice)\n",
    "ylim = (0, 12)\n",
    "da = 1e6 * data[\"liquid_water_content\"].sum(\"radius_bins\")\n",
    "da.attrs[\"units\"] = \"$mg m^{-3}$\"\n",
    "da.attrs[\"long_name\"] = \"Liquid water content\"\n",
    "\n",
    "da = da.sel(gridbox=data[\"max_gridbox\"] - 2)\n",
    "\n",
    "da_time_mean, da_time_sem = mean_and_stderror_of_mean(\n",
    "    data=da,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "da_time_mean = da_time_mean.compute()\n",
    "da_time_sem = da_time_sem.compute()\n",
    "\n",
    "da_cloud_mean, da_cloud_sem = mean_and_stderror_of_mean(\n",
    "    data=da_time_mean,\n",
    "    dims=(\"cloud_id\",),\n",
    "    data_std=da_time_sem,\n",
    ")\n",
    "da_cloud_mean = da_cloud_mean.compute()\n",
    "da_cloud_sem = da_cloud_sem.compute()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(\n",
    "    da_time_mean,\n",
    "    bins=lwc_bins,\n",
    "    color=\"k\",\n",
    "    alpha=0.5,\n",
    "    density=False,\n",
    ")\n",
    "ax.axvline(\n",
    "    da_cloud_mean,\n",
    "    color=\"darkorange\",\n",
    "    label=f\"Mean: {da_cloud_mean.values:.2f} $\\pm$ {da_cloud_sem.values:.2f} \"\n",
    "    + label_from_attrs(da, return_name=False),\n",
    ")\n",
    "\n",
    "ax.fill_betweenx(\n",
    "    ylim,\n",
    "    da_cloud_mean - 2 * da_cloud_sem,\n",
    "    da_cloud_mean + 2 * da_cloud_sem,\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    "    label=\"2 SEM\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(da))\n",
    "ax.set_ylabel(\"Occurence\")\n",
    "ax.set_title(f\"Histogram of {label_from_attrs(da, return_units=False).lower()} in sub-cloud layer\")\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim([lwc_bins[0], lwc_bins[-1]])\n",
    "\n",
    "fig.savefig(fig_dir / \"liquid_water_content_histogram_subcloud.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface LWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation.sel(time=time_slice)\n",
    "ylim = (0, 12)\n",
    "\n",
    "da = 1e6 * data[\"liquid_water_content\"].sum(\"radius_bins\")\n",
    "da.attrs[\"units\"] = \"$mg m^{-3}$\"\n",
    "da.attrs[\"long_name\"] = \"Liquid water content\"\n",
    "\n",
    "da = da.sel(gridbox=0)\n",
    "\n",
    "da_time_mean, da_time_sem = mean_and_stderror_of_mean(\n",
    "    data=da,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "da_time_mean = da_time_mean.compute()\n",
    "da_time_sem = da_time_sem.compute()\n",
    "\n",
    "da_cloud_mean, da_cloud_sem = mean_and_stderror_of_mean(\n",
    "    data=da_time_mean,\n",
    "    dims=(\"cloud_id\",),\n",
    "    data_std=da_time_sem,\n",
    ")\n",
    "da_cloud_mean = da_cloud_mean.compute()\n",
    "da_cloud_sem = da_cloud_sem.compute()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(\n",
    "    da_time_mean,\n",
    "    bins=lwc_bins,\n",
    "    color=\"k\",\n",
    "    alpha=0.5,\n",
    "    density=False,\n",
    ")\n",
    "ax.axvline(\n",
    "    da_cloud_mean,\n",
    "    color=\"darkorange\",\n",
    "    label=f\"Mean: {da_cloud_mean.values:.2f} $\\pm$ {da_cloud_sem.values:.2f} \"\n",
    "    + label_from_attrs(da, return_name=False),\n",
    ")\n",
    "\n",
    "ax.fill_betweenx(\n",
    "    ylim,\n",
    "    da_cloud_mean - 2 * da_cloud_sem,\n",
    "    da_cloud_mean + 2 * da_cloud_sem,\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    "    label=\"2 SEM\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(da))\n",
    "ax.set_ylabel(\"Occurence\")\n",
    "ax.set_title(f\"Histogram of {label_from_attrs(da, return_units=False).lower()} in surface layer\")\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim([lwc_bins[0], lwc_bins[-1]])\n",
    "\n",
    "fig.savefig(fig_dir / \"liquid_water_content_histogram_surface.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation.sel(time=time_slice)\n",
    "ylim = (0, 15)\n",
    "da = 1e6 * data[\"liquid_water_content\"].sum(\"radius_bins\")\n",
    "da.attrs[\"units\"] = \"$mg m^{-3}$\"\n",
    "da.attrs[\"long_name\"] = \"Liquid water content\"\n",
    "\n",
    "da = xr.concat(\n",
    "    [da.sel(gridbox=0), da.sel(gridbox=data[\"max_gridbox\"] - 2)],\n",
    "    dim=\"layer\",\n",
    ")\n",
    "\n",
    "da_raw_time_mean, da_raw_time_sem = mean_and_stderror_of_mean(\n",
    "    data=da,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "\n",
    "# the total difference\n",
    "da_time_mean = da_raw_time_mean.sel(layer=1) - da_raw_time_mean.sel(layer=0)\n",
    "da_time_sem: xr.DataArray = np.sqrt(\n",
    "    da_raw_time_sem.sel(layer=1) ** 2 + da_raw_time_sem.sel(layer=0) ** 2\n",
    ")\n",
    "da_time_mean = da_time_mean.compute()\n",
    "da_time_sem = da_time_sem.compute()\n",
    "\n",
    "# # the fractional\n",
    "# da_time_mean = 100 * da_raw_time_mean.sel(layer = 0) / da_raw_time_mean.sel(layer = 1)\n",
    "# da_time_mean = da_time_mean.compute()\n",
    "# da_time_sem = 100 * np.sqrt(\n",
    "#     da_time_mean**2 * (\n",
    "#         (da_raw_time_sem.sel(layer = 1) / da_raw_time_mean.sel(layer = 1))**2\n",
    "#         + (da_raw_time_sem.sel(layer = 0) / da_raw_time_mean.sel(layer = 0))**2\n",
    "#         )\n",
    "#     )\n",
    "# da_time_sem : xr.DataArray = da_time_sem\n",
    "# da_time_sem = da_time_sem.compute()\n",
    "\n",
    "\n",
    "da_cloud_mean, da_cloud_sem = mean_and_stderror_of_mean(\n",
    "    data=da_time_mean,\n",
    "    dims=(\"cloud_id\",),\n",
    "    data_std=da_time_sem,\n",
    ")\n",
    "\n",
    "da_cloud_mean = da_cloud_mean.compute()\n",
    "da_cloud_sem = da_cloud_sem.compute()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(\n",
    "    da_time_mean,\n",
    "    bins=20,\n",
    "    color=\"k\",\n",
    "    alpha=0.5,\n",
    "    density=False,\n",
    ")\n",
    "ax.axvline(\n",
    "    da_cloud_mean,\n",
    "    color=\"darkorange\",\n",
    "    label=f\"Mean: {da_cloud_mean.values:.1f} $\\pm$ {da_cloud_sem.values:.1f} \"\n",
    "    + label_from_attrs(da, return_name=False),\n",
    ")\n",
    "\n",
    "ax.fill_betweenx(\n",
    "    ylim,\n",
    "    da_cloud_mean - 2 * da_cloud_sem,\n",
    "    da_cloud_mean + 2 * da_cloud_sem,\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    "    label=\"2 SEM\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Difference in \" + label_from_attrs(da))\n",
    "ax.set_ylabel(\"Occurence\")\n",
    "ax.set_title(f\"Difference in LWC top sub cloud layer to surface\")\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylim(ylim)\n",
    "fig.savefig(fig_dir / \"liquid_water_content_histogram_diff_total.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1047.03182537)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.cov(da_raw_time_mean.sel(layer=1), da_raw_time_mean.sel(layer=0), dim=\"cloud_id\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation.sel(time=time_slice)\n",
    "ylim = (0, 30)\n",
    "\n",
    "da = 1e6 * data[\"liquid_water_content\"].sum(\"radius_bins\")\n",
    "da.attrs[\"units\"] = \"$mg m^{-3}$\"\n",
    "da.attrs[\"long_name\"] = \"Liquid water content\"\n",
    "\n",
    "da = xr.concat(\n",
    "    [da.sel(gridbox=0), da.sel(gridbox=data[\"max_gridbox\"] - 2)],\n",
    "    dim=\"layer\",\n",
    ")\n",
    "\n",
    "da_raw_time_mean, da_raw_time_sem = mean_and_stderror_of_mean(\n",
    "    data=da,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "\n",
    "# # the total difference\n",
    "# da_time_mean = da_raw_time_mean.sel(layer = 1) - da_raw_time_mean.sel(layer = 0)\n",
    "# da_time_sem : xr.DataArray = np.sqrt(da_raw_time_sem.sel(layer = 1)**2 + da_raw_time_sem.sel(layer = 0)**2)\n",
    "# da_time_mean = da_time_mean.compute()\n",
    "# da_time_sem = da_time_sem.compute()\n",
    "\n",
    "# the fractional\n",
    "da_time_mean = 100 * da_raw_time_mean.sel(layer=0) / da_raw_time_mean.sel(layer=1)\n",
    "da_time_mean = da_time_mean.compute()\n",
    "da_time_sem = 100 * np.sqrt(\n",
    "    da_time_mean**2\n",
    "    * (\n",
    "        (da_raw_time_sem.sel(layer=1) / da_raw_time_mean.sel(layer=1)) ** 2\n",
    "        + (da_raw_time_sem.sel(layer=0) / da_raw_time_mean.sel(layer=0)) ** 2\n",
    "        - 2\n",
    "        * xr.cov(da_raw_time_mean.sel(layer=1), da_raw_time_mean.sel(layer=0), dim=\"cloud_id\")\n",
    "        / (da_raw_time_mean.sel(layer=1) * da_raw_time_mean.sel(layer=0))\n",
    "    )\n",
    ")\n",
    "da_time_sem: xr.DataArray = da_time_sem\n",
    "da_time_sem = da_time_sem.compute()\n",
    "\n",
    "\n",
    "da_cloud_mean, da_cloud_sem = mean_and_stderror_of_mean(\n",
    "    data=da_time_mean,\n",
    "    dims=(\"cloud_id\",),\n",
    "    data_std=da_time_sem,\n",
    ")\n",
    "\n",
    "da_cloud_mean = da_cloud_mean.compute()\n",
    "da_cloud_sem = da_cloud_sem.compute()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(\n",
    "    da_time_mean,\n",
    "    bins=20,\n",
    "    color=\"k\",\n",
    "    alpha=0.5,\n",
    "    density=False,\n",
    ")\n",
    "ax.axvline(\n",
    "    da_cloud_mean,\n",
    "    color=\"darkorange\",\n",
    "    label=f\"Mean: {da_cloud_mean.values:.1f} $\\pm$ {da_cloud_sem.values:.1f} \" + \"[%]\",\n",
    ")\n",
    "\n",
    "ax.fill_betweenx(\n",
    "    ylim,\n",
    "    da_cloud_mean - 2 * da_cloud_sem,\n",
    "    da_cloud_mean + 2 * da_cloud_sem,\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    "    label=\"2 SEM\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Fraction in [%]\")\n",
    "ax.set_ylabel(\"Occurence\")\n",
    "ax.set_title(f\"Fraction of liquid water content reaching the surface\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "ax.set_ylim(ylim)\n",
    "fig.savefig(fig_dir / \"liquid_water_content_histogram_diff_fraction.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to ATR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_composite = xr.open_dataset(\n",
    "    \"/home/m/m301096/repositories/sdm-eurec4a/data/observation/cloud_composite/processed/cloud_composite_si_units.nc\"\n",
    ")\n",
    "identified_clouds = xr.open_dataset(\n",
    "    \"/home/m/m301096/repositories/sdm-eurec4a/data/observation/cloud_composite/processed/identified_clusters/identified_clusters_rain_mask_5.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdm_eurec4a.identifications import match_clouds_and_cloudcomposite, select_individual_cloud_by_id\n",
    "\n",
    "\n",
    "# match_clouds_and_cloudcomposite(\n",
    "#     ds_clouds = identified_clouds,\n",
    "#     ds_cloudcomposite = cloud_composite,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwc_means = []\n",
    "lwc_sems = []\n",
    "lwc_datas = dict()\n",
    "\n",
    "for cloud_id in condensation[\"cloud_id\"]:\n",
    "    da = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "    start = da[\"start\"].values[0]\n",
    "    end = da[\"end\"].values[0]\n",
    "    ds_match = cloud_composite.sel(time=slice(start, end))\n",
    "    lwc = ds_match[\"liquid_water_content_original\"]\n",
    "    lwc_mean, lwc_sem = mean_and_stderror_of_mean(\n",
    "        data=lwc,\n",
    "        dims=(\"time\",),\n",
    "    )\n",
    "    lwc_mean = lwc_mean.compute()\n",
    "    lwc_sem = lwc_sem.compute()\n",
    "\n",
    "    lwc_mean = lwc_mean.expand_dims(dim=dict(cloud_id=[cloud_id]))\n",
    "    lwc_sem = lwc_sem.expand_dims(dim=dict(cloud_id=[cloud_id]))\n",
    "    lwc = lwc.expand_dims(dim=dict(cloud_id=[cloud_id])).drop(\"time\")\n",
    "\n",
    "    lwc_means.append(lwc_mean)\n",
    "    lwc_sems.append(lwc_sem)\n",
    "    lwc_datas[str(cloud_id.values)] = lwc\n",
    "\n",
    "lwc_mean = xr.concat(lwc_means, dim=\"cloud_id\")\n",
    "lwc_sem = xr.concat(lwc_sems, dim=\"cloud_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_composite_lwc_mean, cloud_composite_lwc_sem = lwc_mean, lwc_sem\n",
    "cleo_lwc = 1e3 * condensation[\"liquid_water_content\"].sel(gridbox=condensation[\"max_gridbox\"]).sel(\n",
    "    time=time_slice\n",
    ").sum(\"radius_bins\", keep_attrs=True)\n",
    "cleo_lwc_mean, cleo_lwc_sem = mean_and_stderror_of_mean(\n",
    "    data=cleo_lwc,\n",
    "    dims=(\"time\",),\n",
    ")\n",
    "cleo_lwc_mean = cleo_lwc_mean.compute()\n",
    "cleo_lwc_sem = cleo_lwc_sem.compute()\n",
    "\n",
    "cleo_lwc_mean.attrs.update(units=\"$g m^{-3}$\", long_name=\"CLEO Liquid water content\")\n",
    "cloud_composite_lwc_mean.attrs.update(units=\"$g m^{-3}$\", long_name=\"ATR Liquid water content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface LWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.errorbar(\n",
    "    x=cleo_lwc_mean,\n",
    "    y=cloud_composite_lwc_mean,\n",
    "    xerr=2 * cleo_lwc_sem,\n",
    "    yerr=2 * cloud_composite_lwc_sem,\n",
    "    linestyle=\"None\",\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot([0, 1], [0, 1], color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(label_from_attrs(cleo_lwc_mean))\n",
    "ax.set_ylabel(label_from_attrs(cloud_composite_lwc_mean))\n",
    "fig.suptitle(\"Liquid water content comparison\\nbetween CLEO and ATR\")\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "ax.set_box_aspect(1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"lwc_comparison_cleo_atr.svg\")\n",
    "ax.set_xlim(0, 0.6)\n",
    "ax.set_ylim(0, 0.6)\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"lwc_comparison_cleo_atr_zoom.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_datas = dict()\n",
    "\n",
    "for cloud_id in null_microphysics[\"cloud_id\"]:\n",
    "    da = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "    start = da[\"start\"].values[0]\n",
    "    end = da[\"end\"].values[0]\n",
    "    ds_match = cloud_composite.sel(time=slice(start, end))\n",
    "    psd = ds_match[\"particle_size_distribution\"]\n",
    "    psd = psd.expand_dims(dim=dict(cloud_id=[cloud_id])).drop(\"time\")\n",
    "\n",
    "    psd_datas[str(cloud_id.values)] = psd\n",
    "\n",
    "cleo_psd_mean = (\n",
    "    condensation[\"xi_per_volume\"]\n",
    "    .sel(gridbox=condensation[\"max_gridbox\"])\n",
    "    .sel(time=time_slice)\n",
    "    .mean(\"time\", keep_attrs=True)\n",
    "    .compute()\n",
    ")\n",
    "cleo_psd_init = (\n",
    "    condensation[\"xi_per_volume\"].sel(gridbox=condensation[\"max_gridbox\"]).sel(time=0).compute()\n",
    ")\n",
    "cleo_psd_init_nmp = (\n",
    "    null_microphysics[\"xi_per_volume\"]\n",
    "    .sel(gridbox=null_microphysics[\"max_gridbox\"])\n",
    "    .sel(time=0)\n",
    "    .compute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdm_eurec4a.input_processing import transfer\n",
    "import lmfit\n",
    "from sdm_eurec4a.reductions import shape_dim_as_dataarray\n",
    "\n",
    "\n",
    "def fit_particle_size_distribution(\n",
    "    ds_cloudcomposite: xr.Dataset,\n",
    "    particle_split_radius: float = 45e-6,  # 45 micrometer\n",
    ") -> transfer.PSD_LnNormal:\n",
    "    \"\"\"\n",
    "    Fits the particle size distribution (PSD) of cloud and rain droplets\n",
    "    idependently.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    The PSD is fitted with a bimodal Lognormal distribution.\n",
    "    For the cloud droplets, the PSD is fitted with\n",
    "    - geometric mean between 0.1 micrometer and the split radius.\n",
    "    - geometric sigma between 0 and 1.7.\n",
    "    For the rain droplets, the PSD is fitted with\n",
    "    - geometric mean within the range of radius values provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_cloudcomposite : xr.Dataset\n",
    "        Dataset containing the cloud composite data.\n",
    "    particle_split_radius : float, optional\n",
    "        The radius at which to split the data into cloud and rain droplets. Default is 45 micrometers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    psd_fit : transfer.PSD_LnNormal\n",
    "        The fitted particle size distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into cloud and rain\n",
    "    ds_small_droplets = ds_cloudcomposite.sel(radius=slice(None, particle_split_radius))\n",
    "    ds_rain_droplets = ds_cloudcomposite.sel(radius=slice(particle_split_radius, None))\n",
    "\n",
    "    # ======================================\n",
    "    # Fit the PSDs\n",
    "    # ======================================\n",
    "\n",
    "    # Use the PSD_LnNormal model\n",
    "    psd_rain_fit = transfer.PSD_LnNormal()\n",
    "    psd_cloud_fit = transfer.PSD_LnNormal()\n",
    "\n",
    "    # ---------\n",
    "    # Rain\n",
    "    # ---------\n",
    "    data = ds_rain_droplets\n",
    "    radi2d = shape_dim_as_dataarray(da=data, output_dim=\"radius\")\n",
    "    psd_model = psd_rain_fit.get_model()\n",
    "\n",
    "    # update geometric mean to be within range of the data\n",
    "    psd_rain_fit.update_individual_model_parameters(\n",
    "        lmfit.Parameter(\n",
    "            name=\"geometric_means\",\n",
    "            min=data[\"radius\"].min().data,\n",
    "            max=data[\"radius\"].max().data,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # fit model parameters and update them\n",
    "    model_result = psd_model.fit(\n",
    "        data=data.data, radii=radi2d.data, params=psd_rain_fit.get_model_parameters(), nan_policy=\"omit\"\n",
    "    )\n",
    "    psd_rain_fit.lmfitParameterValues_to_dict(model_result.params)\n",
    "\n",
    "    # ---------\n",
    "    # Small cloud and drizzle\n",
    "    # ---------\n",
    "    # For this, the parameters need to be updated\n",
    "\n",
    "    # update geometric mean to be within range of 0.1 micrometer and the split radius\n",
    "    psd_cloud_fit.update_individual_model_parameters(\n",
    "        lmfit.Parameter(\n",
    "            name=\"geometric_means\",\n",
    "            value=1e-5,\n",
    "            min=0.1e-6,  # at least 0.1 micrometer\n",
    "            max=particle_split_radius,  # at most the split radius (default 45 micrometer)\n",
    "        )\n",
    "    )\n",
    "    # update geometric sigma to be within range of 0 and 1.7.\n",
    "    # NOTE: No real physical meaning, but it is a good range for the fit\n",
    "    psd_cloud_fit.update_individual_model_parameters(\n",
    "        lmfit.Parameter(\n",
    "            name=\"geometric_sigmas\",\n",
    "            value=1.1,\n",
    "            min=0,\n",
    "            max=1.7,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    data = ds_small_droplets\n",
    "    radi2d = shape_dim_as_dataarray(da=data, output_dim=\"radius\")\n",
    "    psd_model = psd_cloud_fit.get_model()\n",
    "\n",
    "    # fit model parameters and update them\n",
    "    model_result = psd_model.fit(\n",
    "        data=data.data, radii=radi2d.data, params=psd_cloud_fit.get_model_parameters(), nan_policy=\"omit\"\n",
    "    )\n",
    "    psd_cloud_fit.lmfitParameterValues_to_dict(model_result.params)\n",
    "\n",
    "    # --------\n",
    "    # Combine the fits\n",
    "    # --------\n",
    "\n",
    "    psd_fit = psd_rain_fit + psd_cloud_fit\n",
    "\n",
    "    return psd_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdm_eurec4a.visulization import ncols_nrows_from_N\n",
    "from sdm_eurec4a.input_processing.transfer import fit_lnnormal_for_psd, fit_2lnnormal_for_psd\n",
    "from sdm_eurec4a.conversions import lwc_from_psd\n",
    "\n",
    "\n",
    "np.random.seed(879345)\n",
    "random_cloud_ids = np.random.choice(condensation[\"cloud_id\"], 9, replace=False)\n",
    "\n",
    "psd_fits = dict()\n",
    "lwc_fits = dict()\n",
    "for cloud_id in random_cloud_ids:\n",
    "    cloud_id_str = str(cloud_id)\n",
    "    psd = psd_datas[cloud_id_str]\n",
    "    psd = psd.where(psd != 0, drop=True)\n",
    "    psd = psd.mean(\"cloud_id\")\n",
    "    psd_fit = fit_particle_size_distribution(\n",
    "        ds_cloudcomposite=psd,\n",
    "    )\n",
    "    psd_fits[cloud_id_str] = psd_fit\n",
    "\n",
    "    psd_fit = psd_fits[cloud_id_str].eval_func(psd[\"radius\"])\n",
    "\n",
    "from sdm_eurec4a.conversions import lwc_from_psd\n",
    "\n",
    "lwc_cleo_init = 1e3 * lwc_from_psd(\n",
    "    ds=xr.Dataset(data_vars=dict(particle_size_distribution=cleo_psd_init)),\n",
    "    sum_dim=\"radius_bins\",\n",
    "    scale_name=\"radius_bins\",\n",
    "    scale_factor=1e-6,\n",
    ")\n",
    "lwc_cleo_init.attrs.update(units=\"$g m^{-3}$\", long_name=\"CLEO Liquid water content\")\n",
    "# calculate LWC\n",
    "for cloud_id in random_cloud_ids:\n",
    "    cloud_id_str = str(cloud_id)\n",
    "    psd = psd_datas[cloud_id_str]\n",
    "    psd_fit = psd_fits[cloud_id_str].eval_func(psd[\"radius\"])\n",
    "\n",
    "    lwc_fit = 1e3 * lwc_from_psd(xr.Dataset(data_vars=dict(particle_size_distribution=psd_fit)))\n",
    "    lwc_fits[cloud_id_str] = lwc_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    figsize=(15, 15),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    **ncols_nrows_from_N(len(random_cloud_ids)),\n",
    ")\n",
    "\n",
    "for idx, cloud_id in enumerate(random_cloud_ids):\n",
    "    cloud_id_str = str(cloud_id)\n",
    "    cc_psd = psd_datas[cloud_id_str].mean(\"cloud_id\")\n",
    "    psd_fit = psd_fits[cloud_id_str]\n",
    "\n",
    "    sel_cleo_psd_mean = cleo_psd_mean.sel(cloud_id=cloud_id)\n",
    "    sel_cleo_psd_init = cleo_psd_init.sel(cloud_id=cloud_id)\n",
    "    sel_cleo_psd_init_nmp = cleo_psd_init_nmp.sel(cloud_id=cloud_id)\n",
    "\n",
    "    lwc_cleo = lwc_cleo_init.sel(cloud_id=cloud_id)\n",
    "    lwc_fit = lwc_fits[cloud_id_str]\n",
    "    lwc_atr = cloud_composite_lwc_mean.sel(cloud_id=cloud_id)\n",
    "\n",
    "    ax = axs.flatten()[idx]\n",
    "\n",
    "    ax.plot(\n",
    "        1e6 * cc_psd[\"radius\"],\n",
    "        cc_psd,\n",
    "        marker=\"+\",\n",
    "        linestyle=\"None\",\n",
    "        color=\"grey\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        marker=\"+\",\n",
    "        linestyle=\"None\",\n",
    "        color=\"grey\",\n",
    "        alpha=1,\n",
    "        label=f\"ATR data {lwc_atr.values:.2f} $g m^{{-3}}$\",\n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        1e6 * cc_psd[\"radius\"],\n",
    "        psd_fit.eval_func(cc_psd[\"radius\"]),\n",
    "        linestyle=\"-\",\n",
    "        color=\"b\",\n",
    "        label=f\"ATR Fit {lwc_fit.values:.2f} $g m^{{-3}}$\",\n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        sel_cleo_psd_init[\"radius_bins\"],\n",
    "        sel_cleo_psd_init,\n",
    "        marker=\"x\",\n",
    "        linestyle=\"-\",\n",
    "        color=\"r\",\n",
    "        label=f\"CLEO init {lwc_cleo.values:.2f} $g m^{{-3}}$\",\n",
    "    )\n",
    "\n",
    "    # ax.plot(\n",
    "    #     sel_cleo_psd_mean[\"radius_bins\"],\n",
    "    #     sel_cleo_psd_mean,\n",
    "    #     marker = \"x\",\n",
    "    #     linestyle = \"-\",\n",
    "    #     color = \"r\",\n",
    "    #     label = f\"CLEO stationary\"\n",
    "    # )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Cloud ID: {cloud_id}\")\n",
    "\n",
    "\n",
    "ax = axs.flatten()[0]\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"symlog\", linthresh=1e0, linscale=1)\n",
    "ax.set_ylim(0, 1e8)\n",
    "\n",
    "for ax in axs[-1, :]:\n",
    "    ax.set_xlabel(\"Radius [µm]\")\n",
    "\n",
    "for ax in axs[:, 0]:\n",
    "    ax.set_ylabel(\"Number concentration $[\\# m^{-3} (log(\\mu m))^{-1}]$\")\n",
    "\n",
    "\n",
    "fig.savefig(fig_dir / \"comparison_psd_fit_and_lwc_cleo_atr.svg\")\n",
    "fig.savefig(fig_dir / \"comparison_psd_fit_and_lwc_cleo_atr.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LWC for all microphysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condensation\n",
      "collision_condensation\n",
      "coalbure_condensation_cke\n",
      "coalbure_condensation_large\n",
      "coalbure_condensation_small\n"
     ]
    }
   ],
   "source": [
    "datas = [\n",
    "    condensation,\n",
    "    collision_condensation,\n",
    "    coalbure_condensation_cke,\n",
    "    coalbure_condensation_large,\n",
    "    coalbure_condensation_small,\n",
    "]\n",
    "\n",
    "bins = np.arange(-500, 50, 2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "\n",
    "for data in datas:\n",
    "    mp = data.attrs[\"microphysics_short\"]\n",
    "    print(mp)\n",
    "    color = colors_dict[mp]\n",
    "\n",
    "    data = data.sel(time=time_slice)\n",
    "\n",
    "    lh_sum = (data[\"latent_heating_full\"] * data[\"gridbox_thickness\"]).sum(\"gridbox\")\n",
    "\n",
    "    lh_sum.attrs[\"units\"] = \"Wm^{-2}\"\n",
    "    lh_sum.attrs[\"long_name\"] = \"Column int. latent heating\"\n",
    "\n",
    "    lh_sum_time_mean, lh_sum_time_sem = mean_and_stderror_of_mean(\n",
    "        data=lh_sum,\n",
    "        dims=(\"time\",),\n",
    "    )\n",
    "    lh_sum_time_mean = lh_sum_time_mean.compute()\n",
    "    lh_sum_time_sem = lh_sum_time_sem.compute()\n",
    "\n",
    "    lh_sum_cloud_mean, lh_sum_cloud_sem = mean_and_stderror_of_mean(\n",
    "        data=lh_sum_time_mean,\n",
    "        dims=(\"cloud_id\",),\n",
    "        data_std=lh_sum_time_sem,\n",
    "    )\n",
    "    lh_sum_cloud_mean = lh_sum_cloud_mean.compute()\n",
    "    lh_sum_cloud_sem = lh_sum_cloud_sem.compute()\n",
    "\n",
    "    ax.hist(\n",
    "        lh_sum_time_mean,\n",
    "        bins=bins,\n",
    "        color=[0.85, 0.85, 0.85],\n",
    "        alpha=1,\n",
    "        density=True,\n",
    "        zorder=1,\n",
    "    )\n",
    "    ax.axvline(\n",
    "        lh_sum_cloud_mean,\n",
    "        color=color,\n",
    "        label=\"Mean\",\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    ax.fill_betweenx(\n",
    "        [0, 0.1],\n",
    "        lh_sum_cloud_mean - 2 * lh_sum_cloud_sem,\n",
    "        lh_sum_cloud_mean + 2 * lh_sum_cloud_sem,\n",
    "        color=color,\n",
    "        alpha=0.1,\n",
    "        label=\"2 SEM\",\n",
    "        zorder=2,\n",
    "    )\n",
    "\n",
    "    # ax.axvline(\n",
    "    #     lh_sum_time_mean.compute().median(\"cloud_id\"),\n",
    "    #     color=\"red\",\n",
    "    #     label=\"Median\",\n",
    "    #     linestyle = \"--\"\n",
    "    # )\n",
    "\n",
    "\n",
    "ax.set_xlabel(label_from_attrs(lh_sum))\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(f\"Histogram of {label_from_attrs(lh_sum, return_units=False)}\")\n",
    "\n",
    "ax.set_ylim(0, 0.065)\n",
    "\n",
    "ax.set_xlim(-100, -10)\n",
    "fig.savefig(fig_dir / \"histogram_column_integrated_latent_heating_all_microphysics.svg\")\n",
    "fig.savefig(fig_dir / \"histogram_column_integrated_latent_heating_all_microphysics.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of thermodynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``NOTE:`` \n",
    "\n",
    "**It is good to see, that the evaporation rates are in line with the literature**\n",
    "\n",
    "*... of 15–352 Wm−2 over a 700 m deep sub-cloud layer is equivalent to 2–50 K d−1 of evaporative cooling. This is comparable to the typical stratocumulus cloud-top radiative longwave cooling (4–10 K d−1) and with the rain evaporation cooling rate at cloud base in the marine sub-cloud stratocumulus deck of 2–20 K d−1 (shown in Wood, 2005).*\n",
    "([Sarkar et al., 2023, p. 12685](zotero://select/library/items/G2B2A8IK)) ([pdf](zotero://open-pdf/library/items/ZNPPEKFT?page=15&annotation=K6IIGBHX))\n",
    "\n",
    "We can see that the height of the cloud does alter the mean evaporation rate slightly. \n",
    "With more evaporation for lower clouds.\n",
    "Why this is the case, we do not yet know.\n",
    "But this can also be due to higher cloud beeing sampled at different days!\n",
    "\n",
    "In the end there seems to be no big correlation.\n",
    "\n",
    "BUT: certainly the height does play a big role in terms of total evaporated rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thermodynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condensation\n",
    "\n",
    "latent_heating = 1e3 * data[\"latent_heating\"]\n",
    "latent_heating.where(data[\"sub_cloud_layer_mask\"])\n",
    "latent_heating.attrs[\"long_name\"] = data[\"latent_heating\"].attrs[\"long_name\"]\n",
    "latent_heating.attrs[\"units\"] = \"m\" + data[\"latent_heating\"].attrs[\"units\"].replace(\"$\", \"\")\n",
    "\n",
    "\n",
    "latent_heating_anomaly = 1e3 * (\n",
    "    data[\"latent_heating\"] - data[\"latent_heating\"].mean(\"gridbox\", keep_attrs=True)\n",
    ")\n",
    "latent_heating_anomaly.attrs[\"long_name\"] = \"Latent heating vertical anomaly\"\n",
    "latent_heating_anomaly.attrs[\"units\"] = latent_heating.attrs[\"units\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (\n",
    "    data[\"mass_represented_per_volume\"]\n",
    "    .sum(\"radius_bins\")\n",
    "    .sel(time=time_slice)\n",
    "    .mean(\"time\", keep_attrs=True)\n",
    "    .astype(float)\n",
    ")\n",
    "m = m.where(data[\"sub_cloud_layer_mask\"]).compute()\n",
    "m_anomaly = m - m.mean(\"gridbox\", keep_attrs=True).compute()\n",
    "\n",
    "m_init_1d = m.sel(gridbox=data[\"max_gridbox\"] - 1).drop(\"gridbox\").compute()\n",
    "m_init = m_init_1d.expand_dims(gridbox=data[\"gridbox\"])\n",
    "\n",
    "rh = data[\"relative_humidity\"]\n",
    "rh = rh.where(data[\"sub_cloud_layer_mask\"]).compute()\n",
    "rh_anomaly = (rh - rh.mean(\"gridbox\")).compute()\n",
    "\n",
    "coord3 = data[\"gridbox_coord3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculat the slope of a linear regression for the relative humidity for all clouds\n",
    "\n",
    "\n",
    "def slope_intercept(x, y, **kwargs):\n",
    "    # print(f\"received {type(x)} shape: {x.shape}\")\n",
    "    # print(f\"received {type(y)} shape: {y.shape}\")\n",
    "    try:\n",
    "        idx = np.isfinite(x) & np.isfinite(y)\n",
    "        slope, intercept = np.polyfit(x[idx], y[idx], **kwargs)\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "    return slope, intercept\n",
    "\n",
    "\n",
    "rh_slopes, rh_inter = xr.apply_ufunc(\n",
    "    slope_intercept,\n",
    "    data[\"gridbox_coord3\"].chunk(dict(cloud_id=-1)).compute(),\n",
    "    rh.chunk(dict(cloud_id=-1)).compute(),\n",
    "    input_core_dims=[[\"gridbox\"], [\"gridbox\"]],\n",
    "    output_core_dims=[[], []],\n",
    "    exclude_dims={\"gridbox\"},\n",
    "    # output_sizes={\"slope\": 1, \"intercept\": 1},\n",
    "    # output_dtypes=[[float], [float]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    kwargs=dict(deg=1),\n",
    ")\n",
    "latent_heating_slopes, latent_heating_inter = xr.apply_ufunc(\n",
    "    slope_intercept,\n",
    "    data[\"gridbox_coord3\"].chunk(dict(cloud_id=-1)).compute(),\n",
    "    latent_heating.chunk(dict(cloud_id=-1)).compute(),\n",
    "    input_core_dims=[[\"gridbox\"], [\"gridbox\"]],\n",
    "    output_core_dims=[[], []],\n",
    "    exclude_dims={\"gridbox\"},\n",
    "    # output_sizes={\"slope\": 1, \"intercept\": 1},\n",
    "    # output_dtypes=[[float], [float]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    kwargs=dict(deg=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot latent heating\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Latent heating anomalyagainst mass in gridbox and relative humidity')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pure\n",
    "print(\"plot latent heating\")\n",
    "fig, ax = plt.subplots(figsize=(10, 4.5))\n",
    "sc = ax.scatter(\n",
    "    m,\n",
    "    rh,\n",
    "    c=latent_heating,\n",
    "    marker=\".\",\n",
    "    alpha=0.8,\n",
    "    cmap=\"inferno\",\n",
    "    vmin=-100,\n",
    "    vmax=0,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(data[\"mass_represented_per_volume\"]))\n",
    "ax.set_ylabel(label_from_attrs(data[\"relative_humidity\"]))\n",
    "fig.colorbar(sc, ax=ax, label=label_from_attrs(latent_heating))\n",
    "\n",
    "fig.suptitle(\"Latent heating against mass in gridbox and relative humidity\")\n",
    "\n",
    "# Anolamy\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4.5))\n",
    "sc = ax.scatter(\n",
    "    m_anomaly,\n",
    "    rh_anomaly,\n",
    "    c=latent_heating_anomaly,\n",
    "    marker=\".\",\n",
    "    alpha=0.8,\n",
    "    cmap=\"RdBu\",\n",
    "    vmin=-30,\n",
    "    vmax=30,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(data[\"mass_represented_per_volume\"]))\n",
    "ax.set_ylabel(label_from_attrs(data[\"relative_humidity\"]))\n",
    "fig.colorbar(sc, ax=ax, label=label_from_attrs(latent_heating_anomaly))\n",
    "\n",
    "fig.suptitle(\"Latent heating anomalyagainst mass in gridbox and relative humidity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculat the slope of a linear regression for the relative humidity for all clouds\n",
    "\n",
    "\n",
    "def slope_intercept(x, y, **kwargs):\n",
    "    # print(f\"received {type(x)} shape: {x.shape}\")\n",
    "    # print(f\"received {type(y)} shape: {y.shape}\")\n",
    "    try:\n",
    "        idx = np.isfinite(x) & np.isfinite(y)\n",
    "        slope, intercept = np.polyfit(x[idx], y[idx], **kwargs)\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "    return slope, intercept\n",
    "\n",
    "\n",
    "rh_slopes, rh_inter = xr.apply_ufunc(\n",
    "    slope_intercept,\n",
    "    data[\"gridbox_coord3\"].chunk(dict(cloud_id=-1)).compute(),\n",
    "    rh.chunk(dict(cloud_id=-1)).compute(),\n",
    "    input_core_dims=[[\"gridbox\"], [\"gridbox\"]],\n",
    "    output_core_dims=[[], []],\n",
    "    exclude_dims={\"gridbox\"},\n",
    "    # output_sizes={\"slope\": 1, \"intercept\": 1},\n",
    "    # output_dtypes=[[float], [float]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    kwargs=dict(deg=1),\n",
    ")\n",
    "latent_heating_slopes, latent_heating_inter = xr.apply_ufunc(\n",
    "    slope_intercept,\n",
    "    data[\"gridbox_coord3\"].chunk(dict(cloud_id=-1)).compute(),\n",
    "    latent_heating.chunk(dict(cloud_id=-1)).compute(),\n",
    "    input_core_dims=[[\"gridbox\"], [\"gridbox\"]],\n",
    "    output_core_dims=[[], []],\n",
    "    exclude_dims={\"gridbox\"},\n",
    "    # output_sizes={\"slope\": 1, \"intercept\": 1},\n",
    "    # output_dtypes=[[float], [float]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    kwargs=dict(deg=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varibles = [rh_slopes, m_init_1d]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 6), ncols=2)\n",
    "\n",
    "for i, var in enumerate(varibles):\n",
    "    axs[i].scatter(\n",
    "        var,\n",
    "        latent_heating_slopes,\n",
    "        marker=\".\",\n",
    "        alpha=0.5,\n",
    "        label=\"Individual clouds\",\n",
    "    )\n",
    "    linear_fit_plot(\n",
    "        ax=axs[i],\n",
    "        x=var,\n",
    "        y=latent_heating_slopes,\n",
    "    )\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(latent_heating))\n",
    "    axs[i].set_title(f\"{label_from_attrs(latent_heating)} against {label_from_attrs(var)}\")\n",
    "    axs[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varibles = [rh_slopes, m_init_1d]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 6), ncols=2)\n",
    "\n",
    "for i, var in enumerate(varibles):\n",
    "    axs[i].scatter(\n",
    "        var,\n",
    "        latent_heating_slopes,\n",
    "        marker=\".\",\n",
    "        alpha=0.5,\n",
    "        label=\"Individual clouds\",\n",
    "    )\n",
    "    linear_fit_plot(\n",
    "        ax=axs[i],\n",
    "        x=var,\n",
    "        y=latent_heating_slopes,\n",
    "    )\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(latent_heating))\n",
    "    axs[i].set_title(f\"{label_from_attrs(latent_heating)} against {label_from_attrs(var)}\")\n",
    "    axs[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varibles = [rh, m]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 6), ncols=2)\n",
    "\n",
    "for i, var in enumerate(varibles):\n",
    "    axs[i].scatter(\n",
    "        var,\n",
    "        latent_heating,\n",
    "        marker=\".\",\n",
    "        alpha=0.5,\n",
    "        label=\"Individual clouds\",\n",
    "    )\n",
    "    linear_fit_plot(\n",
    "        ax=axs[i],\n",
    "        x=var,\n",
    "        y=latent_heating,\n",
    "    )\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(latent_heating))\n",
    "    axs[i].set_title(f\"{label_from_attrs(latent_heating)} against {label_from_attrs(var)}\")\n",
    "    axs[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "varibles = [rh_slopes, m_init_1d]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 6), ncols=2)\n",
    "\n",
    "for i, var in enumerate(varibles):\n",
    "    x = var.data\n",
    "    y = latent_heating_slopes.values\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    X = np.column_stack((x,))\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "\n",
    "    pred_ols = results.get_prediction()\n",
    "    iv_l = pred_ols.summary_frame()[\"obs_ci_lower\"]\n",
    "    iv_u = pred_ols.summary_frame()[\"obs_ci_upper\"]\n",
    "\n",
    "    axs[i].plot(x, y, \"o\", label=\"data\")\n",
    "    axs[i].plot(x, results.fittedvalues, \"r-\", label=\"OLS\")\n",
    "    axs[i].plot(x, iv_u, \"r:\")\n",
    "    axs[i].plot(x, iv_l, \"r:\")\n",
    "    axs[i].legend(loc=\"best\")\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(latent_heating_slopes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "varibles = [rh, m]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 6), ncols=2)\n",
    "\n",
    "for i, var in enumerate(varibles):\n",
    "    x = var.values\n",
    "    y = latent_heating.values\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    idx = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    X = np.column_stack((x,))\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "\n",
    "    pred_ols = results.get_prediction()\n",
    "    iv_l = pred_ols.summary_frame()[\"obs_ci_lower\"]\n",
    "    iv_u = pred_ols.summary_frame()[\"obs_ci_upper\"]\n",
    "\n",
    "    axs[i].plot(x, y, \"o\", label=\"data\")\n",
    "    axs[i].plot(x, results.fittedvalues, \"r-\", label=\"OLS\")\n",
    "    axs[i].plot(x, iv_u, \"r:\")\n",
    "    axs[i].plot(x, iv_l, \"r:\")\n",
    "    axs[i].legend(loc=\"best\")\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(latent_heating_slopes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "varibles = [\n",
    "    rh,\n",
    "    m,\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 6), ncols=3)\n",
    "\n",
    "for i, var in enumerate(varibles):\n",
    "    x = var.values\n",
    "    y = latent_heating_anomaly.values\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    idx = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    X = np.column_stack((x,))\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "\n",
    "    pred_ols = results.get_prediction()\n",
    "    iv_l = pred_ols.summary_frame()[\"obs_ci_lower\"]\n",
    "    iv_u = pred_ols.summary_frame()[\"obs_ci_upper\"]\n",
    "\n",
    "    axs[i].scatter(x, y, marker=\".\", label=\"data\")\n",
    "    axs[i].plot(x, results.fittedvalues, \"r-\", label=\"OLS\")\n",
    "    axs[i].plot(x, iv_u, \"r:\")\n",
    "    axs[i].plot(x, iv_l, \"r:\")\n",
    "    axs[i].legend(loc=\"best\")\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(latent_heating_slopes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "varibles = [rh_anomaly, m_anomaly]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 6), ncols=2)\n",
    "\n",
    "for i, var in enumerate(varibles):\n",
    "    x = var.values\n",
    "    y = latent_heating_anomaly.values\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    idx = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    X = np.column_stack((x,))\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "\n",
    "    pred_ols = results.get_prediction()\n",
    "    iv_l = pred_ols.summary_frame()[\"obs_ci_lower\"]\n",
    "    iv_u = pred_ols.summary_frame()[\"obs_ci_upper\"]\n",
    "\n",
    "    axs[i].scatter(x, y, marker=\".\", label=\"data\")\n",
    "    axs[i].plot(x, results.fittedvalues, \"r-\", label=\"OLS\")\n",
    "    axs[i].plot(x, iv_u, \"r:\")\n",
    "    axs[i].plot(x, iv_l, \"r:\")\n",
    "    axs[i].legend(loc=\"best\")\n",
    "    axs[i].set_xlabel(label_from_attrs(var))\n",
    "    axs[i].set_ylabel(label_from_attrs(latent_heating_slopes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ffe642306e0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we want to analyse the realtion of the latent heating slope to :\n",
    "# 1. the relative humidity slope\n",
    "# 2. the initial mass in the gridbox\n",
    "\n",
    "# further the correlation coefficients will be calcultaed and a linear regression will be performed\n",
    "# the linear regression shall be plotted with its uncertainty\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(14, 5), ncols=2)\n",
    "\n",
    "axs[0].scatter(\n",
    "    rh_slopes,\n",
    "    latent_heating_slopes,\n",
    "    # linestyle = '-',\n",
    "    # marker=\".\",\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "axs[1].scatter(\n",
    "    m_init_1d,\n",
    "    latent_heating_slopes,\n",
    "    # linestyle = '-',\n",
    "    # marker=\".\",\n",
    "    alpha=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 2.644 ± 0.234\n",
      "Intercept: -0.016 ± 0.002\n",
      "R-squared: 0.670\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Example data\n",
    "x = rh_slopes\n",
    "y = latent_heating_slopes\n",
    "\n",
    "# sort by x\n",
    "idx = np.argsort(x)\n",
    "x = x.data[idx]\n",
    "y = y.data[idx]\n",
    "\n",
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "# Calculate the regression line\n",
    "regression_line = slope * x + intercept\n",
    "\n",
    "# Calculate the uncertainty (standard error)\n",
    "slope_uncertainty = std_err\n",
    "intercept_uncertainty = std_err * np.sqrt(np.sum((x - np.mean(x)) ** 2) / len(x))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, label=\"Data points\")\n",
    "plt.plot(x, regression_line, color=\"red\", label=\"Linear regression\")\n",
    "plt.fill_between(\n",
    "    x,\n",
    "    regression_line - slope_uncertainty,\n",
    "    regression_line + slope_uncertainty,\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    "    label=\"Uncertainty\",\n",
    ")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.title(\"Linear Regression with Uncertainty\")\n",
    "plt.show()\n",
    "print(f\"Slope: {slope:.3f} ± {slope_uncertainty:.3f}\")\n",
    "print(f\"Intercept: {intercept:.3f} ± {intercept_uncertainty:.3f}\")\n",
    "print(f\"R-squared: {r_value**2:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7ffe244d7a10>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(x, regression_line + slope_uncertainty)\n",
    "plt.fill_betweenx(x, regression_line - slope_uncertainty, regression_line - slope_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ffe441e2840>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(14, 5), ncols=2)\n",
    "\n",
    "axs[0].scatter(\n",
    "    rh_anomaly,\n",
    "    latent_heating_anomaly,\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "axs[1].scatter(\n",
    "    m_init.T,\n",
    "    latent_heating_anomaly,\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4981414062727827\n",
      "0.8972324609381398\n",
      "30.123976579476608\n",
      "-0.37322667649540714\n",
      "0.008303319842886014\n",
      "0.008303319842886013\n"
     ]
    }
   ],
   "source": [
    "print(xr.corr(rh, latent_heating).values)\n",
    "print(xr.corr(rh_anomaly, latent_heating_anomaly).values)\n",
    "print(xr.cov(rh, latent_heating_anomaly).values)\n",
    "print(xr.cov(m, latent_heating).values)\n",
    "print(xr.cov(m_anomaly, latent_heating_anomaly).values)\n",
    "print(xr.cov(m, latent_heating_anomaly).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.03129359)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.corr(\n",
    "    m,\n",
    "    latent_heating_anomaly,\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "ax.scatter(\n",
    "    condensation[\"relative_humidity\"],\n",
    "    condensation[\"latent_heating\"],\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(condensation[\"relative_humidity\"]))\n",
    "ax.set_ylabel(label_from_attrs(condensation[\"latent_heating\"]))\n",
    "fig.suptitle(\"Latent heating rate vs. relative humidity\")\n",
    "fig.savefig(fig_dir / \"latent_heating_against_humidity.svg\")\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "ax.scatter(\n",
    "    condensation[\"mass_represented_per_volume\"].sum(\"radius_bins\").sel(time=time_slice).mean(\"time\"),\n",
    "    condensation[\"latent_heating\"],\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(condensation[\"mass_represented_per_volume\"]))\n",
    "ax.set_ylabel(label_from_attrs(condensation[\"latent_heating\"]))\n",
    "fig.suptitle(\"Latent heating rate vs. mass\")\n",
    "fig.savefig(fig_dir / \"latent_heating_against_mass.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "\n",
    "latent_heating_anomaly = condensation[\"latent_heating\"] - condensation[\"latent_heating\"].mean(\n",
    "    \"gridbox\", keep_attrs=True\n",
    ")\n",
    "latent_heating_anomaly.attrs[\"long_name\"] = \"Latent heating anomaly\"\n",
    "latent_heating_anomaly.attrs[\"units\"] = condensation[\"latent_heating\"].attrs[\"units\"]\n",
    "\n",
    "ax.scatter(\n",
    "    condensation[\"relative_humidity\"],\n",
    "    latent_heating_anomaly,\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(condensation[\"relative_humidity\"]))\n",
    "ax.set_ylabel(label_from_attrs(latent_heating_anomaly))\n",
    "fig.suptitle(\"Latent heating anomaly vs. relative humidity\")\n",
    "fig.savefig(fig_dir / \"latent_heating_anomaly_against_humidity.svg\")\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "ax.scatter(\n",
    "    condensation[\"mass_represented_per_volume\"].sum(\"radius_bins\").sel(time=time_slice).mean(\"time\"),\n",
    "    latent_heating_anomaly,\n",
    "    marker=\".\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xlabel(label_from_attrs(condensation[\"mass_represented_per_volume\"]))\n",
    "ax.set_ylabel(label_from_attrs(latent_heating_anomaly))\n",
    "fig.suptitle(\"Latent heating anomaly vs. mass\")\n",
    "fig.savefig(fig_dir / \"latent_heating_anomaly_against_mass.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdm_eurec4a_env312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
