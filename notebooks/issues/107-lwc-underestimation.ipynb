{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import lmfit\n",
    "from typing import Union, List, Tuple\n",
    "\n",
    "from sdm_eurec4a.visulization import (\n",
    "    set_custom_rcParams,\n",
    ")\n",
    "from sdm_eurec4a.identifications import select_individual_cloud_by_id, match_clouds_and_cloudcomposite\n",
    "\n",
    "from sdm_eurec4a.reductions import mean_and_stderror_of_mean\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "default_colors = set_custom_rcParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def random_integers_sum_to_n(parts, n):\n",
    "    \"\"\"\n",
    "    Divide an integer n into a given number of diverse/random non-zero integers.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): The integer to be divided.\n",
    "    parts (int): The number of parts to divide the integer into.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of integers that sum up to n.\n",
    "    \"\"\"\n",
    "    if parts > n:\n",
    "        raise ValueError(\"Number of parts cannot be greater than the integer itself.\")\n",
    "\n",
    "    # Generate random break points\n",
    "    break_points = sorted(random.sample(range(1, n), parts - 1))\n",
    "    print(break_points)\n",
    "\n",
    "    # Create the parts by calculating the differences between break points\n",
    "    result = [b - a for a, b in zip([0] + break_points, break_points + [n])]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_normal_distribution(\n",
    "    x: np.ndarray, scale_factor: float, geometric_mean: float, geometric_sigma: float\n",
    ") -> np.ndarray:\n",
    "    sigtilda = np.log(geometric_sigma)\n",
    "    mutilda = np.log(geometric_mean)\n",
    "\n",
    "    norm = scale_factor / (np.sqrt(2 * np.pi) * sigtilda)\n",
    "    exponent = -((np.log(x) - mutilda) ** 2) / (2 * sigtilda**2)\n",
    "\n",
    "    dn_dlnr = norm * np.exp(exponent)  # eq.5.8 [lohmann intro 2 clouds]\n",
    "\n",
    "    return dn_dlnr\n",
    "\n",
    "\n",
    "def normal_distribution(x, mu, sigma, scale_factor):\n",
    "    return scale_factor * 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n",
    "\n",
    "\n",
    "def diff_same_size(x: np.ndarray):\n",
    "    \"\"\"\n",
    "    This function gives you the width between x values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate differences between consecutive x values\n",
    "    diffs = np.diff(x)\n",
    "\n",
    "    # Initialize dx array with zeros\n",
    "    dx = np.zeros_like(x)\n",
    "\n",
    "    # For each x value (except the first and last), calculate the average of the differences with its neighbors\n",
    "    dx[1:-1] = (diffs[:-1] + diffs[1:]) / 2\n",
    "\n",
    "    # For the first and last x values, use linear interpolation\n",
    "    dx[0] = diffs[0]\n",
    "    dx[-1] = diffs[-1]\n",
    "\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create minimum problem example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 1. 1. 3. 1. 2. 1.]\n",
      "[2. 1. 3. 3. 1. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "class TestData:\n",
    "    def __init__(\n",
    "        self,\n",
    "        x: Union[np.ndarray, List, Tuple],\n",
    "        y: Union[np.ndarray, List, Tuple],\n",
    "        dx: Union[np.ndarray, List, Tuple],\n",
    "        name: str = \"\",\n",
    "    ):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.dx = dx\n",
    "\n",
    "        self.y_normalized = self.y / self.dx\n",
    "        self.name = name\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.__dict__[key]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.__dict__[key] = value\n",
    "\n",
    "    def resample(self, width: np.ndarray) -> \"TestData\":\n",
    "        \"\"\"\n",
    "        Resample the data in non uniform intervals given by width array\n",
    "        The width array elements need to sum up to the length of the data array\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        width: array\n",
    "            array with the width of the intervals\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        TestData object with resampled data\n",
    "        \"\"\"\n",
    "\n",
    "        assert np.sum(width) == len(self.x)\n",
    "\n",
    "        end = np.cumsum(width)\n",
    "        start = end - width\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        dx = []\n",
    "        for i, (s, e) in enumerate(zip(start, end)):\n",
    "\n",
    "            x.append(np.mean(self.x[s:e]))\n",
    "            y.append(np.sum(self.y[s:e]))\n",
    "            dx.append(np.sum(self.dx[s:e]))\n",
    "\n",
    "        return TestData(np.array(x), np.array(y), np.array(dx))\n",
    "\n",
    "    def normalize(self) -> \"TestData\":\n",
    "        \"\"\"\n",
    "        Normalize the data by dividing the y values by the dx values\n",
    "        \"\"\"\n",
    "        return TestData(\n",
    "            x=self.x,\n",
    "            y=self.y / self.dx,\n",
    "            dx=self.dx,\n",
    "        )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}\\nx: {self.x},\\ny: {self.y},\\ndx: {self.dx}\"\n",
    "\n",
    "    def plot_bar(self, ax=None, normalized=False, **kwargs):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        x = self.x\n",
    "        dx = self.dx\n",
    "\n",
    "        if normalized:\n",
    "            y = self.y_normalized\n",
    "        else:\n",
    "            y = self.y\n",
    "\n",
    "        ax.bar(x=x, height=y, width=dx, **kwargs)\n",
    "        # ax.scatter(\n",
    "        #     x,\n",
    "        #     y,\n",
    "        #     marker = 'x',\n",
    "        #     color = kwargs.get('edgecolor', 'black'),\n",
    "        #     )\n",
    "        return ax\n",
    "\n",
    "    def plot_scatter(self, ax=None, normalized=False, **kwargs):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        x = self.x\n",
    "        dx = self.dx\n",
    "\n",
    "        if normalized:\n",
    "            y = self.y_normalized\n",
    "        else:\n",
    "            y = self.y\n",
    "\n",
    "        ax.scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            # marker = 'o',\n",
    "            **kwargs,\n",
    "        )\n",
    "        # ax.scatter(\n",
    "        #     x,\n",
    "        #     y,\n",
    "        #     marker = 'x',\n",
    "        #     color = kwargs.get('edgecolor', 'black'),\n",
    "        #     )\n",
    "        return ax\n",
    "\n",
    "    @property\n",
    "    def fit_result(self):\n",
    "        return self._fit_result\n",
    "\n",
    "    @fit_result.setter\n",
    "    def fit_result(self, fit_result):\n",
    "        self._fit_result = fit_result\n",
    "\n",
    "    @fit_result.getter\n",
    "    def fit_result(self):\n",
    "        return self._fit_result\n",
    "\n",
    "\n",
    "# set up normal distribution with observations in equal intervals\n",
    "x_equal = np.arange(-6, 7, 1, dtype=float)\n",
    "dx_equal = np.full_like(a=x_equal, fill_value=x_equal[1] - x_equal[0])\n",
    "y_equal = norm.pdf(x_equal)\n",
    "\n",
    "td1 = TestData(x_equal, y_equal, dx_equal, name=\"equal\")\n",
    "\n",
    "# resample data in non uniform intervals\n",
    "width = np.array((2, 1, 1, 1, 1, 3, 1, 2, 1))\n",
    "td2 = td1.resample(width)\n",
    "td2.name = \"uneq.1\"\n",
    "\n",
    "# resample data in non uniform intervals\n",
    "width = np.array((2, 1, 3, 3, 1, 2, 1))\n",
    "td3 = td1.resample(width)\n",
    "td3.name = \"uneq.2\"\n",
    "\n",
    "\n",
    "td1_normalized = td1.normalize()\n",
    "td2_normalized = td2.normalize()\n",
    "td3_normalized = td3.normalize()\n",
    "\n",
    "for td in (td1_normalized, td2_normalized, td3_normalized):\n",
    "    print(td.dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'probability')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), sharex=True, sharey=True)\n",
    "ax = axs[0]\n",
    "ax_norm = axs[1]\n",
    "\n",
    "style = dict(\n",
    "    # color = 'None',\n",
    "    alpha=0.8,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "markers = [\"o\", \"x\", \"s\"]\n",
    "for i, td in enumerate([td1, td2, td3]):\n",
    "    td.plot_scatter(\n",
    "        ax=ax,\n",
    "        normalized=False,\n",
    "        label=td.name,\n",
    "        marker=markers[i],\n",
    "        # edgecolor = default_colors[i],\n",
    "        color=default_colors[i],\n",
    "        **style,\n",
    "    )\n",
    "\n",
    "for i, td in enumerate([td1_normalized, td2_normalized, td3_normalized]):\n",
    "    td.plot_bar(\n",
    "        ax=ax_norm, normalized=True, label=td.name, edgecolor=default_colors[i], color=\"None\", **style\n",
    "    )\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xlabel(\"x\")\n",
    "    _ax.legend()\n",
    "\n",
    "ax.set_title(\"normal distribution\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "ax_norm.set_title(\"normal distribution\\nnormalized by bin width\")\n",
    "ax_norm.set_ylabel(\"probability\")\n",
    "\n",
    "# ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(x, mu, sigma, scale_factor):\n",
    "    return scale_factor * 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n",
    "\n",
    "\n",
    "lm_mod = lmfit.Model(normal_distribution, independent_vars=(\"x\",))\n",
    "\n",
    "params = lmfit.Parameters()\n",
    "params.add(\"scale_factor\", value=1)\n",
    "params.add(\"mu\", value=2)\n",
    "params.add(\"sigma\", value=2)\n",
    "\n",
    "# fit the log nornmal distribution to the data of all three TestData objects\n",
    "for td in (td1, td2, td3, td1_normalized, td2_normalized, td3_normalized):\n",
    "    td.fit_result = lm_mod.fit(data=td.y, x=td.x, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'probability')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 3.5), sharex=True, sharey=True)\n",
    "ax = axs[0]\n",
    "ax_norm = axs[1]\n",
    "\n",
    "x = np.arange(-6, 6, 0.1)\n",
    "for td in (td1, td2, td3):\n",
    "    # make sure to use the same color for data and fit\n",
    "    lines = ax.plot(td.x, td.y, \"o\")\n",
    "    color = lines[0].get_color()\n",
    "    ax.plot(x, td.fit_result.eval(x=x), color=color)\n",
    "\n",
    "for td in (td1_normalized, td2_normalized, td3_normalized):\n",
    "    # make sure to use the same color for data and fit\n",
    "    lines = ax_norm.plot(td.x, td.y, \"o\")\n",
    "    color = lines[0].get_color()\n",
    "    ax_norm.plot(x, td.fit_result.eval(x=x), color=color)\n",
    "\n",
    "ax.set_title(\"normal distribution\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "ax_norm.set_title(\"normal distribution\\nnormalized by bin width\")\n",
    "ax_norm.set_ylabel(\"probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to maintain the Integral over the quantitiy with different x spacings\n",
    "\n",
    "The sum of the data is equal in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equal 1.0\n",
      "uneq.1 1.0\n",
      "uneq.2 1.0\n"
     ]
    }
   ],
   "source": [
    "assert td2.y.sum() == td1.y.sum() == td3.y.sum()\n",
    "for td in (td1, td2, td3):\n",
    "    print(f\"{td.name} {td.y.sum()/ td1.y.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the FITS using different x spacings does not give the same sum over the values.\n",
    "\n",
    "This needs to be solved.\n",
    "Ask Clara, how she did this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tequal\tuneq.1\tuneq.2\t\n",
      "equal\t[1.     0.5469 0.3005]\n",
      "uneq.1\t[1.9312 0.9871 0.7387]\n",
      "uneq.2\t[3.9657 2.249  1.0003]\n"
     ]
    }
   ],
   "source": [
    "top = \"\\t\"\n",
    "for td_x in (td1, td2, td3):\n",
    "    top += f\"{td_x.name}\\t\"\n",
    "print(top)\n",
    "\n",
    "result = np.zeros((3, 3))\n",
    "\n",
    "for i, td_x in enumerate((td1, td2, td3)):\n",
    "    for j, td_y in enumerate((td1, td2, td3)):\n",
    "        result[i, j] = np.sum(td_x.fit_result.eval(x=td_y.x))\n",
    "\n",
    "    print(f\"{td_x.name}\\t{np.round(result[i, :], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogNormal Case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 6, 7, 8, 9, 14, 15, 16, 18, 19, 38]\n",
      "[2, 13, 14, 15, 27, 33]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# set up normal distribution with observations in equal intervals\n",
    "x_equal = np.arange(-4, 6, 0.5, dtype=float)\n",
    "x_equal = np.arange(-4, 6, 0.25, dtype=float)\n",
    "x_equal = np.exp(x_equal)\n",
    "\n",
    "dx_equal = diff_same_size(x_equal)\n",
    "y_equal = ln_normal_distribution(x_equal, scale_factor=1, geometric_mean=1, geometric_sigma=2)\n",
    "\n",
    "td1_ln = TestData(x_equal, y_equal, dx_equal, name=\"equal\")\n",
    "\n",
    "# resample data in non uniform intervals\n",
    "\n",
    "N = len(x_equal)\n",
    "\n",
    "random.seed(42)\n",
    "width = random_integers_sum_to_n(14, N)\n",
    "td2_ln = td1_ln.resample(width)\n",
    "td2_ln.name = \"uneq.1\"\n",
    "\n",
    "# resample data in non uniform intervals\n",
    "\n",
    "width = random_integers_sum_to_n(7, N)\n",
    "td3_ln = td1_ln.resample(width)\n",
    "td3_ln.name = \"uneq.2\"\n",
    "\n",
    "\n",
    "td1_ln_normalized = td1_ln.normalize()\n",
    "td2_ln_normalized = td2_ln.normalize()\n",
    "td3_ln_normalized = td3_ln.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), sharex=True, sharey=True)\n",
    "ax = axs[0]\n",
    "ax_norm = axs[1]\n",
    "\n",
    "style = dict(\n",
    "    # color = 'None',\n",
    "    alpha=0.8,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "markers = [\"o\", \"x\", \"s\"]\n",
    "for i, td in enumerate([td1_ln, td2_ln, td3_ln]):\n",
    "    td.plot_scatter(\n",
    "        ax=ax,\n",
    "        normalized=False,\n",
    "        label=rf\"{td.name} $\\sum$ {td.y.sum():.2f}\",\n",
    "        # edgecolor = default_colors[i],\n",
    "        marker=markers[i],\n",
    "        color=default_colors[i],\n",
    "        **style,\n",
    "    )\n",
    "\n",
    "for i, td in enumerate([td1_ln_normalized, td2_ln_normalized, td3_ln_normalized]):\n",
    "    td.plot_scatter(\n",
    "        ax=ax_norm,\n",
    "        # normalized = True,\n",
    "        label=rf\"{td.name} $\\sum$ {td.y.sum():.2f}\",\n",
    "        marker=markers[i],\n",
    "        color=default_colors[i],\n",
    "        # color = \"None\",\n",
    "        **style,\n",
    "    )\n",
    "\n",
    "for _ax in axs.flatten():\n",
    "    _ax.set_xlabel(\"x\")\n",
    "    _ax.legend(loc=\"upper left\")\n",
    "\n",
    "ax.set_title(\"normal distribution\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "ax_norm.set_title(\"normal distribution\\nnormalized by bin width\")\n",
    "ax_norm.set_ylabel(\"probability\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_mod = lmfit.Model(ln_normal_distribution, independent_vars=(\"x\",))\n",
    "\n",
    "params = lmfit.Parameters()\n",
    "params.add(\"scale_factor\", value=1, min=0)\n",
    "params.add(\"geometric_mean\", value=3, min=0)\n",
    "params.add(\"geometric_sigma\", value=2, min=0)\n",
    "\n",
    "# fit the log nornmal distribution to the data of all three TestData objects\n",
    "for td in (\n",
    "    td1_ln,\n",
    "    td2_ln,\n",
    "    td3_ln,\n",
    "    td1_ln_normalized,\n",
    "    td2_ln_normalized,\n",
    "    td3_ln_normalized,\n",
    "):\n",
    "    try:\n",
    "        td.fit_result = lm_mod.fit(\n",
    "            data=td.y,\n",
    "            x=td.x,\n",
    "            # nan_policy='omit',\n",
    "            **params,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 3.5), sharex=True, sharey=True)\n",
    "ax = axs[0]\n",
    "ax_norm = axs[1]\n",
    "\n",
    "x = np.arange(-6, 6, 0.01)\n",
    "x = np.exp(x)\n",
    "for td in (td1_ln, td2_ln, td3_ln):\n",
    "    # make sure to use the same color for data and fit\n",
    "    lines = ax.plot(td.x, td.y, \"o\")\n",
    "    color = lines[0].get_color()\n",
    "    y = td.fit_result.eval(x=x)\n",
    "    ax.plot(x, y, color=color, label=rf\"{td.name} $\\sum$ {y.sum():.2f}\")\n",
    "\n",
    "for td in (td1_ln_normalized, td2_ln_normalized, td3_ln_normalized):\n",
    "    # make sure to use the same color for data and fit\n",
    "    lines = ax_norm.plot(td.x, td.y, \"o\")\n",
    "    color = lines[0].get_color()\n",
    "    y = td.fit_result.eval(x=x)\n",
    "    ax_norm.plot(x, y, color=color, label=rf\"{td.name} $\\sum$ {y.sum():.2f}\")\n",
    "\n",
    "ax.set_title(\"normal distribution\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "ax_norm.set_title(\"normal distribution\\nnormalized by bin width\")\n",
    "ax_norm.set_ylabel(\"probability\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")\n",
    "    _ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fff246e0320>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.exp(np.arange(-6, 6, 0.1))\n",
    "dx = diff_same_size(x)\n",
    "\n",
    "td = td1_ln\n",
    "ax.plot(td.x, td.y, \"o\", color=\"black\", label=rf\"original $\\sum$ {td.y.sum():.2f}\")\n",
    "\n",
    "\n",
    "for i, td_norm in enumerate((td1_ln_normalized, td2_ln_normalized, td3_ln_normalized)):\n",
    "\n",
    "    fit = td_norm.fit_result\n",
    "    y_ln = fit.eval(x=td.x) * td.dx\n",
    "    y = fit.eval(x=x) * dx\n",
    "\n",
    "    ax.plot(td.x, y_ln, \".\", color=default_colors[i], label=rf\"$\\sum$ {y_ln.sum():.2f}\")\n",
    "    ax.plot(x, y, \"x\", color=default_colors[i], label=rf\"$\\sum$ {y.sum():.2f}\")\n",
    "\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATR Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_composite = xr.open_dataset(\n",
    "    \"/home/m/m301096/repositories/sdm-eurec4a/data/observation/cloud_composite/processed/cloud_composite_si_units.nc\"\n",
    ")\n",
    "identified_clouds = xr.open_dataset(\n",
    "    \"/home/m/m301096/repositories/sdm-eurec4a/data/observation/cloud_composite/processed/identified_clusters/identified_clusters_rain_mask_5.nc\"\n",
    ")\n",
    "\n",
    "attrs = cloud_composite[\"radius\"].attrs.copy()\n",
    "attrs.update({\"units\": \"µm\"})\n",
    "cloud_composite[\"radius\"] = cloud_composite[\"radius\"]\n",
    "cloud_composite[\"radius_micro\"] = 1e6 * cloud_composite[\"radius\"]\n",
    "cloud_composite[\"radius\"].attrs = attrs\n",
    "\n",
    "# cloud_composite = cloud_composite.sel(radius = slice(10, None))\n",
    "\n",
    "identified_clouds = identified_clouds.where(\n",
    "    identified_clouds.duration.dt.total_seconds() > 100, drop=True\n",
    ")\n",
    "identified_clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_mod = lmfit.Model(normal_distribution, independent_vars=(\"x\",))\n",
    "params_rain = lmfit.Parameters()\n",
    "params_rain.add(\"mu\", value=np.log(300e-6), min=np.log(80e-6), max=np.log(2e-3))\n",
    "params_rain.add(\"scale_factor\", value=1, min=0)\n",
    "params_rain.add(\"sigma\", value=0.5, max=1)\n",
    "\n",
    "params_cloud = lmfit.Parameters()\n",
    "params_cloud.add(\"mu\", value=np.log(0.1e-6), min=np.log(10e-6), max=np.log(50e-6))\n",
    "params_cloud.add(\"scale_factor\", value=1e5, min=0)\n",
    "params_cloud.add(\"sigma\", value=0.5, max=1)\n",
    "\n",
    "RADIUS = cloud_composite[\"radius\"]\n",
    "\n",
    "\n",
    "# for cloud_id in identified_clouds.cloud_id:\n",
    "def fit_both(cloud_id):\n",
    "    da = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "    start = da[\"start\"].values[0]\n",
    "    end = da[\"end\"].values[0]\n",
    "    ds = cloud_composite.sel(time=slice(start, end))\n",
    "\n",
    "    ds[\"particle_size_distribution\"] = ds[\"particle_size_distribution\"] / ds[\"bin_width\"]\n",
    "\n",
    "    ds_rain = ds.sel(radius=slice(50e-6, None))\n",
    "    ds_cloud = ds.sel(radius=slice(None, 50e-6))\n",
    "\n",
    "    td_cloud = TestData(\n",
    "        x=np.log(ds_cloud[\"radius\"].expand_dims(time=ds.time).transpose(\"time\", \"radius\")),\n",
    "        y=ds_cloud[\"particle_size_distribution\"].transpose(\"time\", \"radius\"),\n",
    "        dx=ds_cloud[\"bin_width\"].expand_dims(time=ds.time).transpose(\"time\", \"radius\"),\n",
    "        name=\"cloud\",\n",
    "    )\n",
    "    td_rain = TestData(\n",
    "        x=np.log(ds_rain[\"radius\"].expand_dims(time=ds.time).transpose(\"time\", \"radius\")),\n",
    "        y=ds_rain[\"particle_size_distribution\"].transpose(\"time\", \"radius\"),\n",
    "        dx=ds_rain[\"bin_width\"].expand_dims(time=ds.time).transpose(\"time\", \"radius\"),\n",
    "        name=\"cloud\",\n",
    "    )\n",
    "\n",
    "    for td in (td_cloud, td_rain):\n",
    "\n",
    "        # td.x = td.x.mean('time')\n",
    "        # td.y = td.y.mean('time')\n",
    "        # td.dx = td.dx.mean('time')\n",
    "\n",
    "        td.x = td.x.values.flatten()\n",
    "        td.y = td.y.values.flatten()\n",
    "        td.dx = td.dx.values.flatten()\n",
    "        args = np.isfinite(td.y) & np.isfinite(td.x)\n",
    "        td.x = td.x[args]\n",
    "        td.y = td.y[args]\n",
    "        td.dx = td.dx[args]\n",
    "    # td.y = td.y * np.exp(td.x) ** 3\n",
    "\n",
    "    td_cloud.fit_result = lm_mod.fit(data=td_cloud.y, x=td_cloud.x, **params_cloud)\n",
    "    td_rain.fit_result = lm_mod.fit(data=td_rain.y, x=td_rain.x, **params_rain)\n",
    "    return td_cloud, td_rain\n",
    "\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id.values:\n",
    "    cloud_id_str = str(cloud_id)\n",
    "    try:\n",
    "        td_cloud, td_rain = fit_both(cloud_id)\n",
    "    except TypeError:\n",
    "        print(\"error in cloud_id\", cloud_id)\n",
    "    test_dict[cloud_id_str] = dict(\n",
    "        cloud=td_cloud,\n",
    "        rain=td_rain,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_id = np.random.choice(identified_clouds.cloud_id.values)\n",
    "# cloud_id = 356\n",
    "cloud_id_str = str(cloud_id)\n",
    "\n",
    "ds = match_clouds_and_cloudcomposite(\n",
    "    ds_clouds=select_individual_cloud_by_id(identified_clouds, cloud_id),\n",
    "    ds_cloudcomposite=cloud_composite,\n",
    ")\n",
    "radius = ds[\"radius\"]\n",
    "dx = ds[\"bin_width\"]\n",
    "psd = ds[\"particle_size_distribution\"]\n",
    "\n",
    "\n",
    "td_rain = test_dict[cloud_id_str][\"rain\"]\n",
    "x = np.log(radius)\n",
    "psd_fit = td_rain.fit_result.eval(x=x) * dx\n",
    "lwc_fit = 1000 * psd_fit * 4 / 3 * np.pi * RADIUS**3\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 3))\n",
    "ax.plot(psd.radius, psd, marker=\".\", linestyle=\"None\", color=\"k\", alpha=0.2)\n",
    "ax.plot(radius, psd_fit, color=\"r\", linestyle=\":\")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"symlog\", linthresh=1, linscale=0.1)\n",
    "ax.set_ylim(-1, None)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(7, 3), width_ratios=[1, 0.07])\n",
    "\n",
    "ax = axs[0]\n",
    "cax = axs[1]\n",
    "\n",
    "msd = psd * psd[\"radius\"] ** 3\n",
    "lwc = ds[\"liquid_water_content\"]\n",
    "\n",
    "pcm = ax.pcolormesh(\n",
    "    psd.time,\n",
    "    psd.radius,\n",
    "    1e9 * msd,\n",
    "    cmap=\"Blues\",\n",
    "    shading=\"nearest\",\n",
    "    vmin=0,\n",
    "    vmax=50,\n",
    ")\n",
    "fig.colorbar(pcm, cax=cax, label=\"MSD [mg/m³]\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Radius [µm]\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(lwc.time, 1e3 * lwc, color=\"black\", lw=2, linestyle=\":\")\n",
    "ax2.axhline(1e3 * lwc.mean(\"time\"), color=\"black\", lw=2, linestyle=\"-\")\n",
    "# ax2.fill_between(lwc.time,\n",
    "#                 1e3 * (lwc.mean('time') - lwc.std('time')),\n",
    "#                 1e3 * (lwc.mean('time') + lwc.std('time')),\n",
    "#                 color=\"black\",\n",
    "#                 alpha = 0.1\n",
    "#     )\n",
    "ax2.axhline(1e3 * lwc_fit.sum(), color=\"red\", lw=2)\n",
    "ax2.set_ylabel(\"LWC [g/m³]\")\n",
    "\n",
    "ax2.set_ylim(0, 2)\n",
    "\n",
    "fig.add_axes(ax2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id.values:\n",
    "\n",
    "    d = test_dict[str(cloud_id)]\n",
    "    td_cloud = d[\"cloud\"]\n",
    "    td_rain = d[\"rain\"]\n",
    "\n",
    "    radius = cloud_composite.radius\n",
    "\n",
    "    psd = td_cloud.fit_result.eval(x=np.log(radius)) + td_rain.fit_result.eval(x=np.log(radius))\n",
    "    msd = 1000 * 4 / 3 * np.pi * psd * radius**3\n",
    "    # msd_cumsum = ds['mass_size_distribution'].cumsum('radius')\n",
    "    psd_cumsum = np.cumsum(psd)\n",
    "    msd_cumsum = np.cumsum(msd)\n",
    "    msd_cumsum = msd_cumsum / msd_cumsum[-1]\n",
    "    psd_cumsum = psd_cumsum / psd_cumsum[-1]\n",
    "\n",
    "    ax.plot(\n",
    "        1e6 * radius,\n",
    "        msd_cumsum,\n",
    "        # marker = 'o',\n",
    "        color=\"blue\",\n",
    "    )\n",
    "\n",
    "    ax2.plot(\n",
    "        1e6 * radius,\n",
    "        psd_cumsum,\n",
    "        # marker = 'x',\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id:\n",
    "\n",
    "    dsi = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "\n",
    "    ds = cloud_composite.sel(time=slice(dsi.start.values[0], dsi.end.values[0]))\n",
    "\n",
    "    msd_cumsum = ds[\"mass_size_distribution\"].cumsum(\"radius\")\n",
    "    psd_cumsum = ds[\"particle_size_distribution\"].cumsum(\"radius\")\n",
    "\n",
    "    msd_cumsum = msd_cumsum / msd_cumsum.isel(radius=-1)\n",
    "    psd_cumsum = psd_cumsum / psd_cumsum.isel(radius=-1)\n",
    "\n",
    "    ax.plot(\n",
    "        1e6 * msd_cumsum.radius,\n",
    "        msd_cumsum.mean(\"time\"),\n",
    "        # marker = 'o',\n",
    "        color=\"blue\",\n",
    "    )\n",
    "\n",
    "    ax2.plot(\n",
    "        1e6 * psd_cumsum.radius,\n",
    "        psd_cumsum.mean(\"time\"),\n",
    "        # marker = 'x',\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id.values:\n",
    "\n",
    "    d = test_dict[str(cloud_id)]\n",
    "    td_cloud = d[\"cloud\"]\n",
    "    td_rain = d[\"rain\"]\n",
    "\n",
    "    radius = cloud_composite.radius\n",
    "\n",
    "    psd = td_cloud.fit_result.eval(x=np.log(radius)) + td_rain.fit_result.eval(x=np.log(radius))\n",
    "    msd = 1000 * 4 / 3 * np.pi * psd * radius**3\n",
    "    # msd_cumsum = ds['mass_size_distribution'].cumsum('radius')\n",
    "    psd_cumsum = np.cumsum(psd)\n",
    "    msd_cumsum = np.cumsum(msd)\n",
    "    msd_cumsum = msd_cumsum / msd_cumsum[-1]\n",
    "    psd_cumsum = psd_cumsum / psd_cumsum[-1]\n",
    "\n",
    "    ax.plot(\n",
    "        1e6 * radius,\n",
    "        msd_cumsum,\n",
    "        # marker = 'o',\n",
    "        color=\"blue\",\n",
    "    )\n",
    "\n",
    "    ax2.plot(\n",
    "        1e6 * radius,\n",
    "        psd_cumsum,\n",
    "        # marker = 'x',\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffed870e480>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id.values:\n",
    "\n",
    "    dsi = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "    ds = cloud_composite.sel(time=slice(dsi.start.values[0], dsi.end.values[0]))\n",
    "    radius = ds.radius\n",
    "\n",
    "    m_obs, s_obs = mean_and_stderror_of_mean(ds[\"mass_size_distribution\"].sum(\"radius\"), (\"time\",))\n",
    "\n",
    "    fit = test_dict[str(cloud_id)]\n",
    "    td_cloud = fit[\"cloud\"]\n",
    "    td_rain = fit[\"rain\"]\n",
    "\n",
    "    psd = td_rain.fit_result.eval(x=np.log(radius))\n",
    "    msd = 1000 * 4 / 3 * np.pi * psd * radius**3\n",
    "\n",
    "    m_fit, s_fit = np.sum(msd), 0\n",
    "\n",
    "    ax.errorbar(\n",
    "        x=1e3 * m_obs,\n",
    "        xerr=1e3 * s_obs,\n",
    "        y=1e3 * m_fit,\n",
    "        yerr=1e3 * s_fit,\n",
    "        marker=\"o\",\n",
    "    )\n",
    "\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 4)\n",
    "ax.plot(\n",
    "    ax.get_xlim(),\n",
    "    ax.get_ylim(),\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_id = np.random.choice(identified_clouds.cloud_id.values)\n",
    "# cloud_id = 273\n",
    "da = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "start = da[\"start\"].values[0]\n",
    "end = da[\"end\"].values[0]\n",
    "ds_match = cloud_composite.sel(time=slice(start, end)).sel(radius=slice(50e-6, None))\n",
    "\n",
    "lm_mod = lmfit.Model(normal_distribution, independent_vars=(\"x\",))\n",
    "params = lmfit.Parameters()\n",
    "params.add(\"scale_factor\", value=1)\n",
    "params.add(\"mu\", value=-8, min=-11, max=-5)\n",
    "params.add(\"sigma\", value=0.1, max=5)\n",
    "RADIUS = ds_match[\"radius\"]\n",
    "\n",
    "td_cloud = TestData(\n",
    "    x=np.log(ds_match[\"radius\"].expand_dims(time=ds_match.time).transpose(\"time\", \"radius\")),\n",
    "    y=ds_match[\"particle_size_distribution\"].transpose(\"time\", \"radius\"),\n",
    "    dx=ds_match[\"bin_width\"].expand_dims(time=ds_match.time).transpose(\"time\", \"radius\"),\n",
    "    name=\"cloud\",\n",
    ")\n",
    "\n",
    "\n",
    "td_cloud_mean = TestData(\n",
    "    x=np.log(ds_match[\"radius\"]),\n",
    "    y=ds_match[\"particle_size_distribution\"].mean(dim=\"time\"),\n",
    "    dx=ds_match[\"bin_width\"],\n",
    "    name=\"cloud\",\n",
    ")\n",
    "\n",
    "td_cloud_mean_norm = td_cloud_mean.normalize()\n",
    "\n",
    "for td in (td_cloud, td_cloud_mean, td_cloud_mean_norm):\n",
    "    td.x = td.x.values.flatten()\n",
    "    td.y = td.y.values.flatten()\n",
    "    td.dx = td.dx.values.flatten()\n",
    "\n",
    "    args = np.isfinite(td.y) & np.isfinite(td.x)\n",
    "    td.x = td.x[args]\n",
    "    td.y = td.y[args]\n",
    "    td.dx = td.dx[args]\n",
    "\n",
    "# plt.xscale('log')\n",
    "# fit the log nornmal distribution to the data of all three TestData objects\n",
    "\n",
    "for td in (td_cloud, td_cloud_mean, td_cloud_mean_norm):\n",
    "    td.fit_result = lm_mod.fit(data=td.y, x=td.x, **params)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 3))\n",
    "ax.scatter(\n",
    "    td_cloud.x,\n",
    "    td_cloud.y,\n",
    "    marker=\".\",\n",
    "    # color = 'b',\n",
    ")\n",
    "ax.scatter(\n",
    "    td_cloud_mean.x,\n",
    "    td_cloud_mean.y,\n",
    "    marker=\"o\",\n",
    "    # color = 'r',\n",
    ")\n",
    "\n",
    "# td_cloud.x = np.exp(td_cloud.x)\n",
    "\n",
    "x = np.arange(-12, -6, 0.1)\n",
    "ax.plot(x, td_cloud.fit_result.eval(x=x), color=\"r\")\n",
    "ax.plot(x, td_cloud_mean.fit_result.eval(x=x), color=\"b\", linestyle=\"--\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(x, td_cloud_mean_norm.fit_result.eval(x=x), color=\"g\", linestyle=\":\")\n",
    "\n",
    "psd_fit = td_cloud.fit_result.eval(x=np.log(RADIUS))\n",
    "lwc_fit = 1000 * psd_fit * 4 / 3 * np.pi * RADIUS**3\n",
    "# plt.xscale('log')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(7, 3), width_ratios=[1, 0.07])\n",
    "\n",
    "ax = axs[0]\n",
    "cax = axs[1]\n",
    "\n",
    "psd = ds_match[\"particle_size_distribution\"]\n",
    "msd = psd * psd[\"radius\"] ** 3\n",
    "lwc = ds_match[\"liquid_water_content\"]\n",
    "\n",
    "pcm = ax.pcolormesh(\n",
    "    psd.time,\n",
    "    psd.radius,\n",
    "    msd,\n",
    "    cmap=\"Blues\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Radius [µm]\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(lwc.time, 1e3 * lwc, color=\"black\", lw=2, linestyle=\":\")\n",
    "ax2.axhline(1e3 * lwc.mean(\"time\"), color=\"black\", lw=2, linestyle=\"-\")\n",
    "ax2.fill_between(\n",
    "    lwc.time,\n",
    "    1e3 * (lwc.mean(\"time\") - lwc.std(\"time\")),\n",
    "    1e3 * (lwc.mean(\"time\") + lwc.std(\"time\")),\n",
    "    color=\"black\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "ax2.axhline(1e3 * lwc_fit.sum(), color=\"red\", lw=2)\n",
    "ax2.set_ylabel(\"LWC [g/m³]\")\n",
    "\n",
    "fig.add_axes(ax2)\n",
    "\n",
    "fig.colorbar(pcm, cax=cax, label=\"MSD [µm³/m³]\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_observations = dict()\n",
    "\n",
    "for cloud_id in cloud_ids:\n",
    "    da = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "    start = da[\"start\"].values[0]\n",
    "    end = da[\"end\"].values[0]\n",
    "    ds_match = cloud_composite.sel(time=slice(start, end))\n",
    "\n",
    "    psd = ds_match[\"particle_size_distribution\"]\n",
    "    psd = psd.expand_dims(dim=dict(cloud_id=[cloud_id]))\n",
    "\n",
    "    psd_observations[str(cloud_id)] = psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwc_means = []\n",
    "lwc_sems = []\n",
    "lwc_observations = dict()\n",
    "\n",
    "for cloud_id in cloud_ids:\n",
    "\n",
    "    da = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "    start = da[\"start\"].values[0]\n",
    "    end = da[\"end\"].values[0]\n",
    "    ds_match = cloud_composite.sel(time=slice(start, end))\n",
    "\n",
    "    # Particle size distribution\n",
    "    psd = ds_match[\"particle_size_distribution\"]\n",
    "    psd = psd.expand_dims(dim=dict(cloud_id=[cloud_id]))\n",
    "    psd_observations[str(cloud_id)] = psd\n",
    "\n",
    "    # Liquid water content\n",
    "    lwc = ds_match[\"liquid_water_content_original\"]\n",
    "    lwc_mean, lwc_sem = mean_and_stderror_of_mean(\n",
    "        data=lwc,\n",
    "        dims=(\"time\",),\n",
    "    )\n",
    "    lwc_mean = lwc_mean.compute()\n",
    "    lwc_sem = lwc_sem.compute()\n",
    "\n",
    "    lwc_mean = lwc_mean.expand_dims(dim=dict(cloud_id=[cloud_id]))\n",
    "    lwc_sem = lwc_sem.expand_dims(dim=dict(cloud_id=[cloud_id]))\n",
    "    lwc = lwc.expand_dims(dim=dict(cloud_id=[cloud_id]))\n",
    "\n",
    "    lwc_means.append(lwc_mean)\n",
    "    lwc_sems.append(lwc_sem)\n",
    "    lwc_observations[str(cloud_id)] = lwc\n",
    "\n",
    "lwc_mean = xr.concat(lwc_means, dim=\"cloud_id\")\n",
    "lwc_sem = xr.concat(lwc_sems, dim=\"cloud_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'LWC [g/m³]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5), sharex=True)\n",
    "\n",
    "\n",
    "psd = psd_observations[str(cloud_ids[0])].mean(\"cloud_id\")\n",
    "msd = psd * psd[\"radius\"] ** 3\n",
    "lwc = lwc_observations[str(cloud_ids[0])].mean(\"cloud_id\")\n",
    "\n",
    "ax.pcolormesh(\n",
    "    psd.time,\n",
    "    psd.radius,\n",
    "    msd,\n",
    "    cmap=\"Reds\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Radius [µm]\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(lwc.time, lwc, color=\"black\", lw=2)\n",
    "ax2.set_ylabel(\"LWC [g/m³]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_particle_size_distribution(\n",
    "    ds_cloudcomposite: xr.Dataset,\n",
    "    particle_split_radius: float = 45,  # 45 micrometer\n",
    ") -> transfer.PSD_LnNormal:\n",
    "    \"\"\"\n",
    "    Fits the particle size distribution (PSD) of cloud and rain droplets\n",
    "    idependently.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    The PSD is fitted with a bimodal Lognormal distribution.\n",
    "    For the cloud droplets, the PSD is fitted with\n",
    "    - geometric mean between 0.1 micrometer and the split radius.\n",
    "    - geometric sigma between 0 and 1.7.\n",
    "    For the rain droplets, the PSD is fitted with\n",
    "    - geometric mean within the range of radius values provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_cloudcomposite : xr.Dataset\n",
    "        Dataset containing the cloud composite data.\n",
    "    particle_split_radius : float, optional\n",
    "        The radius at which to split the data into cloud and rain droplets. Default is 45 micrometers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    psd_fit : transfer.PSD_LnNormal\n",
    "        The fitted particle size distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into cloud and rain\n",
    "    ds_small_droplets = ds_cloudcomposite.sel(radius=slice(None, particle_split_radius))\n",
    "    ds_rain_droplets = ds_cloudcomposite.sel(radius=slice(particle_split_radius, None))\n",
    "\n",
    "    # ======================================\n",
    "    # Fit the PSDs\n",
    "    # ======================================\n",
    "\n",
    "    # Use the PSD_LnNormal model\n",
    "    psd_rain_fit = transfer.PSD_LnNormal()\n",
    "    psd_cloud_fit = transfer.PSD_LnNormal()\n",
    "\n",
    "    # ---------\n",
    "    # Rain\n",
    "    # ---------\n",
    "    data = ds_rain_droplets\n",
    "    radi2d = shape_dim_as_dataarray(da=data, output_dim=\"radius\")\n",
    "    psd_model = psd_rain_fit.get_model()\n",
    "\n",
    "    # update geometric mean to be within range of the data\n",
    "    psd_rain_fit.update_individual_model_parameters(\n",
    "        lmfit.Parameter(\n",
    "            name=\"geometric_means\",\n",
    "            min=data[\"radius\"].min().data,\n",
    "            max=data[\"radius\"].max().data,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # fit model parameters and update them\n",
    "    model_result = psd_model.fit(\n",
    "        data=data.data, radii=radi2d.data, params=psd_rain_fit.get_model_parameters(), nan_policy=\"omit\"\n",
    "    )\n",
    "    psd_rain_fit.lmfitParameterValues_to_dict(model_result.params)\n",
    "\n",
    "    # # ---------\n",
    "    # # Small cloud and drizzle\n",
    "    # # ---------\n",
    "    # # For this, the parameters need to be updated\n",
    "\n",
    "    # # update geometric mean to be within range of 0.1 micrometer and the split radius\n",
    "    # psd_cloud_fit.update_individual_model_parameters(\n",
    "    #     lmfit.Parameter(\n",
    "    #         name=\"geometric_means\",\n",
    "    #         value=1e-5 * 1e6,\n",
    "    #         min=0.1e-6 * 1e6,  # at least 0.1 micrometer\n",
    "    #         max=particle_split_radius,  # at most the split radius (default 45 micrometer)\n",
    "    #     )\n",
    "    # )\n",
    "    # # update geometric sigma to be within range of 0 and 1.7.\n",
    "    # # NOTE: No real physical meaning, but it is a good range for the fit\n",
    "    # psd_cloud_fit.update_individual_model_parameters(\n",
    "    #     lmfit.Parameter(\n",
    "    #         name=\"geometric_sigmas\",\n",
    "    #         value=1.1,\n",
    "    #         min=0,\n",
    "    #         max=1.7,\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    # data = ds_small_droplets\n",
    "    # radi2d = shape_dim_as_dataarray(da=data, output_dim=\"radius\")\n",
    "    # psd_model = psd_cloud_fit.get_model()\n",
    "    # # fit model parameters and update them\n",
    "    # model_result = psd_model.fit(\n",
    "    #     data=data.data, radii=radi2d.data, params=psd_cloud_fit.get_model_parameters(), nan_policy=\"omit\"\n",
    "    # )\n",
    "    # psd_cloud_fit.lmfitParameterValues_to_dict(model_result.params)\n",
    "\n",
    "    # # --------\n",
    "    # # Combine the fits\n",
    "    # # --------\n",
    "\n",
    "    psd_fit = psd_rain_fit  # + psd_cloud_fit\n",
    "\n",
    "    return psd_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.logspace(np.log10(psd[\"radius\"].min()), np.log10(psd[\"radius\"].max()), 100)\n",
    "radius_equal100 = xr.DataArray(\n",
    "    r,\n",
    "    dims=[\"radius\"],\n",
    "    coords=dict(\n",
    "        radius=r,\n",
    "    ),\n",
    ")\n",
    "\n",
    "r = np.logspace(-1, 10, 100)\n",
    "radius_equal100_min = xr.DataArray(\n",
    "    r,\n",
    "    dims=[\"radius\"],\n",
    "    coords=dict(\n",
    "        radius=r,\n",
    "    ),\n",
    ")\n",
    "\n",
    "r = np.logspace(np.log10(psd[\"radius\"].min()), np.log10(psd[\"radius\"].max()), 30)\n",
    "radius_equal30 = xr.DataArray(\n",
    "    r,\n",
    "    dims=[\"radius\"],\n",
    "    coords=dict(\n",
    "        radius=r,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "355\n",
      "221\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "psd_fit_funcs = dict()\n",
    "psd_fits = dict()\n",
    "psd_fits2 = dict()\n",
    "lwc_fits = dict()\n",
    "lwc_fits2 = dict()\n",
    "\n",
    "for cloud_id in cloud_ids:\n",
    "    cloud_id_str = str(cloud_id)\n",
    "    print(cloud_id_str)\n",
    "    psd = psd_observations[cloud_id_str]\n",
    "    # psd = psd.where(psd != 0, drop=False)\n",
    "    psd = psd.mean(\"cloud_id\")\n",
    "    psd_fit_func = fit_particle_size_distribution(\n",
    "        ds_cloudcomposite=psd,\n",
    "    )\n",
    "    psd_fit_funcs[cloud_id_str] = psd_fit_func\n",
    "\n",
    "    psd_fits[cloud_id_str] = psd_fit_func.eval_func(psd[\"radius\"])\n",
    "    psd_fits2[cloud_id_str] = psd_fit_func.eval_func(radius_equal30)\n",
    "\n",
    "\n",
    "for cloud_id in cloud_ids:\n",
    "    cloud_id_str = str(cloud_id)\n",
    "\n",
    "    psd_fit = psd_fits[cloud_id_str]\n",
    "    lwc_fit = 1e3 * lwc_from_psd(xr.Dataset(data_vars=dict(particle_size_distribution=psd_fit)))\n",
    "    lwc_fits[cloud_id_str] = lwc_fit\n",
    "\n",
    "    psd_fit = psd_fits2[cloud_id_str]\n",
    "    lwc_fit = 1e3 * lwc_from_psd(xr.Dataset(data_vars=dict(particle_size_distribution=psd_fit)))\n",
    "    lwc_fits2[cloud_id_str] = lwc_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    figsize=(6, 6),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    **ncols_nrows_from_N(len(cloud_ids)),\n",
    ")\n",
    "\n",
    "for idx, cloud_id in enumerate(cloud_ids):\n",
    "    cloud_id_str = str(cloud_id)\n",
    "\n",
    "    psd_obs = psd_observations[cloud_id_str].mean(\"cloud_id\")\n",
    "    lwc_obs = lwc_observations[cloud_id_str].mean(\"time\")\n",
    "\n",
    "    psd_fit = psd_fits[cloud_id_str]\n",
    "    lwc_fit = lwc_fits[cloud_id_str]\n",
    "\n",
    "    psd_fit2 = psd_fits2[cloud_id_str]\n",
    "    lwc_fit2 = lwc_fits2[cloud_id_str]\n",
    "\n",
    "    ax = axs.flatten()[idx]\n",
    "\n",
    "    ax.plot(\n",
    "        psd_fit[\"radius\"],\n",
    "        psd_fit,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        psd_fit2[\"radius\"],\n",
    "        psd_fit2,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        psd_obs[\"radius\"],\n",
    "        psd_obs,\n",
    "        marker=\".\",\n",
    "        color=\"grey\",\n",
    "        alpha=0.1,\n",
    "        linestyle=\"None\",\n",
    "    )\n",
    "\n",
    "    # ax.plot(\n",
    "    #     sel_cleo_psd_mean[\"radius_bins\"],\n",
    "    #     sel_cleo_psd_mean,\n",
    "    #     marker = \"x\",\n",
    "    #     linestyle = \"-\",\n",
    "    #     color = \"r\",\n",
    "    #     label = f\"CLEO stationary\"\n",
    "    # )\n",
    "\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.set_title(f\"Cloud ID: {cloud_id}\")\n",
    "\n",
    "\n",
    "ax = axs.flatten()[0]\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"symlog\", linthresh=1e0, linscale=1)\n",
    "ax.set_ylim(0, 1e8)\n",
    "\n",
    "for ax in axs[-1, :]:\n",
    "    ax.set_xlabel(\"Radius [µm]\")\n",
    "\n",
    "for ax in axs[:, 0]:\n",
    "    ax.set_ylabel(\"Number concentration $[m^{-3} (log(\\mu m))^{-1}]$\")\n",
    "\n",
    "add_subplotlabel(axs, location=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=1, nrows=3, figsize=(8, 8), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "psd = psd_observations[str(cloud_ids[0])].mean(\"cloud_id\")\n",
    "lwc = lwc_observations[str(cloud_ids[0])].mean(\"cloud_id\")\n",
    "\n",
    "psd_fit = psd_fits[str(cloud_ids[0])].expand_dims(time=psd.time)\n",
    "lwc_fit = lwc_fits[str(cloud_ids[0])].expand_dims(time=psd.time)\n",
    "\n",
    "psd_fit2 = psd_fits2[str(cloud_ids[0])].expand_dims(time=psd.time)\n",
    "lwc_fit2 = lwc_fits2[str(cloud_ids[0])].expand_dims(time=psd.time)\n",
    "\n",
    "axpsd = axs[0]\n",
    "axlwc = axpsd.twinx()\n",
    "\n",
    "axpsd.pcolormesh(\n",
    "    psd.time,\n",
    "    psd.radius,\n",
    "    psd,\n",
    "    cmap=\"Reds\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "axpsd.set_yscale(\"log\")\n",
    "axpsd.set_ylabel(\"Radius [µm]\")\n",
    "\n",
    "axlwc.plot(lwc.time, lwc, color=\"black\", lw=2)\n",
    "axlwc.set_ylabel(\"LWC [g/m³]\")\n",
    "\n",
    "\n",
    "axpsd = axs[1]\n",
    "axlwc = axpsd.twinx()\n",
    "\n",
    "axpsd.pcolormesh(\n",
    "    psd_fit.time,\n",
    "    psd_fit.radius,\n",
    "    psd_fit.T,\n",
    "    cmap=\"Reds\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "axpsd.set_yscale(\"log\")\n",
    "axpsd.set_ylabel(\"Radius [µm]\")\n",
    "\n",
    "axlwc.plot(lwc_fit.time, lwc_fit, color=\"black\", lw=2)\n",
    "axlwc.set_ylabel(\"LWC [g/m³]\")\n",
    "\n",
    "axpsd = axs[2]\n",
    "axlwc = axpsd.twinx()\n",
    "\n",
    "axpsd.pcolormesh(\n",
    "    psd_fit2.time,\n",
    "    psd_fit2.radius,\n",
    "    psd_fit2.T,\n",
    "    cmap=\"Reds\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "axpsd.set_yscale(\"log\")\n",
    "axpsd.set_ylabel(\"Radius [µm]\")\n",
    "\n",
    "axlwc.plot(lwc_fit2.time, lwc_fit2, color=\"black\", lw=2)\n",
    "axlwc.set_ylabel(\"LWC [g/m³]\")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    plt.colorbar(cax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_composite[\"radius\"].plot(marker=\".\", linestyle=\"None\")\n",
    "radius_equal30.plot(marker=\".\", linestyle=\"None\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdm_eurec4a_env312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
