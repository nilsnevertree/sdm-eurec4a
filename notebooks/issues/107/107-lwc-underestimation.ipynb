{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import lmfit\n",
    "from typing import Union, List, Tuple\n",
    "\n",
    "from sdm_eurec4a.visulization import (\n",
    "    set_custom_rcParams,\n",
    ")\n",
    "from sdm_eurec4a.identifications import select_individual_cloud_by_id, match_clouds_and_cloudcomposite\n",
    "\n",
    "from sdm_eurec4a.reductions import mean_and_stderror_of_mean\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "default_colors = set_custom_rcParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def random_integers_sum_to_n(parts, n):\n",
    "    \"\"\"\n",
    "    Divide an integer n into a given number of diverse/random non-zero integers.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): The integer to be divided.\n",
    "    parts (int): The number of parts to divide the integer into.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of integers that sum up to n.\n",
    "    \"\"\"\n",
    "    if parts > n:\n",
    "        raise ValueError(\"Number of parts cannot be greater than the integer itself.\")\n",
    "\n",
    "    # Generate random break points\n",
    "    break_points = sorted(random.sample(range(1, n), parts - 1))\n",
    "    print(break_points)\n",
    "\n",
    "    # Create the parts by calculating the differences between break points\n",
    "    result = [b - a for a, b in zip([0] + break_points, break_points + [n])]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_normal_distribution(\n",
    "    x: np.ndarray, scale_factor: float, geometric_mean: float, geometric_sigma: float\n",
    ") -> np.ndarray:\n",
    "    sigtilda = np.log(geometric_sigma)\n",
    "    mutilda = np.log(geometric_mean)\n",
    "\n",
    "    norm = scale_factor / (np.sqrt(2 * np.pi) * sigtilda)\n",
    "    exponent = -((np.log(x) - mutilda) ** 2) / (2 * sigtilda**2)\n",
    "\n",
    "    dn_dlnr = norm * np.exp(exponent)  # eq.5.8 [lohmann intro 2 clouds]\n",
    "\n",
    "    return dn_dlnr\n",
    "\n",
    "\n",
    "def normal_distribution(x, mu, sigma, scale_factor):\n",
    "    return scale_factor * 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n",
    "\n",
    "\n",
    "def diff_same_size(x: np.ndarray):\n",
    "    \"\"\"\n",
    "    This function gives you the width between x values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate differences between consecutive x values\n",
    "    diffs = np.diff(x)\n",
    "\n",
    "    # Initialize dx array with zeros\n",
    "    dx = np.zeros_like(x)\n",
    "\n",
    "    # For each x value (except the first and last), calculate the average of the differences with its neighbors\n",
    "    dx[1:-1] = (diffs[:-1] + diffs[1:]) / 2\n",
    "\n",
    "    # For the first and last x values, use linear interpolation\n",
    "    dx[0] = diffs[0]\n",
    "    dx[-1] = diffs[-1]\n",
    "\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create minimum problem example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 1. 1. 3. 1. 2. 1.]\n",
      "[2. 1. 3. 3. 1. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "class TestData:\n",
    "    def __init__(\n",
    "        self,\n",
    "        x: Union[np.ndarray, List, Tuple],\n",
    "        y: Union[np.ndarray, List, Tuple],\n",
    "        dx: Union[np.ndarray, List, Tuple],\n",
    "        name: str = \"\",\n",
    "    ):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.dx = dx\n",
    "\n",
    "        self.y_normalized = self.y / self.dx\n",
    "        self.name = name\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.__dict__[key]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.__dict__[key] = value\n",
    "\n",
    "    def resample(self, width: np.ndarray) -> \"TestData\":\n",
    "        \"\"\"\n",
    "        Resample the data in non uniform intervals given by width array\n",
    "        The width array elements need to sum up to the length of the data array\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        width: array\n",
    "            array with the width of the intervals\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        TestData object with resampled data\n",
    "        \"\"\"\n",
    "\n",
    "        assert np.sum(width) == len(self.x)\n",
    "\n",
    "        end = np.cumsum(width)\n",
    "        start = end - width\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        dx = []\n",
    "        for i, (s, e) in enumerate(zip(start, end)):\n",
    "\n",
    "            x.append(np.mean(self.x[s:e]))\n",
    "            y.append(np.sum(self.y[s:e]))\n",
    "            dx.append(np.sum(self.dx[s:e]))\n",
    "\n",
    "        return TestData(np.array(x), np.array(y), np.array(dx))\n",
    "\n",
    "    def normalize(self) -> \"TestData\":\n",
    "        \"\"\"\n",
    "        Normalize the data by dividing the y values by the dx values\n",
    "        \"\"\"\n",
    "        return TestData(\n",
    "            x=self.x,\n",
    "            y=self.y / self.dx,\n",
    "            dx=self.dx,\n",
    "        )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}\\nx: {self.x},\\ny: {self.y},\\ndx: {self.dx}\"\n",
    "\n",
    "    def plot_bar(self, ax=None, normalized=False, **kwargs):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        x = self.x\n",
    "        dx = self.dx\n",
    "\n",
    "        if normalized:\n",
    "            y = self.y_normalized\n",
    "        else:\n",
    "            y = self.y\n",
    "\n",
    "        ax.bar(x=x, height=y, width=dx, **kwargs)\n",
    "        # ax.scatter(\n",
    "        #     x,\n",
    "        #     y,\n",
    "        #     marker = 'x',\n",
    "        #     color = kwargs.get('edgecolor', 'black'),\n",
    "        #     )\n",
    "        return ax\n",
    "\n",
    "    def plot_scatter(self, ax=None, normalized=False, **kwargs):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        x = self.x\n",
    "        dx = self.dx\n",
    "\n",
    "        if normalized:\n",
    "            y = self.y_normalized\n",
    "        else:\n",
    "            y = self.y\n",
    "\n",
    "        ax.scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            # marker = 'o',\n",
    "            **kwargs,\n",
    "        )\n",
    "        # ax.scatter(\n",
    "        #     x,\n",
    "        #     y,\n",
    "        #     marker = 'x',\n",
    "        #     color = kwargs.get('edgecolor', 'black'),\n",
    "        #     )\n",
    "        return ax\n",
    "\n",
    "    @property\n",
    "    def fit_result(self):\n",
    "        return self._fit_result\n",
    "\n",
    "    @fit_result.setter\n",
    "    def fit_result(self, fit_result):\n",
    "        self._fit_result = fit_result\n",
    "\n",
    "    @fit_result.getter\n",
    "    def fit_result(self):\n",
    "        return self._fit_result\n",
    "\n",
    "\n",
    "# set up normal distribution with observations in equal intervals\n",
    "x_equal = np.arange(-6, 7, 1, dtype=float)\n",
    "dx_equal = np.full_like(a=x_equal, fill_value=x_equal[1] - x_equal[0])\n",
    "y_equal = norm.pdf(x_equal)\n",
    "\n",
    "td1 = TestData(x_equal, y_equal, dx_equal, name=\"equal\")\n",
    "\n",
    "# resample data in non uniform intervals\n",
    "width = np.array((2, 1, 1, 1, 1, 3, 1, 2, 1))\n",
    "td2 = td1.resample(width)\n",
    "td2.name = \"uneq.1\"\n",
    "\n",
    "# resample data in non uniform intervals\n",
    "width = np.array((2, 1, 3, 3, 1, 2, 1))\n",
    "td3 = td1.resample(width)\n",
    "td3.name = \"uneq.2\"\n",
    "\n",
    "\n",
    "td1_normalized = td1.normalize()\n",
    "td2_normalized = td2.normalize()\n",
    "td3_normalized = td3.normalize()\n",
    "\n",
    "for td in (td1_normalized, td2_normalized, td3_normalized):\n",
    "    print(td.dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'probability')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), sharex=True, sharey=True)\n",
    "ax = axs[0]\n",
    "ax_norm = axs[1]\n",
    "\n",
    "style = dict(\n",
    "    # color = 'None',\n",
    "    alpha=0.8,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "markers = [\"o\", \"x\", \"s\"]\n",
    "for i, td in enumerate([td1, td2, td3]):\n",
    "    td.plot_scatter(\n",
    "        ax=ax,\n",
    "        normalized=False,\n",
    "        label=td.name,\n",
    "        marker=markers[i],\n",
    "        # edgecolor = default_colors[i],\n",
    "        color=default_colors[i],\n",
    "        **style,\n",
    "    )\n",
    "\n",
    "for i, td in enumerate([td1_normalized, td2_normalized, td3_normalized]):\n",
    "    td.plot_bar(\n",
    "        ax=ax_norm, normalized=True, label=td.name, edgecolor=default_colors[i], color=\"None\", **style\n",
    "    )\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xlabel(\"x\")\n",
    "    _ax.legend()\n",
    "\n",
    "ax.set_title(\"normal distribution\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "ax_norm.set_title(\"normal distribution\\nnormalized by bin width\")\n",
    "ax_norm.set_ylabel(\"probability\")\n",
    "\n",
    "# ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(x, mu, sigma, scale_factor):\n",
    "    return scale_factor * 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n",
    "\n",
    "\n",
    "lm_mod = lmfit.Model(normal_distribution, independent_vars=(\"x\",))\n",
    "\n",
    "params = lmfit.Parameters()\n",
    "params.add(\"scale_factor\", value=1)\n",
    "params.add(\"mu\", value=2)\n",
    "params.add(\"sigma\", value=2)\n",
    "\n",
    "# fit the log nornmal distribution to the data of all three TestData objects\n",
    "for td in (td1, td2, td3, td1_normalized, td2_normalized, td3_normalized):\n",
    "    td.fit_result = lm_mod.fit(data=td.y, x=td.x, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'probability')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 3.5), sharex=True, sharey=True)\n",
    "ax = axs[0]\n",
    "ax_norm = axs[1]\n",
    "\n",
    "x = np.arange(-6, 6, 0.1)\n",
    "for td in (td1, td2, td3):\n",
    "    # make sure to use the same color for data and fit\n",
    "    lines = ax.plot(td.x, td.y, \"o\")\n",
    "    color = lines[0].get_color()\n",
    "    ax.plot(x, td.fit_result.eval(x=x), color=color)\n",
    "\n",
    "for td in (td1_normalized, td2_normalized, td3_normalized):\n",
    "    # make sure to use the same color for data and fit\n",
    "    lines = ax_norm.plot(td.x, td.y, \"o\")\n",
    "    color = lines[0].get_color()\n",
    "    ax_norm.plot(x, td.fit_result.eval(x=x), color=color)\n",
    "\n",
    "ax.set_title(\"normal distribution\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "ax_norm.set_title(\"normal distribution\\nnormalized by bin width\")\n",
    "ax_norm.set_ylabel(\"probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to maintain the Integral over the quantitiy with different x spacings\n",
    "\n",
    "The sum of the data is equal in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equal 1.0\n",
      "uneq.1 1.0\n",
      "uneq.2 1.0\n"
     ]
    }
   ],
   "source": [
    "assert td2.y.sum() == td1.y.sum() == td3.y.sum()\n",
    "for td in (td1, td2, td3):\n",
    "    print(f\"{td.name} {td.y.sum()/ td1.y.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the FITS using different x spacings does not give the same sum over the values.\n",
    "\n",
    "This needs to be solved.\n",
    "Ask Clara, how she did this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tequal\tuneq.1\tuneq.2\t\n",
      "equal\t[1.     0.5469 0.3005]\n",
      "uneq.1\t[1.9312 0.9871 0.7387]\n",
      "uneq.2\t[3.9657 2.249  1.0003]\n"
     ]
    }
   ],
   "source": [
    "top = \"\\t\"\n",
    "for td_x in (td1, td2, td3):\n",
    "    top += f\"{td_x.name}\\t\"\n",
    "print(top)\n",
    "\n",
    "result = np.zeros((3, 3))\n",
    "\n",
    "for i, td_x in enumerate((td1, td2, td3)):\n",
    "    for j, td_y in enumerate((td1, td2, td3)):\n",
    "        result[i, j] = np.sum(td_x.fit_result.eval(x=td_y.x))\n",
    "\n",
    "    print(f\"{td_x.name}\\t{np.round(result[i, :], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogNormal Case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 6, 7, 8, 9, 14, 15, 16, 18, 19, 38]\n",
      "[2, 13, 14, 15, 27, 33]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# set up normal distribution with observations in equal intervals\n",
    "x_equal = np.arange(-4, 6, 0.5, dtype=float)\n",
    "x_equal = np.arange(-4, 6, 0.25, dtype=float)\n",
    "x_equal = np.exp(x_equal)\n",
    "\n",
    "dx_equal = diff_same_size(x_equal)\n",
    "y_equal = ln_normal_distribution(x_equal, scale_factor=1, geometric_mean=1, geometric_sigma=2)\n",
    "\n",
    "td1_ln = TestData(x_equal, y_equal, dx_equal, name=\"equal\")\n",
    "\n",
    "# resample data in non uniform intervals\n",
    "\n",
    "N = len(x_equal)\n",
    "\n",
    "random.seed(42)\n",
    "width = random_integers_sum_to_n(14, N)\n",
    "td2_ln = td1_ln.resample(width)\n",
    "td2_ln.name = \"uneq.1\"\n",
    "\n",
    "# resample data in non uniform intervals\n",
    "\n",
    "width = random_integers_sum_to_n(7, N)\n",
    "td3_ln = td1_ln.resample(width)\n",
    "td3_ln.name = \"uneq.2\"\n",
    "\n",
    "\n",
    "td1_ln_normalized = td1_ln.normalize()\n",
    "td2_ln_normalized = td2_ln.normalize()\n",
    "td3_ln_normalized = td3_ln.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), sharex=True, sharey=True)\n",
    "ax = axs[0]\n",
    "ax_norm = axs[1]\n",
    "\n",
    "style = dict(\n",
    "    # color = 'None',\n",
    "    alpha=0.8,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "markers = [\"o\", \"x\", \"s\"]\n",
    "for i, td in enumerate([td1_ln, td2_ln, td3_ln]):\n",
    "    td.plot_scatter(\n",
    "        ax=ax,\n",
    "        normalized=False,\n",
    "        label=rf\"{td.name} $\\sum$ {td.y.sum():.2f}\",\n",
    "        # edgecolor = default_colors[i],\n",
    "        marker=markers[i],\n",
    "        color=default_colors[i],\n",
    "        **style,\n",
    "    )\n",
    "\n",
    "for i, td in enumerate([td1_ln_normalized, td2_ln_normalized, td3_ln_normalized]):\n",
    "    td.plot_scatter(\n",
    "        ax=ax_norm,\n",
    "        # normalized = True,\n",
    "        label=rf\"{td.name} $\\sum$ {td.y.sum():.2f}\",\n",
    "        marker=markers[i],\n",
    "        color=default_colors[i],\n",
    "        # color = \"None\",\n",
    "        **style,\n",
    "    )\n",
    "\n",
    "for _ax in axs.flatten():\n",
    "    _ax.set_xlabel(\"x\")\n",
    "    _ax.legend(loc=\"upper left\")\n",
    "\n",
    "ax.set_title(\"normal distribution\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "ax_norm.set_title(\"normal distribution\\nnormalized by bin width\")\n",
    "ax_norm.set_ylabel(\"probability\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_mod = lmfit.Model(ln_normal_distribution, independent_vars=(\"x\",))\n",
    "\n",
    "params = lmfit.Parameters()\n",
    "params.add(\"scale_factor\", value=1, min=0)\n",
    "params.add(\"geometric_mean\", value=3, min=0)\n",
    "params.add(\"geometric_sigma\", value=2, min=0)\n",
    "\n",
    "# fit the log nornmal distribution to the data of all three TestData objects\n",
    "for td in (\n",
    "    td1_ln,\n",
    "    td2_ln,\n",
    "    td3_ln,\n",
    "    td1_ln_normalized,\n",
    "    td2_ln_normalized,\n",
    "    td3_ln_normalized,\n",
    "):\n",
    "    try:\n",
    "        td.fit_result = lm_mod.fit(\n",
    "            data=td.y,\n",
    "            x=td.x,\n",
    "            # nan_policy='omit',\n",
    "            **params,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8, 3.5), sharex=True, sharey=True)\n",
    "ax = axs[0]\n",
    "ax_norm = axs[1]\n",
    "\n",
    "x = np.arange(-6, 6, 0.01)\n",
    "x = np.exp(x)\n",
    "for td in (td1_ln, td2_ln, td3_ln):\n",
    "    # make sure to use the same color for data and fit\n",
    "    lines = ax.plot(td.x, td.y, \"o\")\n",
    "    color = lines[0].get_color()\n",
    "    y = td.fit_result.eval(x=x)\n",
    "    ax.plot(x, y, color=color, label=rf\"{td.name} $\\sum$ {y.sum():.2f}\")\n",
    "\n",
    "for td in (td1_ln_normalized, td2_ln_normalized, td3_ln_normalized):\n",
    "    # make sure to use the same color for data and fit\n",
    "    lines = ax_norm.plot(td.x, td.y, \"o\")\n",
    "    color = lines[0].get_color()\n",
    "    y = td.fit_result.eval(x=x)\n",
    "    ax_norm.plot(x, y, color=color, label=rf\"{td.name} $\\sum$ {y.sum():.2f}\")\n",
    "\n",
    "ax.set_title(\"normal distribution\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "\n",
    "ax_norm.set_title(\"normal distribution\\nnormalized by bin width\")\n",
    "ax_norm.set_ylabel(\"probability\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")\n",
    "    _ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fffa03d0980>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.exp(np.arange(-6, 6, 0.1))\n",
    "dx = diff_same_size(x)\n",
    "\n",
    "td = td1_ln\n",
    "ax.plot(td.x, td.y, \"o\", color=\"black\", label=rf\"original $\\sum$ {td.y.sum():.2f}\")\n",
    "\n",
    "\n",
    "for i, td_norm in enumerate((td1_ln_normalized, td2_ln_normalized, td3_ln_normalized)):\n",
    "\n",
    "    fit = td_norm.fit_result\n",
    "    y_ln = fit.eval(x=td.x) * td.dx\n",
    "    y = fit.eval(x=x) * dx\n",
    "\n",
    "    ax.plot(td.x, y_ln, \".\", color=default_colors[i], label=rf\"Obs resolved: $\\sum$ {y_ln.sum():.2f}\")\n",
    "    ax.plot(x, y, \"x\", color=default_colors[i], label=rf\"High resolved: $\\sum$ {y.sum():.2f}\")\n",
    "\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATR Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_composite = xr.open_dataset(\n",
    "    \"/home/m/m301096/repositories/sdm-eurec4a/data/observation/cloud_composite/processed/cloud_composite_si_units.nc\"\n",
    ")\n",
    "identified_clouds = xr.open_dataset(\n",
    "    \"/home/m/m301096/repositories/sdm-eurec4a/data/observation/cloud_composite/processed/identified_clusters/identified_clusters_rain_mask_5.nc\"\n",
    ")\n",
    "\n",
    "attrs = cloud_composite[\"radius\"].attrs.copy()\n",
    "attrs.update({\"units\": \"µm\"})\n",
    "cloud_composite[\"radius\"] = cloud_composite[\"radius\"]\n",
    "cloud_composite[\"radius_micro\"] = 1e6 * cloud_composite[\"radius\"]\n",
    "cloud_composite[\"radius\"].attrs = attrs\n",
    "\n",
    "# cloud_composite = cloud_composite.sel(radius = slice(10, None))\n",
    "\n",
    "identified_clouds = identified_clouds.where(\n",
    "    (\n",
    "        (identified_clouds.duration.dt.total_seconds() > 50)\n",
    "        & (identified_clouds.alt < 1300)\n",
    "        & (identified_clouds.alt > 500)\n",
    "    ),\n",
    "    drop=True,\n",
    ")\n",
    "\n",
    "cloud_composite = match_clouds_and_cloudcomposite(identified_clouds, cloud_composite)\n",
    "\n",
    "cloud_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_composite = cloud_composite.coarsen(radius=2).sum()\n",
    "coarse_composite[\"diameter\"] = 2 * coarse_composite[\"radius\"]\n",
    "coarse_composite.flight_number.plot(marker=\"o\")\n",
    "coarse_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00e-07, 5.00e-07, 5.00e-07, 5.00e-07, 5.00e-07, 5.00e-07,\n",
       "       5.00e-07, 5.00e-07, 5.00e-07, 5.00e-07, 5.00e-07, 7.50e-07,\n",
       "       1.00e-06, 1.00e-06, 1.00e-06, 1.00e-06, 1.00e-06, 1.00e-06,\n",
       "       1.00e-06, 1.00e-06, 1.00e-06, 1.00e-06, 1.00e-06, 1.00e-06,\n",
       "       1.00e-06, 1.00e-06, 3.50e-06, 5.00e-06, 5.00e-06, 5.00e-06,\n",
       "       5.00e-06, 5.00e-06, 2.50e-06, 1.00e-05, 1.00e-05, 1.00e-05,\n",
       "       1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05,\n",
       "       1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05,\n",
       "       1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05,\n",
       "       1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05,\n",
       "       1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05,\n",
       "       1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05,\n",
       "       1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 1.00e-05, 5.75e-05,\n",
       "       1.00e-04, 1.00e-04, 1.00e-04, 1.00e-04, 1.00e-04, 1.00e-04,\n",
       "       1.00e-04])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(florian[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ds in enumerate([cloud_composite, coarse_composite]):\n",
    "    x = np.full(ds.radius.shape, i / 2)\n",
    "    plt.scatter(ds.radius[1:], np.diff(ds.radius), marker=\"x\")\n",
    "\n",
    "plt.scatter(\n",
    "    florian[:, 0][1:],\n",
    "    np.diff(florian[:, 0]),\n",
    ")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_mod = lmfit.Model(normal_distribution, independent_vars=(\"x\",))\n",
    "params_rain = lmfit.Parameters()\n",
    "params_rain.add(\"mu\", value=np.log(300e-6), min=np.log(80e-6), max=np.log(2e-3))\n",
    "params_rain.add(\"scale_factor\", value=1, min=0)\n",
    "params_rain.add(\"sigma\", value=0.5, max=1)\n",
    "\n",
    "params_cloud = lmfit.Parameters()\n",
    "params_cloud.add(\"mu\", value=np.log(0.1e-6), min=np.log(10e-6), max=np.log(50e-6))\n",
    "params_cloud.add(\"scale_factor\", value=1e5, min=0)\n",
    "params_cloud.add(\"sigma\", value=0.5, max=1)\n",
    "\n",
    "RADIUS = coarse_composite[\"radius\"]\n",
    "\n",
    "\n",
    "# for cloud_id in identified_clouds.cloud_id:\n",
    "def fit_both(cloud_id):\n",
    "    da = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "    start = da[\"start\"].values[0]\n",
    "    end = da[\"end\"].values[0]\n",
    "    ds = coarse_composite.sel(time=slice(start, end))\n",
    "\n",
    "    ds[\"particle_size_distribution\"] = ds[\"particle_size_distribution\"] / ds[\"bin_width\"]\n",
    "\n",
    "    ds_rain = ds.sel(radius=slice(50e-6, None))\n",
    "    ds_cloud = ds.sel(radius=slice(None, 50e-6))\n",
    "\n",
    "    td_cloud = TestData(\n",
    "        x=np.log(ds_cloud[\"radius\"].expand_dims(time=ds.time).transpose(\"time\", \"radius\")),\n",
    "        y=ds_cloud[\"particle_size_distribution\"].transpose(\"time\", \"radius\"),\n",
    "        dx=ds_cloud[\"bin_width\"].expand_dims(time=ds.time).transpose(\"time\", \"radius\"),\n",
    "        name=\"cloud\",\n",
    "    )\n",
    "    td_rain = TestData(\n",
    "        x=np.log(ds_rain[\"radius\"].expand_dims(time=ds.time).transpose(\"time\", \"radius\")),\n",
    "        y=ds_rain[\"particle_size_distribution\"].transpose(\"time\", \"radius\"),\n",
    "        dx=ds_rain[\"bin_width\"].expand_dims(time=ds.time).transpose(\"time\", \"radius\"),\n",
    "        name=\"cloud\",\n",
    "    )\n",
    "\n",
    "    for td in (td_cloud, td_rain):\n",
    "\n",
    "        # td.x = td.x.mean('time')\n",
    "        # td.y = td.y.mean('time')\n",
    "        # td.dx = td.dx.mean('time')\n",
    "\n",
    "        td.x = td.x.values.flatten()\n",
    "        td.y = td.y.values.flatten()\n",
    "        td.dx = td.dx.values.flatten()\n",
    "        args = np.isfinite(td.y) & np.isfinite(td.x)\n",
    "        td.x = td.x[args]\n",
    "        td.y = td.y[args]\n",
    "        td.dx = td.dx[args]\n",
    "    # td.y = td.y * np.exp(td.x) ** 3\n",
    "\n",
    "    td_cloud.fit_result = lm_mod.fit(data=td_cloud.y, x=td_cloud.x, **params_cloud)\n",
    "    td_rain.fit_result = lm_mod.fit(data=td_rain.y, x=td_rain.x, **params_rain)\n",
    "    return td_cloud, td_rain\n",
    "\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id.values:\n",
    "    cloud_id_str = str(cloud_id)\n",
    "    try:\n",
    "        td_cloud, td_rain = fit_both(cloud_id)\n",
    "    except TypeError:\n",
    "        print(\"error in cloud_id\", cloud_id)\n",
    "    test_dict[cloud_id_str] = dict(\n",
    "        cloud=td_cloud,\n",
    "        rain=td_rain,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_id = np.random.choice(identified_clouds.cloud_id.values)\n",
    "# cloud_id = 356\n",
    "cloud_id_str = str(cloud_id)\n",
    "\n",
    "ds = match_clouds_and_cloudcomposite(\n",
    "    ds_clouds=select_individual_cloud_by_id(identified_clouds, cloud_id),\n",
    "    ds_cloudcomposite=coarse_composite,\n",
    ")\n",
    "radius = ds[\"radius\"]\n",
    "dx = ds[\"bin_width\"]\n",
    "psd = ds[\"particle_size_distribution\"]\n",
    "\n",
    "\n",
    "td_rain = test_dict[cloud_id_str][\"rain\"]\n",
    "x = np.log(radius)\n",
    "psd_fit = td_rain.fit_result.eval(x=x) * dx\n",
    "lwc_fit = 1000 * psd_fit * 4 / 3 * np.pi * RADIUS**3\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 3))\n",
    "ax.plot(psd.radius, psd, marker=\".\", linestyle=\"None\", color=\"k\", alpha=0.2)\n",
    "ax.plot(radius, psd_fit, color=\"r\", linestyle=\":\")\n",
    "x2 = np.logspace(-6, -3, 10)\n",
    "dx2 = (x2[2:] - x2[:-2]) / 2\n",
    "x2 = x2[1:-1]\n",
    "ax.plot(x2, td_rain.fit_result.eval(x=np.log(x2)) * dx2, color=\"b\", linestyle=\":\")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"symlog\", linthresh=1, linscale=0.1)\n",
    "ax.set_ylim(-1, None)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(7, 3), width_ratios=[1, 0.07])\n",
    "\n",
    "ax = axs[0]\n",
    "cax = axs[1]\n",
    "\n",
    "msd = psd * psd[\"radius\"] ** 3\n",
    "lwc = ds[\"liquid_water_content\"]\n",
    "\n",
    "pcm = ax.pcolormesh(\n",
    "    psd.time,\n",
    "    psd.radius,\n",
    "    1e9 * msd,\n",
    "    cmap=\"Blues\",\n",
    "    shading=\"nearest\",\n",
    "    vmin=0,\n",
    "    vmax=50,\n",
    ")\n",
    "fig.colorbar(pcm, cax=cax, label=\"MSD [mg/m³]\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Radius [µm]\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(lwc.time, 1e3 * lwc, color=\"black\", lw=2, linestyle=\":\")\n",
    "ax2.axhline(1e3 * lwc.mean(\"time\"), color=\"black\", lw=2, linestyle=\"-\")\n",
    "# ax2.fill_between(lwc.time,\n",
    "#                 1e3 * (lwc.mean('time') - lwc.std('time')),\n",
    "#                 1e3 * (lwc.mean('time') + lwc.std('time')),\n",
    "#                 color=\"black\",\n",
    "#                 alpha = 0.1\n",
    "#     )\n",
    "ax2.axhline(1e3 * lwc_fit.sum(), color=\"red\", lw=2)\n",
    "ax2.set_ylabel(\"LWC [g/m³]\")\n",
    "\n",
    "ax2.set_ylim(0, 2)\n",
    "\n",
    "fig.add_axes(ax2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id:\n",
    "\n",
    "    dsi = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "\n",
    "    ds = coarse_composite.sel(time=slice(dsi.start.values[0], dsi.end.values[0]))\n",
    "\n",
    "    msd_cumsum = ds[\"mass_size_distribution\"].cumsum(\"radius\")\n",
    "    psd_cumsum = ds[\"particle_size_distribution\"].cumsum(\"radius\")\n",
    "\n",
    "    msd_cumsum = msd_cumsum / msd_cumsum.isel(radius=-1)\n",
    "    psd_cumsum = psd_cumsum / psd_cumsum.isel(radius=-1)\n",
    "\n",
    "    ax.plot(\n",
    "        1e6 * msd_cumsum.radius,\n",
    "        msd_cumsum.mean(\"time\"),\n",
    "        # marker = 'o',\n",
    "        color=\"blue\",\n",
    "    )\n",
    "\n",
    "    ax2.plot(\n",
    "        1e6 * psd_cumsum.radius,\n",
    "        psd_cumsum.mean(\"time\"),\n",
    "        # marker = 'x',\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id.values:\n",
    "\n",
    "    d = test_dict[str(cloud_id)]\n",
    "    td_cloud = d[\"cloud\"]\n",
    "    td_rain = d[\"rain\"]\n",
    "\n",
    "    radius = coarse_composite.radius\n",
    "\n",
    "    psd = td_cloud.fit_result.eval(x=np.log(radius)) + td_rain.fit_result.eval(x=np.log(radius))\n",
    "    msd = 1000 * 4 / 3 * np.pi * psd * radius**3\n",
    "    # msd_cumsum = ds['mass_size_distribution'].cumsum('radius')\n",
    "    psd_cumsum = np.cumsum(psd)\n",
    "    msd_cumsum = np.cumsum(msd)\n",
    "    msd_cumsum = msd_cumsum / msd_cumsum[-1]\n",
    "    psd_cumsum = psd_cumsum / psd_cumsum[-1]\n",
    "\n",
    "    ax.plot(\n",
    "        1e6 * radius,\n",
    "        msd_cumsum,\n",
    "        # marker = 'o',\n",
    "        color=\"blue\",\n",
    "    )\n",
    "\n",
    "    ax2.plot(\n",
    "        1e6 * radius,\n",
    "        psd_cumsum,\n",
    "        # marker = 'x',\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax2.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffe942e8080>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for cloud_id in identified_clouds.cloud_id.values:\n",
    "\n",
    "    dsi = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "    ds = coarse_composite.sel(time=slice(dsi.start.values[0], dsi.end.values[0]))\n",
    "    radius = ds.radius\n",
    "\n",
    "    m_obs, s_obs = mean_and_stderror_of_mean(ds[\"mass_size_distribution\"].sum(\"radius\"), (\"time\",))\n",
    "\n",
    "    fit = test_dict[str(cloud_id)]\n",
    "    td_cloud = fit[\"cloud\"]\n",
    "    td_rain = fit[\"rain\"]\n",
    "\n",
    "    psd = td_rain.fit_result.eval(x=np.log(radius))\n",
    "    msd = 1000 * 4 / 3 * np.pi * psd * radius**3\n",
    "\n",
    "    m_fit, s_fit = np.sum(msd), 0\n",
    "\n",
    "    ax.errorbar(\n",
    "        x=1e3 * m_obs,\n",
    "        xerr=1e3 * s_obs,\n",
    "        y=1e3 * m_fit,\n",
    "        yerr=1e3 * s_fit,\n",
    "        marker=\"o\",\n",
    "    )\n",
    "\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 4)\n",
    "ax.plot(\n",
    "    ax.get_xlim(),\n",
    "    ax.get_ylim(),\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_id = np.random.choice(identified_clouds.cloud_id.values)\n",
    "# cloud_id = 273\n",
    "da = select_individual_cloud_by_id(identified_clouds, cloud_id)\n",
    "start = da[\"start\"].values[0]\n",
    "end = da[\"end\"].values[0]\n",
    "ds_match = coarse_composite.sel(time=slice(start, end)).sel(radius=slice(50e-6, None))\n",
    "\n",
    "lm_mod = lmfit.Model(normal_distribution, independent_vars=(\"x\",))\n",
    "params = lmfit.Parameters()\n",
    "params.add(\"scale_factor\", value=1)\n",
    "params.add(\"mu\", value=-8, min=-11, max=-5)\n",
    "params.add(\"sigma\", value=0.1, max=5)\n",
    "RADIUS = ds_match[\"radius\"]\n",
    "\n",
    "td_cloud = TestData(\n",
    "    x=np.log(ds_match[\"radius\"].expand_dims(time=ds_match.time).transpose(\"time\", \"radius\")),\n",
    "    y=ds_match[\"particle_size_distribution\"].transpose(\"time\", \"radius\"),\n",
    "    dx=ds_match[\"bin_width\"].expand_dims(time=ds_match.time).transpose(\"time\", \"radius\"),\n",
    "    name=\"cloud\",\n",
    ")\n",
    "\n",
    "\n",
    "td_cloud_mean = TestData(\n",
    "    x=np.log(ds_match[\"radius\"]),\n",
    "    y=ds_match[\"particle_size_distribution\"].mean(dim=\"time\"),\n",
    "    dx=ds_match[\"bin_width\"],\n",
    "    name=\"cloud\",\n",
    ")\n",
    "\n",
    "td_cloud_mean_norm = td_cloud_mean.normalize()\n",
    "\n",
    "for td in (td_cloud, td_cloud_mean, td_cloud_mean_norm):\n",
    "    td.x = td.x.values.flatten()\n",
    "    td.y = td.y.values.flatten()\n",
    "    td.dx = td.dx.values.flatten()\n",
    "\n",
    "    args = np.isfinite(td.y) & np.isfinite(td.x)\n",
    "    td.x = td.x[args]\n",
    "    td.y = td.y[args]\n",
    "    td.dx = td.dx[args]\n",
    "\n",
    "# plt.xscale('log')\n",
    "# fit the log nornmal distribution to the data of all three TestData objects\n",
    "\n",
    "for td in (td_cloud, td_cloud_mean, td_cloud_mean_norm):\n",
    "    td.fit_result = lm_mod.fit(data=td.y, x=td.x, **params)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 3))\n",
    "ax.scatter(\n",
    "    np.exp(td_cloud.x),\n",
    "    td_cloud.y,\n",
    "    marker=\".\",\n",
    "    # color = 'b',\n",
    ")\n",
    "ax.scatter(\n",
    "    np.exp(td_cloud_mean.x),\n",
    "    td_cloud_mean.y,\n",
    "    marker=\"o\",\n",
    "    # color = 'r',\n",
    ")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.axvline(50e-6, color=\"black\", linestyle=\"--\")\n",
    "# td_cloud.x = np.exp(td_cloud.x)\n",
    "\n",
    "x = np.arange(-12, -6, 0.1)\n",
    "ax.plot(np.exp(x), td_cloud.fit_result.eval(x=x), color=\"r\")\n",
    "ax.plot(np.exp(x), td_cloud_mean.fit_result.eval(x=x), color=\"b\", linestyle=\"--\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.exp(x), td_cloud_mean_norm.fit_result.eval(x=x), color=\"g\", linestyle=\":\")\n",
    "\n",
    "psd_fit = td_cloud.fit_result.eval(x=np.log(RADIUS))\n",
    "lwc_fit = 1000 * psd_fit * 4 / 3 * np.pi * RADIUS**3\n",
    "# plt.xscale('log')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(7, 3), width_ratios=[1, 0.07])\n",
    "\n",
    "ax = axs[0]\n",
    "cax = axs[1]\n",
    "\n",
    "psd = ds_match[\"particle_size_distribution\"]\n",
    "msd = psd * psd[\"radius\"] ** 3\n",
    "lwc = ds_match[\"liquid_water_content\"]\n",
    "\n",
    "pcm = ax.pcolormesh(\n",
    "    psd.time,\n",
    "    psd.radius,\n",
    "    msd,\n",
    "    cmap=\"Blues\",\n",
    "    shading=\"nearest\",\n",
    ")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Radius [µm]\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(lwc.time, 1e3 * lwc, color=\"black\", lw=2, linestyle=\":\")\n",
    "ax2.axhline(1e3 * lwc.mean(\"time\"), color=\"black\", lw=2, linestyle=\"-\")\n",
    "ax2.fill_between(\n",
    "    lwc.time,\n",
    "    1e3 * (lwc.mean(\"time\") - lwc.std(\"time\")),\n",
    "    1e3 * (lwc.mean(\"time\") + lwc.std(\"time\")),\n",
    "    color=\"black\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "ax2.axhline(1e3 * lwc_fit.sum(), color=\"red\", lw=2)\n",
    "ax2.set_ylabel(\"LWC [g/m³]\")\n",
    "\n",
    "fig.add_axes(ax2)\n",
    "\n",
    "fig.colorbar(pcm, cax=cax, label=\"MSD [µm³/m³]\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climNum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
