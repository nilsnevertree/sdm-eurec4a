{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from numpy.random import default_rng\n",
    "from scipy.optimize import least_squares, Bounds\n",
    "from typing import List, Tuple, Dict, TypedDict, Union, Callable\n",
    "\n",
    "from sdm_eurec4a.reductions import mean_and_stderror_of_mean\n",
    "from sdm_eurec4a.visulization import set_custom_rcParams, adjust_lightness_array, label_from_attrs\n",
    "from sdm_eurec4a.identifications import match_clouds_and_cloudcomposite, select_individual_cloud_by_id\n",
    "from sdm_eurec4a.conversions import msd_from_psd_dataarray, psd_from_msd_dataarray\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "default_colors = set_custom_rcParams()\n",
    "dark_colors = adjust_lightness_array(default_colors, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variance_field(\n",
    "    y: np.ndarray,\n",
    "    variance: Union[None, float, int, np.ndarray] = None,\n",
    "    variance_scale: float = 0.01,\n",
    "    variance_minimal: float = 1e30,\n",
    "    #   variance_replace: Union[None, float] = None\n",
    ") -> Union[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Create a variance field based on the input data and specified parameters.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y : np.ndarray\n",
    "        The input data array for which the variance field is to be created.\n",
    "    variance : Union[bool, np.ndarray], optional\n",
    "        If True, the variance is calculated as the scaled absolute value of `y`.\n",
    "        If False, the variance is set to 1.\n",
    "        If an array, it is used directly as the variance.\n",
    "        Default is True.\n",
    "    variance_scale : float, optional\n",
    "        The scaling factor applied to the absolute value of `y` to calculate the variance.\n",
    "        Default is 0.01.\n",
    "    # variance_minimal : float, optional\n",
    "    #     The minimal threshold for the variance. Values below this threshold are replaced.\n",
    "    #     Default is 1e-12.\n",
    "    # variance_replace : Union[None, float], optional\n",
    "    #     The value to replace variances below the minimal threshold. If None, the minimum\n",
    "    #     non-NaN variance is used. Default is None.\n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        The calculated variance field based on the input data and specified parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # plt.figure()\n",
    "    # also devide by the variance of the data\n",
    "    if variance == None:\n",
    "        # we scale the variance by the absolute value of the data\n",
    "        var = np.abs(variance_scale * (y / np.nanstd(y)))\n",
    "        # plt.plot(var, '--')\n",
    "        # we handle the case where the data is zero, by setting the variance there to the maximum value\n",
    "        var_nozero = np.where(y != 0, var, np.nan)\n",
    "        var_truemin = np.nanmin(var_nozero)\n",
    "        # we replace the zero values with the minimum\n",
    "        # plt.axhline(y=var_truemin, color='r', linestyle =  ':')\n",
    "        var = np.where(var != 0, var, var_truemin)\n",
    "        # we replace the variances below the minimal threshold\n",
    "        # var = np.where(var <= variance_minimal, var, var_min)\n",
    "\n",
    "    elif isinstance(variance, (np.ndarray, int, float)):\n",
    "        var = variance\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            f\"The variance parameter must be either None, a float or a numpy array.\\nBut is of type: {type(variance)}.\"\n",
    "        )\n",
    "\n",
    "    # var = var * 0 + 1\n",
    "\n",
    "    # plt.plot(var)\n",
    "    # plt.show()\n",
    "\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions to be used for fit\n",
    "### LnNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LnParams(TypedDict):\n",
    "    mu1: float\n",
    "    sigma1: float\n",
    "    scale_factor1: float\n",
    "\n",
    "\n",
    "def ln_normal_distribution(\n",
    "    t: np.ndarray,\n",
    "    mu1: float,\n",
    "    sigma1: float,\n",
    "    scale_factor1: float,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    result = t * 0\n",
    "\n",
    "    sigtilda = np.log(sigma1)\n",
    "    mutilda = np.log(mu1)\n",
    "\n",
    "    norm = scale_factor1 / (np.sqrt(2 * np.pi) * sigtilda)\n",
    "    exponent = -((np.log(t) - mutilda) ** 2) / (2 * sigtilda**2)\n",
    "\n",
    "    dn_dlnr = norm * np.exp(exponent)  # eq.5.8 [lohmann intro 2 clouds]\n",
    "\n",
    "    result += dn_dlnr\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def ln_normal_distribution_cost(\n",
    "    x: Tuple[float, float, float],\n",
    "    t: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    variance: Union[None, np.ndarray, float] = None,\n",
    "    variance_scale: float = 0.01,\n",
    "    variance_minimal: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    y_pred = ln_normal_distribution(t, *x)\n",
    "\n",
    "    var = create_variance_field(y, variance, variance_scale, variance_minimal)\n",
    "\n",
    "    return np.ravel((y_pred - y) / np.sqrt(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double LnNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleLnParams(TypedDict):\n",
    "    mu1: float\n",
    "    sigma1: float\n",
    "    scale_factor1: float\n",
    "    mu2: float\n",
    "    sigma2: float\n",
    "    scale_factor2: float\n",
    "\n",
    "\n",
    "def double_ln_normal_distribution(\n",
    "    t: np.ndarray,\n",
    "    mu1: float,\n",
    "    sigma1: float,\n",
    "    scale_factor1: float,\n",
    "    mu2: float,\n",
    "    sigma2: float,\n",
    "    scale_factor2: float,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    result = t * 0\n",
    "\n",
    "    for mu, sigma, scale_factor in zip(\n",
    "        (mu1, mu2),\n",
    "        (sigma1, sigma2),\n",
    "        (scale_factor1, scale_factor2),\n",
    "    ):\n",
    "        sigtilda = np.log(sigma)\n",
    "        mutilda = np.log(mu)\n",
    "\n",
    "        norm = scale_factor / (np.sqrt(2 * np.pi) * sigtilda)\n",
    "        exponent = -((np.log(t) - mutilda) ** 2) / (2 * sigtilda**2)\n",
    "\n",
    "        dn_dlnr = norm * np.exp(exponent)  # eq.5.8 [lohmann intro 2 clouds]\n",
    "\n",
    "        result += dn_dlnr\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def double_ln_normal_distribution_cost(\n",
    "    x: Tuple[float, float, float, float, float, float],\n",
    "    t: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    variance: Union[None, float, int, np.ndarray] = None,\n",
    "    variance_scale: float = 0.01,\n",
    "    variance_minimal: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    y_pred = double_ln_normal_distribution(t, *x)\n",
    "\n",
    "    var = create_variance_field(y, variance, variance_scale, variance_minimal)\n",
    "\n",
    "    return np.ravel((y_pred - y) / np.sqrt(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GammaParams(TypedDict):\n",
    "    shape: float\n",
    "    slope: float\n",
    "    intercept: float\n",
    "\n",
    "\n",
    "def gamma_distribution(\n",
    "    radius: np.ndarray,  # radius\n",
    "    shape: float,\n",
    "    slope: float,\n",
    "    intercept: float,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    n = intercept + slope * (2 * radius) ** shape * np.exp(-slope * (2 * radius))\n",
    "\n",
    "    return n\n",
    "\n",
    "\n",
    "def gamma_distribution_cost(\n",
    "    x: Tuple[float, float, float],\n",
    "    t: np.ndarray,  # radius,\n",
    "    y: np.ndarray,\n",
    "    variance: Union[None, float, int, np.ndarray] = None,\n",
    "    variance_scale: float = 0.01,\n",
    "    variance_minimal: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    y_pred = gamma_distribution(t, *x)\n",
    "\n",
    "    var = create_variance_field(y, variance, variance_scale, variance_minimal)\n",
    "\n",
    "    return np.ravel((y_pred - y) / np.sqrt(var))\n",
    "\n",
    "\n",
    "def gamma_distribution_stats(\n",
    "    t: Union[np.ndarray, xr.DataArray],\n",
    "    a: float,\n",
    "    loc: float,\n",
    "    scale: float,\n",
    "    N0: float,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    result = stats.gamma.pdf(t, a=a, loc=loc, scale=scale)\n",
    "    # normalize to have the same maximum as the data\n",
    "    result = N0 / np.max(result) * result\n",
    "\n",
    "    return t * 0 + result\n",
    "\n",
    "\n",
    "def gamma_distribution_stats_cost(\n",
    "    x: np.ndarray,\n",
    "    t: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    variance: Union[None, float, int, np.ndarray] = None,\n",
    "    variance_scale: float = 0.01,\n",
    "    variance_minimal: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    a, loc, scale, N0 = x\n",
    "    y_pred = gamma_distribution_stats(t, a, loc, scale, N0)\n",
    "\n",
    "    var = create_variance_field(y, variance, variance_scale, variance_minimal)\n",
    "\n",
    "    return np.ravel((y_pred - y) / np.sqrt(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate example for the fitting of the 2LnNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "\n",
    "\n",
    "def gen_data(\n",
    "    t: np.ndarray,\n",
    "    func: Callable,\n",
    "    func_args: Tuple = (),\n",
    "    func_kwargs: Union[dict, TypedDict] = dict(),\n",
    "    noise=0.0,\n",
    "    n_outliers=0,\n",
    "    seed=None,\n",
    "):\n",
    "    rng = default_rng(seed)\n",
    "\n",
    "    y = func(t, *func_args, **func_kwargs)\n",
    "    error = noise * rng.standard_normal(t.size)\n",
    "    outliers = rng.integers(0, t.size, n_outliers)\n",
    "    error[outliers] = np.sqrt(t[outliers]) * error[outliers]\n",
    "\n",
    "    return y + error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = DoubleLnParams(\n",
    "    mu1=1e-2,\n",
    "    sigma1=2,\n",
    "    scale_factor1=5,\n",
    "    mu2=0.5e1,\n",
    "    sigma2=3,\n",
    "    scale_factor2=2,\n",
    ")\n",
    "\n",
    "t_min = 0.1\n",
    "t_max = 10\n",
    "n_points = 40\n",
    "n_outliers = 5\n",
    "\n",
    "t_train = np.logspace(-3, 2, n_points)\n",
    "m_train = gen_data(\n",
    "    t=t_train,\n",
    "    func=double_ln_normal_distribution,\n",
    "    func_kwargs=params,\n",
    "    noise=0.2,\n",
    "    n_outliers=n_outliers,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "\n",
    "x0 = np.array([1e-1, 2.0, 1.0, 10.0, 2.0, 1.0])\n",
    "\n",
    "\n",
    "bounds = Bounds(\n",
    "    lb=[1e-10, 1e-10, -np.inf, 2e-2, 1e-10, -np.inf],\n",
    "    ub=[5e-1, np.inf, np.inf, np.inf, np.inf, np.inf],\n",
    "    keep_feasible=[True, True, True, False, True, True],\n",
    ")\n",
    "\n",
    "\n",
    "res_lsq = least_squares(double_ln_normal_distribution_cost, x0, bounds=bounds, args=(t_train, m_train))\n",
    "\n",
    "res_soft_l1 = least_squares(\n",
    "    double_ln_normal_distribution_cost,\n",
    "    x0,\n",
    "    loss=\"soft_l1\",\n",
    "    f_scale=0.1,\n",
    "    bounds=bounds,\n",
    "    args=(t_train, m_train),\n",
    ")\n",
    "\n",
    "res_log = least_squares(\n",
    "    double_ln_normal_distribution_cost,\n",
    "    x0,\n",
    "    loss=\"cauchy\",\n",
    "    f_scale=0.1,\n",
    "    bounds=bounds,\n",
    "    args=(t_train, m_train),\n",
    ")\n",
    "\n",
    "\n",
    "t_test = np.logspace(-5, 2, n_points * 10)\n",
    "m_true = gen_data(\n",
    "    t=t_test,\n",
    "    func=double_ln_normal_distribution,\n",
    "    func_kwargs=params,\n",
    ")\n",
    "\n",
    "m_lsq = gen_data(t=t_test, func=double_ln_normal_distribution, func_args=res_lsq.x)\n",
    "m_soft_l1 = gen_data(t=t_test, func=double_ln_normal_distribution, func_args=res_soft_l1.x)\n",
    "m_log = gen_data(t=t_test, func=double_ln_normal_distribution, func_args=res_log.x)\n",
    "plt.plot(t_train, m_train, \"o\")\n",
    "plt.plot(t_test, m_true, \"k\", linewidth=2, label=\"true\", linestyle=\"-\")\n",
    "plt.plot(t_test, m_lsq, label=\"linear loss\", linestyle=\"--\")\n",
    "plt.plot(t_test, m_soft_l1, label=\"soft_l1 loss\", linestyle=\"-.\")\n",
    "plt.plot(t_test, m_log, label=\"cauchy loss\", linestyle=\"\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the ``least_square`` method to the cloud composite dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdm_eurec4a import RepositoryPath\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = RepositoryPath(\"nils_private\").get_data_dir()\n",
    "\n",
    "cloud_composite = xr.open_dataset(\n",
    "    data_dir / Path(\"observation/cloud_composite/processed/cloud_composite_SI_units_20241025.nc\")\n",
    ")\n",
    "identified_clouds = xr.open_dataset(\n",
    "    data_dir\n",
    "    / Path(\n",
    "        \"observation/cloud_composite/processed/identified_clusters/identified_clusters_rain_mask_5.nc\"\n",
    "    )\n",
    ")\n",
    "identified_clouds = identified_clouds.swap_dims({\"time\": \"cloud_id\"})\n",
    "\n",
    "attrs = cloud_composite[\"radius\"].attrs.copy()\n",
    "attrs.update({\"units\": \"µm\"})\n",
    "cloud_composite[\"radius\"] = cloud_composite[\"radius\"]\n",
    "cloud_composite[\"radius_micro\"] = 1e6 * cloud_composite[\"radius\"]\n",
    "cloud_composite[\"radius\"].attrs = attrs\n",
    "\n",
    "cloud_composite[\"radius2D\"] = cloud_composite[\"radius\"].expand_dims(time=cloud_composite[\"time\"])\n",
    "cloud_composite = cloud_composite.transpose(\"radius\", ...)\n",
    "\n",
    "\n",
    "# cloud_composite = cloud_composite.sel(radius = slice(10, None))\n",
    "\n",
    "identified_clouds = identified_clouds.where(\n",
    "    (\n",
    "        (identified_clouds.duration.dt.seconds >= 3)\n",
    "        & (identified_clouds.altitude < 1200)\n",
    "        & (identified_clouds.altitude > 500)\n",
    "    ),\n",
    "    drop=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to coarsen the results, we need to make sure to apply the coarsening on the **NON** normalized data.\n",
    "Then we can normalized afterwards again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_split = 95e-6  # 50 µm\n",
    "coarsen_factor = 3\n",
    "\n",
    "\n",
    "coarse_composite = cloud_composite.sel(radius=slice(radius_split, None)).copy()\n",
    "\n",
    "# make sure to have non normalized data to be coarsened\n",
    "# otherwise, the sum will not be conserved\n",
    "coarse_composite[\"particle_size_distribution\"] = (\n",
    "    coarse_composite[\"particle_size_distribution\"] * coarse_composite[\"bin_width\"]\n",
    ")\n",
    "coarse_composite[\"mass_size_distribution\"] = (\n",
    "    coarse_composite[\"mass_size_distribution\"] * coarse_composite[\"bin_width\"]\n",
    ")\n",
    "\n",
    "# use mean for radius and radius2D\n",
    "coarse_composite_radius = coarse_composite[\"radius\"].coarsen(radius=coarsen_factor).mean()\n",
    "coarse_composite_radius2D = coarse_composite[\"radius2D\"].coarsen(radius=coarsen_factor).mean()\n",
    "# use the sum for the rest\n",
    "coarse_composite = coarse_composite.coarsen(radius=coarsen_factor).sum()\n",
    "\n",
    "coarse_composite[\"radius\"] = coarse_composite_radius\n",
    "coarse_composite[\"radius2D\"] = coarse_composite_radius2D\n",
    "coarse_composite[\"diameter\"] = 2 * coarse_composite[\"radius\"]\n",
    "\n",
    "# make sure to have normalized data again\n",
    "coarse_composite[\"particle_size_distribution\"] = (\n",
    "    coarse_composite[\"particle_size_distribution\"] / coarse_composite[\"bin_width\"]\n",
    ")\n",
    "coarse_composite[\"mass_size_distribution\"] = (\n",
    "    coarse_composite[\"mass_size_distribution\"] / coarse_composite[\"bin_width\"]\n",
    ")\n",
    "\n",
    "coarse_composite[\"particle_size_distribution\"].attrs = dict(\n",
    "    long_name=\"Number concentration\",\n",
    "    unit=cloud_composite[\"particle_size_distribution\"].attrs[\"unit\"],\n",
    ")\n",
    "coarse_composite[\"mass_size_distribution\"].attrs = dict(\n",
    "    long_name=\"Mass concentration\",\n",
    "    unit=cloud_composite[\"mass_size_distribution\"].attrs[\"unit\"],\n",
    ")\n",
    "\n",
    "# merge the two composites with higher resoltion at small radii\n",
    "# and lower resolution at large radii\n",
    "coarse_composite = xr.merge(\n",
    "    [\n",
    "        coarse_composite.sel(radius=slice(radius_split, None)),\n",
    "        cloud_composite.sel(radius=slice(None, radius_split)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Test liquid water content is conserved\n",
    "np.testing.assert_allclose(\n",
    "    (coarse_composite[\"bin_width\"] * coarse_composite[\"mass_size_distribution\"]).sum(\"radius\"),\n",
    "    (cloud_composite[\"bin_width\"] * cloud_composite[\"mass_size_distribution\"]).sum(\"radius\"),\n",
    "    rtol=0.001,\n",
    ")\n",
    "# Test particle concentration is conserved\n",
    "np.testing.assert_allclose(\n",
    "    (coarse_composite[\"bin_width\"] * coarse_composite[\"particle_size_distribution\"]).sum(\"radius\"),\n",
    "    (cloud_composite[\"bin_width\"] * cloud_composite[\"particle_size_distribution\"]).sum(\"radius\"),\n",
    "    rtol=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(dataset, axs):\n",
    "    for i, cloud_id in enumerate(cloud_ids):\n",
    "        cloud = identified_clouds.sel(cloud_id=cloud_id)\n",
    "        ds = match_clouds_and_cloudcomposite(cloud, dataset)\n",
    "        m, v = mean_and_stderror_of_mean(ds[\"particle_size_distribution\"], dims=(\"time\",))\n",
    "        axs[0].errorbar(\n",
    "            x=m[\"radius\"],\n",
    "            xerr=0,\n",
    "            y=m,\n",
    "            yerr=2 * v,\n",
    "            label=f\"cloud {cloud_id}\",\n",
    "            color=default_colors[i],\n",
    "            marker=\".\",\n",
    "            linestyle=\"None\",\n",
    "        )\n",
    "        m, v = mean_and_stderror_of_mean(ds[\"mass_size_distribution\"], dims=(\"time\",))\n",
    "        axs[1].errorbar(\n",
    "            x=m[\"radius\"],\n",
    "            xerr=0,\n",
    "            y=m,\n",
    "            yerr=2 * v,\n",
    "            label=f\"cloud {cloud_id}\",\n",
    "            color=default_colors[i],\n",
    "            marker=\".\",\n",
    "            linestyle=\"None\",\n",
    "        )\n",
    "        # print(f\"{cloud_id} {ds['mass_size_distribution'].sum('radius').mean('time').values} LWC\")\n",
    "\n",
    "    m, v = mean_and_stderror_of_mean(dataset[\"particle_size_distribution\"], dims=(\"time\",))\n",
    "    axs[0].plot(\n",
    "        m.radius,\n",
    "        m,\n",
    "        label=\"mean\",\n",
    "        color=\"k\",\n",
    "        zorder=10,\n",
    "    )\n",
    "    axs[0].fill_between(\n",
    "        m.radius,\n",
    "        m - 2 * v,\n",
    "        m + 2 * v,\n",
    "        alpha=0.5,\n",
    "        color=\"k\",\n",
    "        label=\"2 std\",\n",
    "        zorder=10,\n",
    "    )\n",
    "\n",
    "    m, v = mean_and_stderror_of_mean(dataset[\"mass_size_distribution\"], dims=(\"time\",))\n",
    "    axs[1].plot(m.radius, m, label=\"mean\", color=\"k\", zorder=10)\n",
    "    axs[1].fill_between(\n",
    "        m.radius,\n",
    "        m - 2 * v,\n",
    "        m + 2 * v,\n",
    "        alpha=0.5,\n",
    "        color=\"k\",\n",
    "        label=\"2 std\",\n",
    "        zorder=10,\n",
    "    )\n",
    "\n",
    "    for _ax in axs:\n",
    "        _ax.set_xscale(\"log\")\n",
    "        _ax.set_yscale(\"log\")\n",
    "\n",
    "    axs[0].set_title(\"particle size distribution\")\n",
    "    axs[1].set_title(\"mass size distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x246801c3c70>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cloud_ids = rng.choice(identified_clouds[\"cloud_id\"], 2, replace=False)\n",
    "\n",
    "\n",
    "fig, axss = plt.subplots(nrows=2, ncols=2, figsize=(10, 6), sharex=True)\n",
    "\n",
    "plot_distributions(cloud_composite, axss[0])\n",
    "plot_distributions(coarse_composite, axss[1])\n",
    "\n",
    "axss[0, 0].legend(loc=\"upper right\", fontsize=\"small\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(\n",
    "    cloud_composite[\"radius\"],\n",
    "    cloud_composite[\"radius\"],\n",
    "    label=\"original\",\n",
    "    color=\"k\",\n",
    "    marker=\".\",\n",
    ")\n",
    "ax.scatter(\n",
    "    coarse_composite[\"radius\"],\n",
    "    coarse_composite[\"radius\"],\n",
    "    label=\"coarse\",\n",
    "    color=\"r\",\n",
    "    marker=\".\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquareFit:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        func: Callable,\n",
    "        cost_func: Callable,\n",
    "        x0: np.ndarray,\n",
    "        bounds: Bounds,\n",
    "        t_train: Union[np.ndarray, xr.DataArray],\n",
    "        y_train: Union[np.ndarray, xr.DataArray],\n",
    "        fit_kwargs: Dict = dict(),\n",
    "        plot_kwargs: Dict = dict(),\n",
    "    ):\n",
    "\n",
    "        self.name = name\n",
    "        self.func = func\n",
    "        self.cost_func = cost_func\n",
    "        self.x0 = x0\n",
    "        self.bounds = bounds\n",
    "        self.t_train = t_train\n",
    "        self.y_train = y_train\n",
    "        self.fit_kwargs = fit_kwargs\n",
    "        self.plot_kwargs = plot_kwargs\n",
    "        self.fit_result = None\n",
    "\n",
    "    def fit(self, repetitions: int = 1):\n",
    "\n",
    "        for i in range(repetitions):\n",
    "            if i != 0:\n",
    "                x0 = self.fit_result.x\n",
    "            else:\n",
    "                x0 = self.x0\n",
    "\n",
    "            self.fit_result = least_squares(\n",
    "                self.cost_func,\n",
    "                x0=x0,\n",
    "                bounds=self.bounds,\n",
    "                args=(np.ravel(self.t_train), np.ravel(self.y_train)),\n",
    "                **self.fit_kwargs,\n",
    "            )\n",
    "\n",
    "        return self.fit_result\n",
    "\n",
    "    def predict(\n",
    "        self, t_test: Union[np.ndarray, xr.DataArray]\n",
    "    ) -> Tuple[Union[np.ndarray, xr.DataArray], Union[np.ndarray, xr.DataArray]]:\n",
    "        self.t_test = t_test\n",
    "        self.y_test = self.func(self.t_test, *self.fit_result.x)\n",
    "\n",
    "        return self.t_test, self.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the fitting to the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt start to end radii range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Double LnNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24683418160>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "cloud_id = rng.choice(identified_clouds[\"cloud_id\"])\n",
    "\n",
    "train_data = match_clouds_and_cloudcomposite(\n",
    "    identified_clouds.sel(cloud_id=cloud_id),\n",
    "    coarse_composite,\n",
    ")\n",
    "\n",
    "t_train = train_data[\"radius2D\"]\n",
    "y_train = train_data[\"particle_size_distribution\"]\n",
    "m_train = train_data[\"mass_size_distribution\"]\n",
    "w_train = train_data[\"bin_width\"]\n",
    "lwc_train = train_data[\"liquid_water_content\"].mean(\"time\")\n",
    "\n",
    "# we can also use only the radii where we have data:\n",
    "radii_measured = train_data.max(\"time\")[\"particle_size_distribution\"] > 0\n",
    "end = train_data[\"radius\"].where(radii_measured).max(\"radius\")\n",
    "start = train_data[\"radius\"].where(radii_measured).min(\"radius\")\n",
    "\n",
    "# create a log spaced array of radii\n",
    "r = np.geomspace(start, end, 1000)\n",
    "t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "w_test = (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "w_test = w_test.interpolate_na(\"radius\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "# t_test = t_test.where(np.isfinite(w_test), drop=True)\n",
    "# w_test = w_test.where(np.isfinite(w_test), drop=True)\n",
    "\n",
    "x0_psd = np.array([3e-6, 2, 1e10, 200e-6, 2, 1e6])\n",
    "bounds_psd = Bounds(\n",
    "    # mu1, sig1, sc1, mu2, sig2, sc2\n",
    "    lb=[1e-6, 1.1, 1e7, 200e-6, 1.1, 1e0],\n",
    "    ub=[10e-6, 3.0, 1e13, 0.5e-3, 3.0, 1e8],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "lqs_psd = LeastSquareFit(\n",
    "    name=\"PSD vari\",\n",
    "    fit_kwargs=dict(loss=\"linear\"),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_psd,\n",
    "    bounds=bounds_psd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[0], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "lqs_psd_var1 = LeastSquareFit(\n",
    "    name=\"PSD nova\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_psd,\n",
    "    bounds=bounds_psd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=dark_colors[0], linestyle=\"--\"),\n",
    ")\n",
    "\n",
    "lsq_gamma = LeastSquareFit(\n",
    "    name=\"Gamma\",\n",
    "    fit_kwargs=dict(loss=\"linear\"),\n",
    "    func=gamma_distribution,\n",
    "    cost_func=gamma_distribution_cost,\n",
    "    x0=[1, 1, 1],\n",
    "    bounds=Bounds(\n",
    "        lb=[0, 0, 0],\n",
    "        ub=[np.inf, np.inf, np.inf],\n",
    "    ),\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[3], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "setups_psd = [lqs_psd, lqs_psd_var1, lsq_gamma]\n",
    "\n",
    "\n",
    "x0_msd = np.array([3e-6, 2, 1e-1, 300e-6, 2, 1e0])\n",
    "bounds_msd = Bounds(\n",
    "    lb=[1e-6, 1.1, 1e-3, 200e-6, 1.3, 1e-3],\n",
    "    ub=[10e-6, 4.0, 1e2, 0.5e-3, 3.0, 1e1],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "lqs_msd = LeastSquareFit(\n",
    "    name=\"MSD vari\",\n",
    "    fit_kwargs=dict(loss=\"linear\"),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[1], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "lqs_msd_var1 = LeastSquareFit(\n",
    "    name=\"MSD nova\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=dark_colors[1], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "softl1_msd = LeastSquareFit(\n",
    "    name=\"MSD Soft\",\n",
    "    fit_kwargs=dict(loss=\"soft_l1\", f_scale=0.1, kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[2], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "setups_msd = [lqs_msd, lqs_msd_var1, softl1_msd]  # , soft_l1, soft_l1_mean]\n",
    "setups = setups_psd + setups_msd\n",
    "\n",
    "for doublefit in setups:\n",
    "    doublefit.fit()\n",
    "\n",
    "\n",
    "# --- Plot the results ---\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(8, 4), sharex=True)\n",
    "ax0, ax1 = axs\n",
    "\n",
    "# plot the particle size distribution\n",
    "ax0.scatter(t_train, y_train, marker=\"o\", color=\"grey\")\n",
    "ax0.scatter(t_train.mean(\"time\"), y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# plot the mass size distribution\n",
    "ax1.scatter(t_train, m_train, marker=\"o\", color=\"grey\")\n",
    "ax1.scatter(t_train.mean(\"time\"), m_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# --- Plot the results ---\n",
    "for fit in setups_psd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, y = fit.predict(t)\n",
    "    m = msd_from_psd_dataarray(y)\n",
    "    lwc_psd = 1e3 * (m * w).sum(\"radius\").values\n",
    "\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", **fit.plot_kwargs)\n",
    "\n",
    "for fit in setups_msd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, m = fit.predict(t)\n",
    "    y = psd_from_msd_dataarray(m)\n",
    "    lwc_msd = 1e3 * (m * w).sum(\"radius\").values\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", **fit.plot_kwargs)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Fits for cloud {cloud_id}: Desired={lwc_train.values:.2f}\", fontsize=\"medium\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")\n",
    "    _ax.set_xlim(1e-6, 0.8e-1)\n",
    "axs[0].set_yscale(\"symlog\", linthresh=1.1e3, linscale=0.1)\n",
    "axs[1].set_yscale(\"symlog\", linthresh=1.1e-7, linscale=0.1)\n",
    "\n",
    "axs[0].set_ylim(1e-12, 1e12)\n",
    "axs[1].set_ylim(1e-12, 0.5e2)\n",
    "axs[0].legend(fontsize=\"small\", loc=\"center right\")\n",
    "axs[1].legend(fontsize=\"small\", loc=\"center right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Easy sinle log normal diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x246858c3e50>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(identified_clouds[\"liquid_water_content\"] / identified_clouds[\"duration\"].dt.seconds).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting\n",
    "## Show the comparison of the fit to PSD and MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_id = rng.choice(\n",
    "    identified_clouds.where(\n",
    "        # (identified_clouds[\"liquid_water_content\"] / identified_clouds['duration'].dt.seconds) > 1,\n",
    "        (identified_clouds[\"liquid_water_content\"] / identified_clouds[\"duration\"].dt.seconds) > 0.4,\n",
    "        # identified_clouds['duration'].dt.seconds > 40,\n",
    "        drop=True,\n",
    "    )[\"cloud_id\"]\n",
    ")\n",
    "# cloud_id = 362 # weird fit\n",
    "# cloud_id = 193  # good fit\n",
    "# # cloud_id = 216 # sparse data\n",
    "# cloud_id = 230  # low cutoff range\n",
    "# cloud_id = 361 # low LWC range\n",
    "# cloud_id = 220 # high LWC and good MSD fit\n",
    "# cloud_id = 58  # very high LWC\n",
    "# cloud_id = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mass concentration\\n$\\\\left[  kg m^{-3} m^{-1}  \\\\right]$')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "train_data = match_clouds_and_cloudcomposite(\n",
    "    identified_clouds.sel(cloud_id=cloud_id),\n",
    "    coarse_composite,\n",
    ")\n",
    "\n",
    "t_train = train_data[\"radius2D\"]\n",
    "y_train = train_data[\"particle_size_distribution\"]\n",
    "m_train = train_data[\"mass_size_distribution\"]\n",
    "w_train = train_data[\"bin_width\"]\n",
    "lwc_train = train_data[\"liquid_water_content\"].mean(\"time\")\n",
    "\n",
    "# we can also use only the radii where we have data:\n",
    "radii_measured = train_data.max(\"time\")[\"particle_size_distribution\"] > 0\n",
    "end = train_data[\"radius\"].where(radii_measured).max(\"radius\")\n",
    "start = train_data[\"radius\"].where(radii_measured).min(\"radius\")\n",
    "end = 1.5 * end\n",
    "# create a log spaced array of radii\n",
    "r = np.geomspace(start, end, 1000)\n",
    "t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "w_test = (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "w_test = w_test.interpolate_na(\"radius\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "# t_test = t_test.where(np.isfinite(w_test), drop=True)\n",
    "# w_test = w_test.where(np.isfinite(w_test), drop=True)\n",
    "\n",
    "x0_psd = np.array([3e-6, 2, 1e10, 200e-6, 2, 1e6])\n",
    "bounds_psd = Bounds(\n",
    "    # mu1, sig1, sc1, mu2, sig2, sc2\n",
    "    lb=[1e-6, 1.1, 1e7, 200e-6, 1.1, 1e0],\n",
    "    ub=[10e-6, 3.0, 1e13, 0.5e-3, 3.0, 1e8],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "lqs_psd = LeastSquareFit(\n",
    "    name=\"PSD\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_psd,\n",
    "    bounds=bounds_psd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[0], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "# lqs_psd_var1 = LeastSquareFit(\n",
    "#     name = \"PSD nova\",\n",
    "#     fit_kwargs=dict(loss=\"linear\", kwargs = dict(variance=1)),\n",
    "#     func = double_ln_normal_distribution,\n",
    "#     cost_func = double_ln_normal_distribution_cost,\n",
    "#     x0 = x0_psd,\n",
    "#     bounds= bounds_psd,\n",
    "#     t_train= t_train.mean('time'),\n",
    "#     y_train= y_train.mean('time'),\n",
    "#     plot_kwargs=dict(color=dark_colors[0], linestyle=\"--\")\n",
    "#     )\n",
    "\n",
    "\n",
    "setups_psd = [lqs_psd]\n",
    "\n",
    "\n",
    "x0_msd = np.array([3e-6, 2, 1e-1, 300e-6, 2, 1e0])\n",
    "bounds_msd = Bounds(\n",
    "    lb=[1e-6, 1.1, 1e-3, 200e-6, 1.3, 1e-3],\n",
    "    ub=[10e-6, 3.0, 1e2, 0.5e-3, 3.0, 1e1],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "# lqs_msd = LeastSquareFit(\n",
    "#     name = \"MSD vari\",\n",
    "#     fit_kwargs=dict(loss=\"linear\"),\n",
    "#     func = double_ln_normal_distribution,\n",
    "#     cost_func = double_ln_normal_distribution_cost,\n",
    "#     x0 = x0_msd,\n",
    "#     bounds= bounds_msd,\n",
    "#     t_train= t_train.mean('time'),\n",
    "#     y_train= m_train.mean('time'),\n",
    "#     plot_kwargs=dict(color=default_colors[1], linestyle=\"-\")\n",
    "#     )\n",
    "\n",
    "lqs_msd_var1 = LeastSquareFit(\n",
    "    name=\"MSD nova\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=dark_colors[1], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "# softl1_msd = LeastSquareFit(\n",
    "#     name = \"MSD Soft\",\n",
    "#     fit_kwargs=dict(loss=\"soft_l1\", f_scale=0.1, kwargs=dict(variance=1)),\n",
    "#     func = double_ln_normal_distribution,\n",
    "#     cost_func = double_ln_normal_distribution_cost,\n",
    "#     x0 = x0_msd,\n",
    "#     bounds= bounds_msd,\n",
    "#     t_train= t_train.mean('time'),\n",
    "#     y_train= m_train.mean('time'),\n",
    "#     plot_kwargs=dict(color=default_colors[2], linestyle=\"-\")\n",
    "#     )\n",
    "\n",
    "\n",
    "setups_msd = [\n",
    "    lqs_msd_var1,\n",
    "]  # , soft_l1, soft_l1_mean]\n",
    "setups = setups_psd + setups_msd\n",
    "\n",
    "for doublefit in setups:\n",
    "    doublefit.fit(repetitions=10)\n",
    "\n",
    "\n",
    "# --- Plot the results ---\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 6), sharex=True)\n",
    "ax0, ax1 = axs\n",
    "\n",
    "# plot the particle size distribution\n",
    "ax0.scatter(t_train, y_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax0.scatter(t_train.mean(\"time\"), y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# plot the mass size distribution\n",
    "ax1.scatter(t_train, m_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax1.scatter(t_train.mean(\"time\"), m_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# --- Plot the results ---\n",
    "for fit in setups_psd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, y = fit.predict(t)\n",
    "    m = msd_from_psd_dataarray(y)\n",
    "    lwc_psd = 1e3 * (m * w).sum(\"radius\").values\n",
    "\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "for fit in setups_msd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, m = fit.predict(t)\n",
    "    y = psd_from_msd_dataarray(m)\n",
    "    lwc_msd = 1e3 * (m * w).sum(\"radius\").values\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Fits for cloud {cloud_id}: Desired={lwc_train.values:.2f}\", fontsize=\"medium\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")\n",
    "    _ax.set_xlim(1e-6, 3.5e-3)\n",
    "axs[0].set_yscale(\"symlog\", linthresh=1.1e3, linscale=0.1)\n",
    "axs[1].set_yscale(\"symlog\", linthresh=1.1e-7, linscale=0.1)\n",
    "\n",
    "axs[0].set_ylim(1e-12, 1e14)\n",
    "axs[1].set_ylim(1e-12, 0.5e2)\n",
    "axs[0].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "axs[1].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "\n",
    "axs[0].set_ylabel(label_from_attrs(y_train, linebreak=True), fontsize=\"small\")\n",
    "axs[1].set_ylabel(label_from_attrs(m_train, linebreak=True), fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mass concentration\\n$\\\\left[  kg m^{-3} m^{-1}  \\\\right]$')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "train_data = match_clouds_and_cloudcomposite(\n",
    "    identified_clouds.sel(cloud_id=cloud_id),\n",
    "    coarse_composite,\n",
    ")\n",
    "\n",
    "t_train = train_data[\"radius2D\"]\n",
    "y_train = train_data[\"particle_size_distribution\"]\n",
    "m_train = train_data[\"mass_size_distribution\"]\n",
    "w_train = train_data[\"bin_width\"]\n",
    "lwc_train = train_data[\"liquid_water_content\"].mean(\"time\")\n",
    "\n",
    "# we can also use only the radii where we have data:\n",
    "radii_measured = train_data.max(\"time\")[\"particle_size_distribution\"] > 0\n",
    "end = train_data[\"radius\"].where(radii_measured).max(\"radius\")\n",
    "start = train_data[\"radius\"].where(radii_measured).min(\"radius\")\n",
    "end = 1.5 * end\n",
    "# create a log spaced array of radii\n",
    "r = np.geomspace(start, end, 1000)\n",
    "t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "w_test = (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "w_test = w_test.interpolate_na(\"radius\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "# t_test = t_test.where(np.isfinite(w_test), drop=True)\n",
    "# w_test = w_test.where(np.isfinite(w_test), drop=True)\n",
    "\n",
    "x0_psd = np.array([3e-6, 2, 1e10, 200e-6, 2, 1e6])\n",
    "bounds_psd = Bounds(\n",
    "    # mu1, sig1, sc1, mu2, sig2, sc2\n",
    "    lb=[1e-6, 1.1, 1e7, 200e-6, 1.1, 1e0],\n",
    "    ub=[10e-6, 3.0, 1e13, 0.5e-3, 3.0, 1e8],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "lqs_psd = LeastSquareFit(\n",
    "    name=\"PSD\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_psd,\n",
    "    bounds=bounds_psd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[0], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "# lqs_psd_var1 = LeastSquareFit(\n",
    "#     name = \"PSD nova\",\n",
    "#     fit_kwargs=dict(loss=\"linear\", kwargs = dict(variance=1)),\n",
    "#     func = double_ln_normal_distribution,\n",
    "#     cost_func = double_ln_normal_distribution_cost,\n",
    "#     x0 = x0_psd,\n",
    "#     bounds= bounds_psd,\n",
    "#     t_train= t_train.mean('time'),\n",
    "#     y_train= y_train.mean('time'),\n",
    "#     plot_kwargs=dict(color=dark_colors[0], linestyle=\"--\")\n",
    "#     )\n",
    "\n",
    "\n",
    "setups_psd = [lqs_psd]\n",
    "\n",
    "\n",
    "x0_msd = np.array([3e-6, 2, 1e-1, 300e-6, 2, 1e0])\n",
    "bounds_msd = Bounds(\n",
    "    lb=[1e-6, 1.1, 1e-3, 200e-6, 1.3, 1e-3],\n",
    "    ub=[10e-6, 3.0, 1e2, 0.5e-3, 3.0, 1e1],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "# lqs_msd = LeastSquareFit(\n",
    "#     name = \"MSD vari\",\n",
    "#     fit_kwargs=dict(loss=\"linear\"),\n",
    "#     func = double_ln_normal_distribution,\n",
    "#     cost_func = double_ln_normal_distribution_cost,\n",
    "#     x0 = x0_msd,\n",
    "#     bounds= bounds_msd,\n",
    "#     t_train= t_train.mean('time'),\n",
    "#     y_train= m_train.mean('time'),\n",
    "#     plot_kwargs=dict(color=default_colors[1], linestyle=\"-\")\n",
    "#     )\n",
    "\n",
    "lqs_msd_var1 = LeastSquareFit(\n",
    "    name=\"MSD nova\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=dark_colors[1], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "# softl1_msd = LeastSquareFit(\n",
    "#     name = \"MSD Soft\",\n",
    "#     fit_kwargs=dict(loss=\"soft_l1\", f_scale=0.1, kwargs=dict(variance=1)),\n",
    "#     func = double_ln_normal_distribution,\n",
    "#     cost_func = double_ln_normal_distribution_cost,\n",
    "#     x0 = x0_msd,\n",
    "#     bounds= bounds_msd,\n",
    "#     t_train= t_train.mean('time'),\n",
    "#     y_train= m_train.mean('time'),\n",
    "#     plot_kwargs=dict(color=default_colors[2], linestyle=\"-\")\n",
    "#     )\n",
    "\n",
    "\n",
    "setups_msd = [\n",
    "    lqs_msd_var1,\n",
    "]  # , soft_l1, soft_l1_mean]\n",
    "setups = setups_psd + setups_msd\n",
    "\n",
    "for doublefit in setups:\n",
    "    doublefit.fit(repetitions=10)\n",
    "\n",
    "\n",
    "# --- Plot the results ---\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 6), sharex=True)\n",
    "ax0, ax1 = axs\n",
    "\n",
    "# plot the particle size distribution\n",
    "ax0.scatter(t_train, y_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax0.scatter(t_train.mean(\"time\"), y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# plot the mass size distribution\n",
    "ax1.scatter(t_train, m_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax1.scatter(t_train.mean(\"time\"), m_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# --- Plot the results ---\n",
    "for fit in setups_psd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, y = fit.predict(t)\n",
    "    m = msd_from_psd_dataarray(y)\n",
    "    lwc_psd = 1e3 * (m * w).sum(\"radius\").values\n",
    "\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "for fit in setups_msd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, m = fit.predict(t)\n",
    "    y = psd_from_msd_dataarray(m)\n",
    "    lwc_msd = 1e3 * (m * w).sum(\"radius\").values\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Fits for cloud {cloud_id}: Desired={lwc_train.values:.2f}\", fontsize=\"medium\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")\n",
    "    _ax.set_xlim(1e-6, 3.5e-3)\n",
    "axs[0].set_yscale(\"linear\")\n",
    "axs[1].set_yscale(\"linear\")\n",
    "\n",
    "axs[0].set_ylim(0, 4e11)\n",
    "axs[1].set_ylim(0, 1.5)\n",
    "axs[0].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "axs[1].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "\n",
    "axs[0].set_ylabel(label_from_attrs(y_train, linebreak=True), fontsize=\"small\")\n",
    "axs[1].set_ylabel(label_from_attrs(m_train, linebreak=True), fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single LnNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2468b93c0a0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "cloud_id = rng.choice(identified_clouds[\"cloud_id\"])\n",
    "\n",
    "train_data = match_clouds_and_cloudcomposite(\n",
    "    identified_clouds.sel(cloud_id=cloud_id), coarse_composite  # .sel(radius=slice(50e-6, None)),\n",
    ")\n",
    "\n",
    "t_train = train_data[\"radius2D\"]\n",
    "y_train = train_data[\"particle_size_distribution\"]\n",
    "m_train = train_data[\"mass_size_distribution\"]\n",
    "w_train = train_data[\"bin_width\"]\n",
    "lwc_train = train_data[\"liquid_water_content\"].mean(\"time\")\n",
    "\n",
    "# we can also use only the radii where we have data:\n",
    "radii_measured = train_data.max(\"time\")[\"particle_size_distribution\"] > 0\n",
    "end = train_data[\"radius\"].where(radii_measured).max(\"radius\")\n",
    "start = train_data[\"radius\"].where(radii_measured).min(\"radius\")\n",
    "start = 10e-6\n",
    "# create a log spaced array of radii\n",
    "r = np.geomspace(start, end, 1000)\n",
    "t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "w_test = (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "w_test = w_test.interpolate_na(\"radius\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "# t_test = t_test.where(np.isfinite(w_test), drop=True)\n",
    "# w_test = w_test.where(np.isfinite(w_test), drop=True)\n",
    "\n",
    "\n",
    "x0_psd = np.array([200e-6, 2, 1e6])\n",
    "bounds_psd = Bounds(\n",
    "    # mu1, sig1, sc1, mu2, sig2, sc2\n",
    "    lb=[200e-6, 1.1, 1e0],\n",
    "    ub=[0.5e-3, 3.0, 1e8],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "lqs_psd = LeastSquareFit(\n",
    "    name=\"PSD vari\",\n",
    "    fit_kwargs=dict(loss=\"linear\"),\n",
    "    func=ln_normal_distribution,\n",
    "    cost_func=ln_normal_distribution_cost,\n",
    "    x0=x0_psd,\n",
    "    bounds=bounds_psd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[0], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "lqs_psd_var1 = LeastSquareFit(\n",
    "    name=\"PSD nova\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=ln_normal_distribution,\n",
    "    cost_func=ln_normal_distribution_cost,\n",
    "    x0=x0_psd,\n",
    "    bounds=bounds_psd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=dark_colors[0], linestyle=\"--\"),\n",
    ")\n",
    "\n",
    "x0_gamma = np.array([2.5, 0, 0.5e-4, 4e6])\n",
    "bounds_gamma = Bounds(\n",
    "    lb=[0, 0, 0, 0.1e7],\n",
    "    ub=[np.inf, np.inf, np.inf, 2e7],\n",
    ")\n",
    "\n",
    "gamma_lsq = LeastSquareFit(\n",
    "    name=\"Gamma\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=gamma_distribution_stats,\n",
    "    cost_func=gamma_distribution_stats_cost,\n",
    "    x0=x0_gamma,\n",
    "    bounds=bounds_gamma,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[3], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "setups_psd = [lqs_psd, lqs_psd_var1, gamma_lsq]\n",
    "\n",
    "\n",
    "x0_msd = np.array([300e-6, 2, 1e0])\n",
    "bounds_msd = Bounds(\n",
    "    lb=[200e-6, 1.3, 1e-3],\n",
    "    ub=[0.5e-3, 3.0, 1e1],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "lqs_msd = LeastSquareFit(\n",
    "    name=\"MSD vari\",\n",
    "    fit_kwargs=dict(loss=\"linear\"),\n",
    "    func=ln_normal_distribution,\n",
    "    cost_func=ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[1], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "lqs_msd_var1 = LeastSquareFit(\n",
    "    name=\"MSD nova\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=ln_normal_distribution,\n",
    "    cost_func=ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=dark_colors[1], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "softl1_msd = LeastSquareFit(\n",
    "    name=\"MSD Soft\",\n",
    "    fit_kwargs=dict(loss=\"soft_l1\", f_scale=0.1, kwargs=dict(variance=1)),\n",
    "    func=ln_normal_distribution,\n",
    "    cost_func=ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[2], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "setups_msd = [lqs_msd, lqs_msd_var1, softl1_msd]  # , soft_l1, soft_l1_mean]\n",
    "setups = setups_psd + setups_msd\n",
    "\n",
    "for doublefit in setups:\n",
    "    doublefit.fit(repetitions=3)\n",
    "\n",
    "\n",
    "# --- Plot the results ---\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(8, 4), sharex=True)\n",
    "ax0, ax1 = axs\n",
    "\n",
    "# plot the particle size distribution\n",
    "ax0.scatter(t_train, y_train, marker=\"o\", color=\"grey\")\n",
    "ax0.scatter(t_train.mean(\"time\"), y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# plot the mass size distribution\n",
    "ax1.scatter(t_train, m_train, marker=\"o\", color=\"grey\")\n",
    "ax1.scatter(t_train.mean(\"time\"), m_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# --- Plot the results ---\n",
    "for fit in setups_psd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, y = fit.predict(t)\n",
    "    m = msd_from_psd_dataarray(y)\n",
    "    total_number_concentration = (y * w).sum(\"radius\").values\n",
    "    lwc = 1e3 * (m * w).sum(\"radius\").values\n",
    "    ax0.plot(t, y, label=f\"{fit.name} N: {total_number_concentration:.2f}\", **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC: {lwc:.2f}\", **fit.plot_kwargs)\n",
    "\n",
    "for fit in setups_msd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, m = fit.predict(t)\n",
    "    y = psd_from_msd_dataarray(m)\n",
    "    total_number_concentration = (y * w).sum(\"radius\").values\n",
    "    lwc = 1e3 * (m * w).sum(\"radius\").values\n",
    "\n",
    "    ax0.plot(t, y, label=f\"{fit.name} N: {total_number_concentration:.2f}\", **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC: {lwc:.2f}\", **fit.plot_kwargs)\n",
    "\n",
    "\n",
    "lwc_train = 1e3 * (m_train * w_train).sum(\"radius\").mean(\"time\")\n",
    "total_number_concentration_train = (y_train * w_train).sum(\"radius\").mean(\"time\")\n",
    "fig.suptitle(\n",
    "    f\"Fits for cloud {cloud_id}: N: {total_number_concentration_train.values:.2f}, LWC: {lwc_train.values:.2f}\",\n",
    "    fontsize=\"medium\",\n",
    ")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")\n",
    "    _ax.set_xlim(1e-6, 0.8e-1)\n",
    "# axs[0].set_yscale(\"symlog\", linthresh=1.1e3, linscale=0.1)\n",
    "# axs[1].set_yscale(\"symlog\", linthresh=1.1e-7, linscale=0.1)\n",
    "\n",
    "axs[0].set_ylim(1e-12, 1e12)\n",
    "axs[1].set_ylim(1e-12, 0.5e2)\n",
    "axs[0].set_ylim(1e-12, 1e7)\n",
    "axs[1].set_ylim(1e-12, 0.25)\n",
    "axs[0].legend(fontsize=\"small\", loc=\"center right\")\n",
    "axs[1].legend(fontsize=\"small\", loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([2.5, 0, 0.5e-4, 3e7])\n",
    "\n",
    "gamma_lsq = LeastSquareFit(\n",
    "    name=\"Gamma\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=gamma_distribution_stats,\n",
    "    cost_func=gamma_distribution_stats_cost,\n",
    "    x0=x0,\n",
    "    bounds=Bounds(\n",
    "        lb=[0, 0, 0, 0],\n",
    "        ub=[np.inf, np.inf, np.inf, np.inf],\n",
    "    ),\n",
    "    t_train=t_train,\n",
    "    y_train=y_train,\n",
    "    plot_kwargs=dict(color=default_colors[3], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "gamma_lsq.fit(10)\n",
    "\n",
    "plt.scatter(t_train, y_train, marker=\".\", color=\"grey\")\n",
    "plt.scatter(t_train.mean(\"time\"), y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "t, y = gamma_lsq.predict(t_test)\n",
    "\n",
    "plt.plot(t, y, label=f\"{gamma_lsq.name}\", color=\"k\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole cloud set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Ln_fit(cloud_id: int, identified_clouds: xr.Dataset, coarse_composite: xr.Dataset) -> dict:\n",
    "\n",
    "    train_data = match_clouds_and_cloudcomposite(\n",
    "        identified_clouds.sel(cloud_id=cloud_id),\n",
    "        coarse_composite,\n",
    "    )\n",
    "\n",
    "    t_train = train_data[\"radius2D\"]\n",
    "    y_train = train_data[\"particle_size_distribution\"]\n",
    "    m_train = train_data[\"mass_size_distribution\"]\n",
    "    w_train = train_data[\"bin_width\"]\n",
    "    lwc_train = train_data[\"liquid_water_content\"].mean(\"time\")\n",
    "\n",
    "    # we can also use only the radii where we have data:\n",
    "    radii_measured = train_data[\"particle_size_distribution\"].mean(\"time\") > 0\n",
    "    end = train_data[\"radius\"].sel(radius=radii_measured).max().values\n",
    "    start = train_data[\"radius\"].sel(radius=radii_measured).min().values\n",
    "    start = 10e-6\n",
    "    end = 1.5 * end\n",
    "\n",
    "    # create a log spaced array of radii\n",
    "    r = np.logspace(np.log10(start), np.log10(end), 1000)\n",
    "    t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "    w_test = (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "    # w_test = w_test.interpolate_na('radius', method='linear', fill_value=\"extrapolate\")\n",
    "    t_test = t_test.where(np.isfinite(w_test), drop=True)\n",
    "    w_test = w_test.where(np.isfinite(w_test), drop=True)\n",
    "\n",
    "    x0_psd = np.array([200e-6, 2, 1e6])\n",
    "    bounds_psd = Bounds(\n",
    "        # mu1, sig1, sc1, mu2, sig2, sc2\n",
    "        lb=[200e-6, 1.1, 1e0],\n",
    "        ub=[0.5e-3, 3.0, 1e8],\n",
    "        # keep_feasible = [True, True, True, False, True, True]\n",
    "    )\n",
    "    lqs_psd = LeastSquareFit(\n",
    "        name=\"PSD vari\",\n",
    "        fit_kwargs=dict(loss=\"linear\"),\n",
    "        func=ln_normal_distribution,\n",
    "        cost_func=ln_normal_distribution_cost,\n",
    "        x0=x0_psd,\n",
    "        bounds=bounds_psd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=y_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=default_colors[0], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    lqs_psd_var1 = LeastSquareFit(\n",
    "        name=\"PSD nova\",\n",
    "        fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "        func=ln_normal_distribution,\n",
    "        cost_func=ln_normal_distribution_cost,\n",
    "        x0=x0_psd,\n",
    "        bounds=bounds_psd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=y_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=dark_colors[0], linestyle=\"--\"),\n",
    "    )\n",
    "\n",
    "    x0_gamma = np.array([2.5, 0, 0.5e-4, 1.5e7])\n",
    "    bounds_gamma = Bounds(\n",
    "        lb=[0, 0, 0, 0.05e7],\n",
    "        ub=[np.inf, np.inf, np.inf, 3e7],\n",
    "    )\n",
    "\n",
    "    gamma_lsq = LeastSquareFit(\n",
    "        name=\"Gamma\",\n",
    "        fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "        func=gamma_distribution_stats,\n",
    "        cost_func=gamma_distribution_stats_cost,\n",
    "        x0=x0_gamma,\n",
    "        bounds=bounds_gamma,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=y_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=default_colors[3], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    setups_psd = [lqs_psd, lqs_psd_var1, gamma_lsq]\n",
    "\n",
    "    x0_msd = np.array([300e-6, 2, 1e0])\n",
    "    bounds_msd = Bounds(\n",
    "        lb=[200e-6, 1.3, 1e-3],\n",
    "        ub=[0.5e-3, 3.0, 1e1],\n",
    "        # keep_feasible = [True, True, True, False, True, True]\n",
    "    )\n",
    "    lqs_msd = LeastSquareFit(\n",
    "        name=\"MSD vari\",\n",
    "        fit_kwargs=dict(loss=\"linear\"),\n",
    "        func=ln_normal_distribution,\n",
    "        cost_func=ln_normal_distribution_cost,\n",
    "        x0=x0_msd,\n",
    "        bounds=bounds_msd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=m_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=default_colors[1], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    lqs_msd_var1 = LeastSquareFit(\n",
    "        name=\"MSD nova\",\n",
    "        fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "        func=ln_normal_distribution,\n",
    "        cost_func=ln_normal_distribution_cost,\n",
    "        x0=x0_msd,\n",
    "        bounds=bounds_msd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=m_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=dark_colors[1], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    softl1_msd = LeastSquareFit(\n",
    "        name=\"MSD Soft\",\n",
    "        fit_kwargs=dict(loss=\"soft_l1\", f_scale=0.1, kwargs=dict(variance=1)),\n",
    "        func=ln_normal_distribution,\n",
    "        cost_func=ln_normal_distribution_cost,\n",
    "        x0=x0_msd,\n",
    "        bounds=bounds_msd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=m_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=default_colors[2], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    setups_msd = [lqs_msd, lqs_msd_var1, softl1_msd]  # , soft_l1, soft_l1_mean]\n",
    "    setups = setups_psd + setups_msd\n",
    "\n",
    "    for doublefit in setups:\n",
    "        doublefit.fit(5)\n",
    "\n",
    "    results = dict()\n",
    "    fits = dict()\n",
    "\n",
    "    # --- Plot the results ---\n",
    "    for fit in setups_psd:\n",
    "        t, w = t_train.mean(\"time\"), w_train\n",
    "        t, w = t_test, w_test\n",
    "\n",
    "        t, y = fit.predict(t)\n",
    "        m = msd_from_psd_dataarray(y)\n",
    "\n",
    "        total_number_concentration = (y * w).sum(\"radius\")\n",
    "        liquid_water_content = 1e3 * (m * w).sum(\"radius\")\n",
    "\n",
    "        results[fit.name] = dict(\n",
    "            total_number_concentration=total_number_concentration.values,\n",
    "            liquid_water_content=liquid_water_content.values,\n",
    "        )\n",
    "        fits[fit.name] = fit.fit_result\n",
    "\n",
    "    for fit in setups_msd:\n",
    "        t, w = t_train.mean(\"time\"), w_train\n",
    "        t, w = t_test, w_test\n",
    "\n",
    "        t, m = fit.predict(t)\n",
    "        y = psd_from_msd_dataarray(m)\n",
    "\n",
    "        total_number_concentration = (y * w).sum(\"radius\")\n",
    "        liquid_water_content = 1e3 * (m * w).sum(\"radius\")\n",
    "\n",
    "        results[fit.name] = dict(\n",
    "            total_number_concentration=total_number_concentration.values,\n",
    "            liquid_water_content=liquid_water_content.values,\n",
    "        )\n",
    "        fits[fit.name] = fit.fit_result\n",
    "\n",
    "    return results, fits\n",
    "\n",
    "\n",
    "def calc_doubleLn_fit(\n",
    "    cloud_id: int, identified_clouds: xr.Dataset, coarse_composite: xr.Dataset\n",
    ") -> dict:\n",
    "\n",
    "    train_data = match_clouds_and_cloudcomposite(\n",
    "        identified_clouds.sel(cloud_id=cloud_id),\n",
    "        coarse_composite,\n",
    "    )\n",
    "\n",
    "    t_train = train_data[\"radius2D\"]\n",
    "    y_train = train_data[\"particle_size_distribution\"]\n",
    "    m_train = train_data[\"mass_size_distribution\"]\n",
    "    w_train = train_data[\"bin_width\"]\n",
    "    lwc_train = train_data[\"liquid_water_content\"].mean(\"time\")\n",
    "\n",
    "    # we can also use only the radii where we have data:\n",
    "    radii_measured = train_data[\"particle_size_distribution\"].mean(\"time\") > 0\n",
    "    end = train_data[\"radius\"].sel(radius=radii_measured).max().values\n",
    "    start = train_data[\"radius\"].sel(radius=radii_measured).min().values\n",
    "    end = 1.5 * end\n",
    "    # create a log spaced array of radii\n",
    "    r = np.logspace(np.log10(start), np.log10(end), 1000)\n",
    "    t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "    w_test = 0.5 * (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "    # w_test = w_test.interpolate_na('radius', method='linear', fill_value=\"extrapolate\")\n",
    "    t_test = t_test.where(np.isfinite(w_test), drop=True)\n",
    "    w_test = w_test.where(np.isfinite(w_test), drop=True)\n",
    "\n",
    "    x0_psd = np.array([3e-6, 2, 1e10, 200e-6, 2, 1e6])\n",
    "    bounds_psd = Bounds(\n",
    "        # mu1, sig1, sc1, mu2, sig2, sc2\n",
    "        lb=[1e-6, 1.1, 1e7, 200e-6, 1.1, 1e0],\n",
    "        ub=[10e-6, 3.0, 1e13, 0.5e-3, 3.0, 1e8],\n",
    "        # keep_feasible = [True, True, True, False, True, True]\n",
    "    )\n",
    "    lqs_psd = LeastSquareFit(\n",
    "        name=\"PSD vari\",\n",
    "        fit_kwargs=dict(loss=\"linear\"),\n",
    "        func=double_ln_normal_distribution,\n",
    "        cost_func=double_ln_normal_distribution_cost,\n",
    "        x0=x0_psd,\n",
    "        bounds=bounds_psd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=y_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=default_colors[0], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    lqs_psd_var1 = LeastSquareFit(\n",
    "        name=\"PSD nova\",\n",
    "        fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "        func=double_ln_normal_distribution,\n",
    "        cost_func=double_ln_normal_distribution_cost,\n",
    "        x0=x0_psd,\n",
    "        bounds=bounds_psd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=y_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=dark_colors[0], linestyle=\"--\"),\n",
    "    )\n",
    "\n",
    "    setups_psd = [lqs_psd, lqs_psd_var1]\n",
    "\n",
    "    x0_msd = np.array([3e-6, 2, 1e-1, 300e-6, 2, 1e0])\n",
    "    bounds_msd = Bounds(\n",
    "        lb=[1e-6, 1.1, 1e-3, 200e-6, 1.3, 1e-3],\n",
    "        ub=[10e-6, 4.0, 1e2, 0.5e-3, 3.0, 1e1],\n",
    "        # keep_feasible = [True, True, True, False, True, True]\n",
    "    )\n",
    "    lqs_msd = LeastSquareFit(\n",
    "        name=\"MSD vari\",\n",
    "        fit_kwargs=dict(loss=\"linear\"),\n",
    "        func=double_ln_normal_distribution,\n",
    "        cost_func=double_ln_normal_distribution_cost,\n",
    "        x0=x0_msd,\n",
    "        bounds=bounds_msd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=m_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=default_colors[1], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    lqs_msd_var1 = LeastSquareFit(\n",
    "        name=\"MSD nova\",\n",
    "        fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "        func=double_ln_normal_distribution,\n",
    "        cost_func=double_ln_normal_distribution_cost,\n",
    "        x0=x0_msd,\n",
    "        bounds=bounds_msd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=m_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=dark_colors[1], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    softl1_msd = LeastSquareFit(\n",
    "        name=\"MSD Soft\",\n",
    "        fit_kwargs=dict(loss=\"soft_l1\", f_scale=0.1, kwargs=dict(variance=1)),\n",
    "        func=double_ln_normal_distribution,\n",
    "        cost_func=double_ln_normal_distribution_cost,\n",
    "        x0=x0_msd,\n",
    "        bounds=bounds_msd,\n",
    "        t_train=t_train.mean(\"time\"),\n",
    "        y_train=m_train.mean(\"time\"),\n",
    "        plot_kwargs=dict(color=default_colors[2], linestyle=\"-\"),\n",
    "    )\n",
    "\n",
    "    setups_msd = [lqs_msd, lqs_msd_var1, softl1_msd]  # , soft_l1, soft_l1_mean]\n",
    "    setups = setups_psd + setups_msd\n",
    "\n",
    "    for doublefit in setups:\n",
    "        doublefit.fit()\n",
    "\n",
    "    results = dict()\n",
    "    fits = dict()\n",
    "\n",
    "    # --- Plot the results ---\n",
    "    for fit in setups_psd:\n",
    "        t, w = t_train.mean(\"time\"), w_train\n",
    "        t, w = t_test, w_test\n",
    "\n",
    "        t, y = fit.predict(t)\n",
    "        m = msd_from_psd_dataarray(y)\n",
    "\n",
    "        total_number_concentration = (y * w).sum(\"radius\")\n",
    "        liquid_water_content = 1e3 * (m * w).sum(\"radius\")\n",
    "\n",
    "        results[fit.name] = dict(\n",
    "            total_number_concentration=total_number_concentration.values,\n",
    "            liquid_water_content=liquid_water_content.values,\n",
    "        )\n",
    "        fits[fit.name] = fit.fit_result\n",
    "\n",
    "    for fit in setups_msd:\n",
    "        t, w = t_train.mean(\"time\"), w_train\n",
    "        t, w = t_test, w_test\n",
    "\n",
    "        t, m = fit.predict(t)\n",
    "        y = psd_from_msd_dataarray(m)\n",
    "\n",
    "        total_number_concentration = (y * w).sum(\"radius\")\n",
    "        liquid_water_content = 1e3 * (m * w).sum(\"radius\")\n",
    "\n",
    "        results[fit.name] = dict(\n",
    "            total_number_concentration=total_number_concentration.values,\n",
    "            liquid_water_content=liquid_water_content.values,\n",
    "        )\n",
    "        fits[fit.name] = fit\n",
    "\n",
    "    return results, fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing function\n",
    "def transpose_dict(d):\n",
    "    transposed = {}\n",
    "    for cloud_id, cloud_dict in d.items():\n",
    "        for fit_type, fit_dict in cloud_dict.items():\n",
    "            for metric_key, metric in fit_dict.items():\n",
    "                if fit_type not in transposed:\n",
    "                    transposed[fit_type] = {}\n",
    "                if metric_key not in transposed[fit_type]:\n",
    "                    transposed[fit_type][metric_key] = {}\n",
    "                transposed[fit_type][metric_key][cloud_id] = float(metric)\n",
    "\n",
    "    return transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### whole radii range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "fit_results = {}\n",
    "error_clouds = []\n",
    "for cloud_id in identified_clouds[\"cloud_id\"]:\n",
    "    cloud_id = identified_clouds[\"cloud_id\"].sel(cloud_id=cloud_id)\n",
    "    cloud_id_str = str(cloud_id.values)\n",
    "    try:\n",
    "        results, fits = calc_doubleLn_fit(\n",
    "            cloud_id=cloud_id,\n",
    "            identified_clouds=identified_clouds,\n",
    "            coarse_composite=coarse_composite,\n",
    "        )\n",
    "        all_results[cloud_id_str] = results\n",
    "        fit_results[cloud_id_str] = fits\n",
    "    except:\n",
    "        error_clouds.append(cloud_id)\n",
    "        print(f\"error at {cloud_id_str}\")\n",
    "        continue\n",
    "\n",
    "transposed_data = transpose_dict(all_results)\n",
    "cloud_ids = identified_clouds[\"cloud_id\"].data\n",
    "cloud_ids = cloud_ids[~np.isin(cloud_ids, error_clouds)]\n",
    "\n",
    "lwc_observations = []\n",
    "lwc_observations_var = []\n",
    "for cloud_id in cloud_ids:\n",
    "    cc = match_clouds_and_cloudcomposite(\n",
    "        identified_clouds.sel(cloud_id=cloud_id),\n",
    "        cloud_composite,\n",
    "    )\n",
    "    m, v = mean_and_stderror_of_mean(cc[\"liquid_water_content\"], dims=(\"time\",))\n",
    "\n",
    "    lwc_observations.append(m)\n",
    "    lwc_observations_var.append(v)\n",
    "\n",
    "lwc_fits = dict()\n",
    "for fit_type, fit_dict in transposed_data.items():\n",
    "    metric_dict = fit_dict[\"liquid_water_content\"]\n",
    "    keys = np.array(list(metric_dict.keys())).astype(int)\n",
    "    lwc_fit = np.array(list(metric_dict.values()))\n",
    "    lwc_fits[fit_type] = ([\"cloud_id\"], lwc_fit)\n",
    "\n",
    "\n",
    "dataset_lwc = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        observations=([\"cloud_id\"], lwc_observations),\n",
    "        observations_var=([\"cloud_id\"], lwc_observations_var),\n",
    "        **lwc_fits,\n",
    "    ),\n",
    "    coords=dict(cloud_id=cloud_ids),\n",
    "    attrs=dict(\n",
    "        setup=\"Coarse\",\n",
    "    ),\n",
    ")\n",
    "fits_allradii = fit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(6, 7), sharex=True, sharey=True)\n",
    "\n",
    "axs = axs.flatten()\n",
    "import itertools\n",
    "\n",
    "marker_iter = itertools.cycle((\"x\", \"+\"))\n",
    "color_iter = itertools.cycle(default_colors)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for fit_type in list(dataset_lwc.data_vars)[2:]:\n",
    "    marker = next(marker_iter)\n",
    "    color = next(color_iter)\n",
    "\n",
    "    observations = dataset_lwc[\"observations\"]\n",
    "    fit = dataset_lwc[fit_type]\n",
    "\n",
    "    corr = np.corrcoef(observations, fit)[0, 1]\n",
    "    axs[i].scatter(observations, fit, label=f\"{fit_type}\", marker=marker, color=color)\n",
    "    axs[i].set_xlabel(r\"LWC obs [$g m^{-3}$]\")\n",
    "    axs[i].set_ylabel(r\"LWC fit [$g m^{-3}$]\")\n",
    "    axs[i].set_title(f\"{fit_type} {corr:.2f}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "for _ax in axs:\n",
    "\n",
    "    _ax.set_xlim(0, 0.6)\n",
    "    _ax.set_ylim(0, 0.6)\n",
    "    _ax.set_xscale(\"linear\")\n",
    "    _ax.set_yscale(\"linear\")\n",
    "    _ax.plot(_ax.get_xlim(), _ax.get_xlim(), \"k--\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### radii above 50um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error at 8\n",
      "error at 13\n",
      "error at 14\n",
      "error at 22\n",
      "error at 23\n",
      "error at 36\n",
      "error at 79\n",
      "error at 100\n",
      "error at 115\n",
      "error at 116\n",
      "error at 147\n",
      "error at 183\n",
      "error at 184\n",
      "error at 189\n",
      "error at 229\n",
      "error at 269\n",
      "error at 299\n",
      "error at 305\n",
      "error at 308\n",
      "error at 310\n",
      "error at 317\n",
      "error at 380\n",
      "error at 390\n",
      "error at 409\n",
      "error at 445\n",
      "error at 565\n",
      "error at 571\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "fit_results = {}\n",
    "error_clouds = []\n",
    "\n",
    "for cloud_id in identified_clouds[\"cloud_id\"]:\n",
    "    cloud_id = identified_clouds[\"cloud_id\"].sel(cloud_id=cloud_id)\n",
    "    cloud_id_str = str(cloud_id.values)\n",
    "    try:\n",
    "        results, fits = calc_Ln_fit(\n",
    "            cloud_id=cloud_id,\n",
    "            identified_clouds=identified_clouds,\n",
    "            coarse_composite=coarse_composite.sel(radius=slice(50e-6, None)),\n",
    "        )\n",
    "        all_results[cloud_id_str] = results\n",
    "        fit_results[cloud_id_str] = fits\n",
    "    except:\n",
    "        error_clouds.append(cloud_id)\n",
    "        print(f\"error at {cloud_id_str}\")\n",
    "        continue\n",
    "\n",
    "transposed_data = transpose_dict(all_results)\n",
    "\n",
    "lwc_observations = []\n",
    "lwc_rain_observations = []\n",
    "\n",
    "cloud_ids = identified_clouds[\"cloud_id\"].data\n",
    "cloud_ids = cloud_ids[~np.isin(cloud_ids, error_clouds)]\n",
    "\n",
    "for cloud_id in cloud_ids:\n",
    "    cc = match_clouds_and_cloudcomposite(\n",
    "        identified_clouds.sel(cloud_id=cloud_id),\n",
    "        coarse_composite,\n",
    "    )\n",
    "    lwc_observations.append(cc[\"liquid_water_content\"].mean(\"time\"))\n",
    "\n",
    "lwc_fits = dict()\n",
    "for fit_type, fit_dict in transposed_data.items():\n",
    "    metric_dict = fit_dict[\"liquid_water_content\"]\n",
    "    keys = np.array(list(metric_dict.keys())).astype(int)\n",
    "    lwc_fit = np.array(list(metric_dict.values()))\n",
    "    lwc_fits[fit_type] = ([\"cloud_id\"], lwc_fit)\n",
    "\n",
    "\n",
    "dataset_lwc_split = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        observations=([\"cloud_id\"], lwc_observations),\n",
    "        **lwc_fits,\n",
    "    ),\n",
    "    coords=dict(cloud_id=cloud_ids),\n",
    "    attrs=dict(setup=\"Coarse Rain Only\"),\n",
    ")\n",
    "\n",
    "fits_50radii = fit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(6, 7), sharex=True, sharey=True)\n",
    "\n",
    "axs = axs.flatten()\n",
    "import itertools\n",
    "\n",
    "marker_iter = itertools.cycle((\"x\", \"+\"))\n",
    "color_iter = itertools.cycle(default_colors)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for fit_type in list(dataset_lwc_split.data_vars)[1:]:\n",
    "    marker = next(marker_iter)\n",
    "    color = next(color_iter)\n",
    "\n",
    "    observations = dataset_lwc_split[\"observations\"]\n",
    "    fit = dataset_lwc_split[fit_type]\n",
    "\n",
    "    corr = np.corrcoef(observations, fit)[0, 1]\n",
    "    axs[i].scatter(observations, fit, label=f\"{fit_type}\", marker=marker, color=color)\n",
    "    axs[i].set_title(f\"{fit_type} {corr:.2f}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "for _ax in axs:\n",
    "\n",
    "    _ax.set_xlim(0, 0.6)\n",
    "    _ax.set_ylim(0, 0.6)\n",
    "    _ax.set_xscale(\"linear\")\n",
    "    _ax.set_yscale(\"linear\")\n",
    "    _ax.plot(_ax.get_xlim(), _ax.get_xlim(), \"k--\")\n",
    "\n",
    "fig.supxlabel(r\"LWC obs [$g m^{-3}$]\")\n",
    "fig.supylabel(r\"LWC fit [$g m^{-3}$]\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radii above 50um AND NOT coarsened "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error at 8\n",
      "error at 13\n",
      "error at 14\n",
      "error at 22\n",
      "error at 23\n",
      "error at 36\n",
      "error at 79\n",
      "error at 100\n",
      "error at 115\n",
      "error at 116\n",
      "error at 147\n",
      "error at 183\n",
      "error at 184\n",
      "error at 189\n",
      "error at 229\n",
      "error at 269\n",
      "error at 299\n",
      "error at 305\n",
      "error at 308\n",
      "error at 310\n",
      "error at 317\n",
      "error at 380\n",
      "error at 404\n",
      "error at 409\n",
      "error at 445\n",
      "error at 565\n",
      "error at 571\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "fit_results = {}\n",
    "error_clouds = []\n",
    "for cloud_id in identified_clouds[\"cloud_id\"]:\n",
    "    cloud_id = identified_clouds[\"cloud_id\"].sel(cloud_id=cloud_id)\n",
    "    cloud_id_str = str(cloud_id.values)\n",
    "    try:\n",
    "        results, fits = calc_Ln_fit(\n",
    "            cloud_id=cloud_id,\n",
    "            identified_clouds=identified_clouds,\n",
    "            coarse_composite=cloud_composite.sel(radius=slice(50e-6, None)),\n",
    "        )\n",
    "        all_results[cloud_id_str] = results\n",
    "        fit_results[cloud_id_str] = fits\n",
    "\n",
    "    except:\n",
    "        error_clouds.append(cloud_id)\n",
    "        print(f\"error at {cloud_id_str}\")\n",
    "        continue\n",
    "\n",
    "transposed_data = transpose_dict(all_results)\n",
    "\n",
    "lwc_observations = []\n",
    "\n",
    "cloud_ids = identified_clouds[\"cloud_id\"].data\n",
    "cloud_ids = cloud_ids[~np.isin(cloud_ids, error_clouds)]\n",
    "\n",
    "for cloud_id in cloud_ids:\n",
    "    cc = match_clouds_and_cloudcomposite(\n",
    "        identified_clouds.sel(cloud_id=cloud_id),\n",
    "        coarse_composite,\n",
    "    )\n",
    "    lwc_observations.append(cc[\"liquid_water_content\"].mean(\"time\"))\n",
    "\n",
    "lwc_fits = dict()\n",
    "for fit_type, fit_dict in transposed_data.items():\n",
    "    metric_dict = fit_dict[\"liquid_water_content\"]\n",
    "    keys = np.array(list(metric_dict.keys())).astype(int)\n",
    "    lwc_fit = np.array(list(metric_dict.values()))\n",
    "    lwc_fits[fit_type] = ([\"cloud_id\"], lwc_fit)\n",
    "\n",
    "\n",
    "dataset_lwc_split_nocoarse = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        observations=([\"cloud_id\"], lwc_observations),\n",
    "        **lwc_fits,\n",
    "    ),\n",
    "    coords=dict(cloud_id=cloud_ids),\n",
    "    attrs=dict(\n",
    "        setup=\"Original Rain Only\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(6, 7), sharex=True, sharey=True)\n",
    "\n",
    "axs = axs.flatten()\n",
    "import itertools\n",
    "\n",
    "marker_iter = itertools.cycle((\"x\", \"+\"))\n",
    "color_iter = itertools.cycle([\"k\"] + default_colors)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for fit_type in list(dataset_lwc_split_nocoarse.data_vars)[2:]:\n",
    "    marker = next(marker_iter)\n",
    "    color = next(color_iter)\n",
    "\n",
    "    observations = dataset_lwc_split_nocoarse[\"observations\"]\n",
    "    fit = dataset_lwc_split_nocoarse[fit_type]\n",
    "\n",
    "    corr = np.corrcoef(observations, fit)[0, 1]\n",
    "    axs[i].scatter(observations, fit, label=f\"{fit_type}\", marker=marker, color=color)\n",
    "    axs[i].set_title(f\"{fit_type} {corr:.2f}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "for _ax in axs:\n",
    "\n",
    "    _ax.set_xlim(0, 0.6)\n",
    "    _ax.set_ylim(0, 0.6)\n",
    "    _ax.set_xscale(\"linear\")\n",
    "    _ax.set_yscale(\"linear\")\n",
    "    _ax.plot(_ax.get_xlim(), _ax.get_xlim(), \"k--\")\n",
    "\n",
    "fig.supxlabel(r\"LWC obs [$g m^{-3}$]\")\n",
    "fig.supylabel(r\"LWC fit [$g m^{-3}$]\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare all setups of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=2, figsize=(10, 6), sharex=True, sharey=True)\n",
    "\n",
    "axs_psd = axs[0]\n",
    "axs_msd = axs[1]\n",
    "\n",
    "for ax, ds in zip(\n",
    "    axs_psd,\n",
    "    [dataset_lwc, dataset_lwc_split, dataset_lwc_split_nocoarse],\n",
    "):\n",
    "    observations = ds[\"observations\"]\n",
    "    fit = ds[\"PSD vari\"]\n",
    "\n",
    "    corr = np.corrcoef(observations, fit)[0, 1]\n",
    "    total_diff = np.abs(observations - fit).mean()\n",
    "    relative_diff = np.abs((observations - fit) / observations).mean()\n",
    "\n",
    "    ax.scatter(observations, fit, label=f\"{fit_type}\", marker=marker, color=color)\n",
    "    ax.set_title(\n",
    "        f\"{ds.attrs['setup']}\\ncorr: {corr:.2f} diff: {total_diff:.2f} rel.diff: {relative_diff:.2f}\"\n",
    "    )\n",
    "\n",
    "for ax, ds in zip(\n",
    "    axs_msd,\n",
    "    [dataset_lwc, dataset_lwc_split, dataset_lwc_split_nocoarse],\n",
    "):\n",
    "    observations = ds[\"observations\"]\n",
    "    fit = ds[\"MSD nova\"]\n",
    "\n",
    "    corr = np.corrcoef(observations, fit)[0, 1]\n",
    "    total_diff = np.abs(observations - fit).mean()\n",
    "    relative_diff = np.abs((observations - fit) / observations).mean()\n",
    "    ax.scatter(observations, fit, label=f\"{fit_type}\", marker=marker, color=color)\n",
    "    ax.set_title(\n",
    "        f\"{ds.attrs['setup']}\\ncorr: {corr:.2f} diff: {total_diff:.2f} rel.diff: {relative_diff:.2f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "for _ax in axs.flatten():\n",
    "\n",
    "    _ax.set_xlim(0, 1)\n",
    "    _ax.set_ylim(0, 1)\n",
    "    _ax.set_xscale(\"linear\")\n",
    "    _ax.set_yscale(\"linear\")\n",
    "    _ax.plot(_ax.get_xlim(), _ax.get_xlim(), \"k--\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best setup: whole radii range and MSD fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "observations = dataset_lwc[\"observations\"]\n",
    "observations_var = dataset_lwc[\"observations_var\"]\n",
    "fit = dataset_lwc[\"MSD nova\"]\n",
    "fit.name = r\"Fit to MSD with radius limited and coarsening above 50$\\mu m$\"\n",
    "\n",
    "observations = observations.where(observations >= 0.1)\n",
    "\n",
    "args = np.isfinite(observations) & np.isfinite(fit)\n",
    "corr = np.corrcoef(observations[args], fit[args])[0, 1]\n",
    "diff = observations - fit\n",
    "relative_diff = (observations - fit) / observations\n",
    "total_diff_mean, total_diff_std = diff.mean(\"cloud_id\"), diff.std(\"cloud_id\")\n",
    "relative_diff_mean, relative_diff_std = relative_diff.mean(\"cloud_id\"), relative_diff.std(\"cloud_id\")\n",
    "\n",
    "for _ax in axs:\n",
    "    # _ax.scatter(observations, fit, label=f\"{fit.name}\", marker=marker, color=color)\n",
    "    _ax.errorbar(\n",
    "        x=observations,\n",
    "        xerr=observations_var,\n",
    "        y=fit,\n",
    "        yerr=0,\n",
    "        linestyle=\"\",\n",
    "        label=f\"{fit.name}\",\n",
    "        marker=marker,\n",
    "        color=color,\n",
    "    )\n",
    "    _ax.plot((0, 2), (0, 2), \"k--\")\n",
    "    _ax.set_xlabel(r\"LWC obs [$g m^{-3}$]\")\n",
    "    _ax.set_ylabel(r\"LWC fit [$g m^{-3}$]\")\n",
    "\n",
    "axs[0].set_xlim(0, 2)\n",
    "axs[0].set_ylim(0, 2)\n",
    "axs[1].set_xlim(0, 0.6)\n",
    "axs[1].set_ylim(0, 0.6)\n",
    "\n",
    "str_corr = f\"{corr:.2f}\"\n",
    "str_total_diff = rf\"{total_diff_mean:.2f}$\\pm${total_diff_std:.2f}\" + r\"$g m^{-3}$\"\n",
    "str_relative_diff = rf\"{100* relative_diff_mean:.0f}$\\pm${100* relative_diff_std:.0f}\" + r\"$\\%$\"\n",
    "\n",
    "fig.suptitle(f\"{fit.name}\\ncorr: {str_corr} diff: {str_total_diff} rel.diff: {str_relative_diff}\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "observations = dataset_lwc[\"observations\"]\n",
    "observations_var = dataset_lwc[\"observations_var\"]\n",
    "fit = dataset_lwc[\"PSD vari\"]\n",
    "fit.name = r\"Fit to PSD with radius limited and coarsening above 50$\\mu m$\"\n",
    "\n",
    "observations = observations.where(observations >= 0.1)\n",
    "\n",
    "args = np.isfinite(observations) & np.isfinite(fit)\n",
    "corr = np.corrcoef(observations[args], fit[args])[0, 1]\n",
    "diff = observations - fit\n",
    "relative_diff = (observations - fit) / observations\n",
    "total_diff_mean, total_diff_std = diff.mean(\"cloud_id\"), diff.std(\"cloud_id\")\n",
    "relative_diff_mean, relative_diff_std = relative_diff.mean(\"cloud_id\"), relative_diff.std(\"cloud_id\")\n",
    "\n",
    "\n",
    "for _ax in axs:\n",
    "    # _ax.scatter(observations, fit, label=f\"{fit.name}\", marker=marker, color=color)\n",
    "    _ax.errorbar(\n",
    "        x=observations,\n",
    "        xerr=observations_var,\n",
    "        y=fit,\n",
    "        yerr=0,\n",
    "        linestyle=\"\",\n",
    "        label=f\"{fit.name}\",\n",
    "        marker=marker,\n",
    "        color=color,\n",
    "    )\n",
    "    _ax.plot((0, 2), (0, 2), \"k--\")\n",
    "    _ax.set_xlabel(r\"LWC obs [$g m^{-3}$]\")\n",
    "    _ax.set_ylabel(r\"LWC fit [$g m^{-3}$]\")\n",
    "\n",
    "axs[0].set_xlim(0, 2)\n",
    "axs[0].set_ylim(0, 2)\n",
    "axs[1].set_xlim(0, 0.6)\n",
    "axs[1].set_ylim(0, 0.6)\n",
    "\n",
    "str_corr = f\"{corr:.2f}\"\n",
    "str_total_diff = rf\"{total_diff_mean:.2f}$\\pm${total_diff_std:.2f}\" + r\"$g m^{-3}$\"\n",
    "str_relative_diff = rf\"{100* relative_diff_mean:.0f}$\\pm${100* relative_diff_std:.0f}\" + r\"$\\%$\"\n",
    "\n",
    "fig.suptitle(f\"{fit.name}\\ncorr: {str_corr} diff: {str_total_diff} rel.diff: {str_relative_diff}\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot all fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.geomspace(0.1e-6, 3e-3, 100)\n",
    "t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "w_test = (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "w_test = w_test.interpolate_na(\"radius\", method=\"linear\", fill_value=\"extrapolate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, m, cost, opt = [], [], [], []\n",
    "for cloud_id in fits_allradii:\n",
    "    xx, mm = fits_allradii[cloud_id][\"MSD nova\"].predict(t_test)\n",
    "    mm = w_test * mm\n",
    "    x.append(xx)\n",
    "    m.append(mm)\n",
    "    cost.append(fits_allradii[cloud_id][\"MSD nova\"].fit_result.cost)\n",
    "    opt.append(fits_allradii[cloud_id][\"MSD nova\"].fit_result.optimality)\n",
    "\n",
    "x = xr.concat(x, dim=\"cloud_id\")\n",
    "m = xr.concat(m, dim=\"cloud_id\")\n",
    "y = psd_from_msd_dataarray(m)\n",
    "\n",
    "ds = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        radius2D=x,\n",
    "        mass_size_distribution=m,\n",
    "        particle_size_distribution=y,\n",
    "        bin_width=w_test,\n",
    "    ),\n",
    "    coords=dict(radius=t_test, cloud_id=dataset_lwc[\"cloud_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'PSD [m$^{-3}$ m$^{-1}$]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [\n",
    "    220,\n",
    "]\n",
    "\n",
    "plt.plot(\n",
    "    1e6 * ds[\"radius2D\"].T,\n",
    "    ds[\"particle_size_distribution\"].T,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# plt.plot(\n",
    "#     ds[\"radius2D\"].sel(cloud_id=ids).T,\n",
    "#     ds[\"particle_size_distribution\"].sel(cloud_id=ids).T,\n",
    "#     alpha=1,\n",
    "#     linewidth=2,\n",
    "# )\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e-1, 1e9)\n",
    "plt.xlim(7e-2, 2e3)\n",
    "plt.yticks((1e0, 1e3, 1e6), minor=False)\n",
    "plt.yticks(10.0 ** np.arange(-1, 8, 1), minor=True, labels=\"\")\n",
    "plt.title(\"Particle Size Distribution\")\n",
    "plt.xlabel(\"Radius [µm]\")\n",
    "plt.ylabel(\"PSD [m$^{-3}$ m$^{-1}$]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting 14.11.2024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_id = rng.choice(\n",
    "    identified_clouds.where(\n",
    "        # (identified_clouds[\"liquid_water_content\"] / identified_clouds['duration'].dt.seconds) > 1,\n",
    "        (identified_clouds[\"liquid_water_content\"] / identified_clouds[\"duration\"].dt.seconds) > 0.4,\n",
    "        # identified_clouds['duration'].dt.seconds > 40,\n",
    "        drop=True,\n",
    "    )[\"cloud_id\"]\n",
    ")\n",
    "# cloud_id = 217 # both good\n",
    "cloud_id = 412  # both good but MSD much higher LWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "train_data = match_clouds_and_cloudcomposite(\n",
    "    identified_clouds.sel(cloud_id=cloud_id),\n",
    "    coarse_composite,\n",
    ")\n",
    "\n",
    "t_train = train_data[\"radius2D\"]\n",
    "y_train = train_data[\"particle_size_distribution\"]\n",
    "m_train = train_data[\"mass_size_distribution\"]\n",
    "w_train = train_data[\"bin_width\"]\n",
    "lwc_train = train_data[\"liquid_water_content\"].mean(\"time\")\n",
    "\n",
    "# we can also use only the radii where we have data:\n",
    "radii_measured = train_data.max(\"time\")[\"particle_size_distribution\"] > 0\n",
    "end = train_data[\"radius\"].where(radii_measured).max(\"radius\")\n",
    "start = train_data[\"radius\"].where(radii_measured).min(\"radius\")\n",
    "end = 1.5 * end\n",
    "# create a log spaced array of radii\n",
    "r = np.geomspace(start, end, 1000)\n",
    "t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "w_test = (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "w_test = w_test.interpolate_na(\"radius\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "# t_test = t_test.where(np.isfinite(w_test), drop=True)\n",
    "# w_test = w_test.where(np.isfinite(w_test), drop=True)\n",
    "\n",
    "x0_psd = np.array([8e-6, 2, 1e10, 200e-6, 2, 1e6])\n",
    "bounds_psd = Bounds(\n",
    "    # mu1, sig1, sc1, mu2, sig2, sc2\n",
    "    lb=[1e-6, 1.1, 1e7, 200e-6, 1.1, 1e0],\n",
    "    ub=[10e-6, 3.0, 1e13, 0.5e-3, 3.0, 1e8],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "lqs_psd = LeastSquareFit(\n",
    "    name=\"PSD\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_psd,\n",
    "    bounds=bounds_psd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=y_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=default_colors[0], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "setups_psd = [lqs_psd]\n",
    "\n",
    "\n",
    "x0_msd = np.array([8e-6, 2, 1e-1, 300e-6, 2, 1e0])\n",
    "bounds_msd = Bounds(\n",
    "    lb=[1e-6, 1.1, 1e-3, 200e-6, 1.3, 1e-3],\n",
    "    ub=[10e-6, 3.0, 1e2, 0.5e-3, 3.0, 1e1],\n",
    "    # keep_feasible = [True, True, True, False, True, True]\n",
    ")\n",
    "\n",
    "lqs_msd_var1 = LeastSquareFit(\n",
    "    name=\"MSD nova\",\n",
    "    fit_kwargs=dict(loss=\"linear\", kwargs=dict(variance=1)),\n",
    "    func=double_ln_normal_distribution,\n",
    "    cost_func=double_ln_normal_distribution_cost,\n",
    "    x0=x0_msd,\n",
    "    bounds=bounds_msd,\n",
    "    t_train=t_train.mean(\"time\"),\n",
    "    y_train=m_train.mean(\"time\"),\n",
    "    plot_kwargs=dict(color=dark_colors[1], linestyle=\"-\"),\n",
    ")\n",
    "\n",
    "\n",
    "# softl1_msd = LeastSquareFit(\n",
    "#     name = \"MSD Soft\",\n",
    "#     fit_kwargs=dict(loss=\"soft_l1\", f_scale=0.1, kwargs=dict(variance=1)),\n",
    "#     func = double_ln_normal_distribution,\n",
    "#     cost_func = double_ln_normal_distribution_cost,\n",
    "#     x0 = x0_msd,\n",
    "#     bounds= bounds_msd,\n",
    "#     t_train= t_train.mean('time'),\n",
    "#     y_train= m_train.mean('time'),\n",
    "#     plot_kwargs=dict(color=default_colors[2], linestyle=\"-\")\n",
    "#     )\n",
    "\n",
    "\n",
    "setups_msd = [\n",
    "    lqs_msd_var1,\n",
    "]  # , soft_l1, soft_l1_mean]\n",
    "setups = setups_psd + setups_msd\n",
    "\n",
    "for doublefit in setups:\n",
    "    doublefit.fit(repetitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mass concentration\\n$\\\\left[  kg m^{-3} m^{-1}  \\\\right]$')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Plot the results ---\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 6), sharex=True)\n",
    "ax0, ax1 = axs\n",
    "\n",
    "# plot the particle size distribution\n",
    "ax0.scatter(t_train, y_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax0.scatter(t_train.mean(\"time\"), y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# plot the mass size distribution\n",
    "ax1.scatter(t_train, m_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax1.scatter(t_train.mean(\"time\"), m_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# --- Plot the results ---\n",
    "for fit in setups_psd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, y = fit.predict(t)\n",
    "    m = msd_from_psd_dataarray(y)\n",
    "    lwc_psd = 1e3 * (m * w).sum(\"radius\").values\n",
    "\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "for fit in setups_msd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, m = fit.predict(t)\n",
    "    y = psd_from_msd_dataarray(m)\n",
    "    lwc_msd = 1e3 * (m * w).sum(\"radius\").values\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Fits for cloud {cloud_id}: Desired={lwc_train.values:.2f}\", fontsize=\"medium\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")\n",
    "    _ax.set_xlim(1e-6, 3.5e-3)\n",
    "axs[0].set_yscale(\"symlog\", linthresh=1.1e3, linscale=0.1)\n",
    "axs[1].set_yscale(\"symlog\", linthresh=1.1e-7, linscale=0.1)\n",
    "\n",
    "axs[0].set_ylim(1e-12, 1e14)\n",
    "axs[1].set_ylim(1e-12, 0.5e2)\n",
    "axs[0].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "axs[1].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "\n",
    "axs[0].set_ylabel(label_from_attrs(y_train, linebreak=True), fontsize=\"small\")\n",
    "axs[1].set_ylabel(label_from_attrs(m_train, linebreak=True), fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mass concentration\\n$\\\\left[  kg m^{-3} m^{-1}  \\\\right]$')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Plot the results ---\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 6), sharex=True)\n",
    "ax0, ax1 = axs\n",
    "\n",
    "# plot the particle size distribution\n",
    "ax0.scatter(t_train, y_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax0.scatter(t_train.mean(\"time\"), y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# plot the mass size distribution\n",
    "ax1.scatter(t_train, m_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax1.scatter(t_train.mean(\"time\"), m_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# --- Plot the results ---\n",
    "for fit in setups_psd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, y = fit.predict(t)\n",
    "    m = msd_from_psd_dataarray(y)\n",
    "    lwc_psd = 1e3 * (m * w).sum(\"radius\").values\n",
    "\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "for fit in setups_msd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, m = fit.predict(t)\n",
    "    y = psd_from_msd_dataarray(m)\n",
    "    lwc_msd = 1e3 * (m * w).sum(\"radius\").values\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Fits for cloud {cloud_id}: Desired={lwc_train.values:.2f}\", fontsize=\"medium\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"log\")\n",
    "    _ax.set_xlim(1e-6, 3.5e-3)\n",
    "axs[0].set_yscale(\"linear\")\n",
    "axs[1].set_yscale(\"linear\")\n",
    "\n",
    "axs[0].set_ylim(0, 4e11)\n",
    "axs[1].set_ylim(0, 1.5)\n",
    "axs[0].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "axs[1].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "\n",
    "axs[0].set_ylabel(label_from_attrs(y_train, linebreak=True), fontsize=\"small\")\n",
    "axs[1].set_ylabel(label_from_attrs(m_train, linebreak=True), fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mass concentration\\n$\\\\left[  kg m^{-3} m^{-1}  \\\\right]$')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Plot the results ---\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 6), sharex=True)\n",
    "ax0, ax1 = axs\n",
    "\n",
    "# plot the particle size distribution\n",
    "ax0.scatter(t_train, y_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax0.scatter(t_train.mean(\"time\"), y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# plot the mass size distribution\n",
    "ax1.scatter(t_train, m_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "ax1.scatter(t_train.mean(\"time\"), m_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# --- Plot the results ---\n",
    "for fit in setups_psd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, y = fit.predict(t)\n",
    "    m = msd_from_psd_dataarray(y)\n",
    "    lwc_psd = 1e3 * (m * w).sum(\"radius\").values\n",
    "\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "for fit in setups_msd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, m = fit.predict(t)\n",
    "    y = psd_from_msd_dataarray(m)\n",
    "    lwc_msd = 1e3 * (m * w).sum(\"radius\").values\n",
    "    ax0.plot(t, y, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, m, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Fits for cloud {cloud_id}: Desired={lwc_train.values:.2f}\", fontsize=\"medium\")\n",
    "\n",
    "for _ax in axs:\n",
    "    _ax.set_xscale(\"linear\")\n",
    "    _ax.set_xlim(1e-6, 3.5e-3)\n",
    "axs[0].set_yscale(\"linear\")\n",
    "axs[1].set_yscale(\"linear\")\n",
    "\n",
    "axs[0].set_ylim(0, 4e11)\n",
    "axs[1].set_ylim(0, 1.5)\n",
    "axs[0].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "axs[1].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "\n",
    "axs[0].set_ylabel(label_from_attrs(y_train, linebreak=True), fontsize=\"small\")\n",
    "axs[1].set_ylabel(label_from_attrs(m_train, linebreak=True), fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Radius [m]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Plot the results ---\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12, 6), sharex=True)\n",
    "ax0, ax1 = axs\n",
    "\n",
    "# # plot the particle size distribution\n",
    "# ax0.scatter(t_train, w_train * y_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "# ax0.scatter(t_train.mean(\"time\"), w_train * y_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "# # plot the mass size distribution\n",
    "# ax1.scatter(t_train, w_train * m_train, marker=\".\", color=\"grey\", alpha=0.5)\n",
    "# ax1.scatter(t_train.mean(\"time\"), w_train * m_train.mean(\"time\"), marker=\"o\", color=\"k\")\n",
    "\n",
    "\n",
    "# create a log spaced array of radii\n",
    "r = np.linspace(start, end, 10000)\n",
    "t_test = xr.DataArray(data=r, coords={\"radius\": r}, dims=[\"radius\"])\n",
    "w_test = (t_test - t_test.shift(radius=2)).shift(radius=-1)\n",
    "w_test = w_test.interpolate_na(\"radius\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "# t_test = t_test.where(np.isfinite(w_test), drop=True)\n",
    "# w_test = w_test.where(np.isfinite(w_test), drop=True)\n",
    "\n",
    "\n",
    "# --- Plot the results ---\n",
    "for fit in setups_psd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, y = fit.predict(t)\n",
    "    m = msd_from_psd_dataarray(y * w)\n",
    "    m = m / w\n",
    "    lwc_psd = 1e3 * (m * w).sum(\"radius\").values\n",
    "\n",
    "    ax0.plot(t, w * y, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, w * m, label=f\"{fit.name} LWC:{lwc_psd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "for fit in setups_msd:\n",
    "    # t, w = t_train.mean('time'), w_train\n",
    "    t, w = t_test, w_test\n",
    "\n",
    "    t, m = fit.predict(t)\n",
    "    y = psd_from_msd_dataarray(m * w)\n",
    "    y = y / w\n",
    "    lwc_msd = 1e3 * (m * w).sum(\"radius\").values\n",
    "    ax0.plot(t, w * y, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "    ax1.plot(t, w * m, label=f\"{fit.name} LWC:{lwc_msd:.2f}\", linewidth=2, **fit.plot_kwargs)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Fits for cloud {cloud_id}: Desired={lwc_train.values:.2f}\", fontsize=\"medium\")\n",
    "\n",
    "for _ax in axs:\n",
    "    # _ax.set_xscale(\"log\")\n",
    "    _ax.set_xlim(1e-6, 2e-3)\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[1].set_yscale(\"linear\")\n",
    "\n",
    "# axs[0].set_ylim(0, 4e11)\n",
    "# axs[1].set_ylim(0, 0.0001)\n",
    "axs[0].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "axs[1].legend(fontsize=\"small\", loc=\"upper center\")\n",
    "\n",
    "axs[0].set_ylabel(label_from_attrs(y_train, return_units=False) + r\"[$m^{-3}$]\", fontsize=\"small\")\n",
    "axs[1].set_ylabel(label_from_attrs(m_train, return_units=False) + r\"[$kg m^{-3}$]\", fontsize=\"small\")\n",
    "axs[1].set_xlabel(\"Radius [m]\", fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climNum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
