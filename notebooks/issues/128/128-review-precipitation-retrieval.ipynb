{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "\n",
    "- The precipitation values calculated from the eulerian dataset approach and the box model approach give different results.\n",
    "- We need to investigate why this is the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import awkward as ak\n",
    "from typing import Callable, Union, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "from sdm_eurec4a.visulization import set_custom_rcParams\n",
    "\n",
    "\n",
    "from pySD.sdmout_src import sdtracing\n",
    "from pySD.sdmout_src import supersdata\n",
    "from pySD.sdmout_src import pygbxsdat, pysetuptxt, supersdata\n",
    "\n",
    "set_custom_rcParams()\n",
    "strength_cmap = sns.cubehelix_palette(start=0.5, rot=-0.5, as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microphysic = \"null_microphysics\"\n",
    "# microphysic = \"condensation\"\n",
    "# microphysic = \"collision_condensation\"\n",
    "microphysic = \"coalbure_condensation_large\"\n",
    "# microphysic = \"coalbure_condensation_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading binary file:\n",
      " /home/m/m301096/CLEO/data/output_v4.0/coalbure_condensation_large/cluster_141/share/eurec4a1d_ddimlessGBxboundaries.dat\n"
     ]
    }
   ],
   "source": [
    "cloud_id = 141\n",
    "\n",
    "data_dir = Path(f\"/home/m/m301096/CLEO/data/output_v4.0/{microphysic}/cluster_{cloud_id}\")\n",
    "\n",
    "# output_dir = data_dir / \"processed\"\n",
    "# output_dir.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "# output_path = output_dir / \"eulerian_dataset.nc\"\n",
    "# output_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "setupfile_path = data_dir / \"config\" / \"eurec4a1d_setup.txt\"\n",
    "statsfile_path = data_dir / \"config\" / \"eurec4a1d_stats.txt\"\n",
    "zarr_path = data_dir / \"eurec4a1d_sol.zarr\"\n",
    "gridfile_path = data_dir / \"share/eurec4a1d_ddimlessGBxboundaries.dat\"\n",
    "\n",
    "\n",
    "# read in constants and intial setup from setup .txt file\n",
    "config = pysetuptxt.get_config(str(setupfile_path), nattrs=3, isprint=False)\n",
    "consts = pysetuptxt.get_consts(str(setupfile_path), isprint=False)\n",
    "gridbox_dict = pygbxsdat.get_gridboxes(str(gridfile_path), consts[\"COORD0\"], isprint=False)\n",
    "\n",
    "ds_zarr = xr.open_zarr(zarr_path, consolidated=False)\n",
    "ds_zarr = ds_zarr.rename({\"gbxindex\": \"gridbox\"})\n",
    "ds_zarr[\"time\"] = np.round(ds_zarr[\"time\"], 1)\n",
    "ds_zarr = ds_zarr.compute()\n",
    "\n",
    "\n",
    "ds_eulerian = xr.open_dataset(data_dir / \"processed/eulerian_dataset.nc\")\n",
    "ds_eulerian[\"time\"] = np.round(ds_eulerian[\"time\"], 1)\n",
    "ds_eulerian[\"radius_bins\"] = ds_eulerian[\"radius_bins\"].where(ds_eulerian[\"radius_bins\"] > 0, 1e-3)\n",
    "\n",
    "ds_conservation = xr.open_dataset(data_dir / \"processed/conservation_dataset.nc\")\n",
    "ds_conservation[\"time\"] = np.round(ds_conservation[\"time\"], 1)\n",
    "ds = xr.merge([ds_eulerian, ds_conservation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"liquid_water_content\"] = 1e3 * ds[\"liquid_water_content\"]\n",
    "ds[\"liquid_water_content\"].attrs[\"units\"] = \"g/m^3\"\n",
    "ds[\"liquid_water_content\"].attrs[\"long_name\"] = \"Liquid water content\"\n",
    "\n",
    "ds[\"cloud_liquid_water_content\"] = ds[\"liquid_water_content\"].isel(gridbox=-1)\n",
    "ds[\"cloud_liquid_water_content\"].attrs[\"long_name\"] = \"Cloud liquid water content\"\n",
    "\n",
    "ds[\"source\"].attrs[\"long_name\"] = \"Evaporation\"\n",
    "ds[\"inflow\"].attrs[\"long_name\"] = \"Cloud Base Precipitation Flux\"\n",
    "ds[\"outflow\"].attrs[\"long_name\"] = \"Surface Precipitation Flux\"\n",
    "\n",
    "# from kg/m^3/s\n",
    "\n",
    "# # to mg/m^3/h\n",
    "# ds['evaporation_rate']  = - ds['massdelta_condensation'] * 1e6 * 3600\n",
    "# ds['evaporation_rate'].attrs['units'] = 'mg/m^3/h'\n",
    "# ds['evaporation_rate'].attrs['long_name'] = 'Evaporation rate'\n",
    "\n",
    "# to mm/m/h\n",
    "rho_water = 1000  # kg / m^3\n",
    "ds[\"evaporation_rate\"] = -1e3 / rho_water * ds[\"massdelta_condensation\"] * 3600\n",
    "ds[\"evaporation_rate\"].attrs[\"units\"] = \"mm/h/m\"\n",
    "ds[\"evaporation_rate\"].attrs[\"long_name\"] = \"Evaporation rate\"\n",
    "\n",
    "for var in [\"source\", \"inflow\", \"outflow\", \"reservoir_change\"]:\n",
    "    attrs = ds[var].attrs.copy()\n",
    "    # from  kg per dT per domain area\n",
    "    # dT = 2s\n",
    "\n",
    "    # # to    g per h per m^2\n",
    "    # ds[var] = ds[var] / 2 * 3600 / ds['surface_area'] * 1e6\n",
    "    # ds[var].attrs.update(attrs)\n",
    "    # ds[var].attrs['units'] = 'mg/m^2/h'\n",
    "\n",
    "    # to    mm / h\n",
    "    rho_water = 1000  # kg / m^3\n",
    "    ds[var] = ds[var] / 2 * 3600 / ds[\"surface_area\"]  # kg / m^2 / h\n",
    "    ds[var] = 1e3 * ds[var] / rho_water  # mm / h\n",
    "    ds[var].attrs.update(attrs)\n",
    "    ds[var].attrs[\"units\"] = \"mm/h\"\n",
    "\n",
    "\n",
    "ds[\"evaporation_fraction\"] = -100 * ds[\"source\"] / ds[\"inflow\"]\n",
    "ds[\"evaporation_fraction\"].attrs[\"units\"] = \"\\\\%\"\n",
    "ds[\"evaporation_fraction\"].attrs[\"long_name\"] = \"Evaporation fraction\"\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffe3c0dca10>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    ds[\"mass_left\"].sum(\"radius_bins\", skipna=True).sel(gridbox=0)\n",
    "    / ds[\"precipitation\"].sum(\"radius_bins\", skipna=True)\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estiamtion of the precipitation and outflow with the two methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eulerian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ak_differentiate(sa: supersdata.SupersAttribute) -> supersdata.SupersAttribute:\n",
    "    \"\"\"\n",
    "    This function calculates the difference of the data in the\n",
    "    supersdata.SupersAttribute along the last axis. The difference is calculated as the\n",
    "    difference of the next value minus the current value. The last value is set to nan,\n",
    "    to make sure, that the mass change is at the same timestep, as the original value.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function is designed to work with awkward arrays\n",
    "    - It is intended to be used on relatively regular arrays, where the last axis has at least 1 value or best 2 values.\n",
    "    - Arrays which are empty along the last axis will be filled with a nan after execution. So use this function with caution due to high increase in memory usage.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sa : supersdata.SupersAttribute\n",
    "        The attribute, which should be differentiated.\n",
    "        Assuming it has the shape (N, M, var), the differentiation is done along the last axis.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    supersdata.SupersAttribute\n",
    "        The differentiated attribute.\n",
    "        The output has the same shape as the input, but the last value along the last axis is nan.\n",
    "        The new name of the attribute is the old name with \"_difference\" appended.\n",
    "        All metadata is copied and the long_name is appended with \"difference\".\n",
    "    \"\"\"\n",
    "\n",
    "    data = sa.data\n",
    "    # logging.info(data)\n",
    "    # It is very important, to concate the nan values at the END of the array, so that the last value is nan.\n",
    "    # This makes sure, that the mass change is at the same timestep, as the original value.\n",
    "    # With this, the evapoartion fraction can not exceed 1.\n",
    "    data: ak.Array = ak.concatenate([data, np.nan], axis=-1)\n",
    "\n",
    "    # if the data has entries, which have only one value, append another nan value\n",
    "    if ak.min(ak.num(data, axis=-1)) < 2:\n",
    "        data = ak.concatenate([data, np.nan], axis=-1)\n",
    "\n",
    "    # calculate the difference\n",
    "    diff = data[..., 1:] - data[..., :-1]\n",
    "\n",
    "    # create a new attribute\n",
    "    result = supersdata.SupersAttribute(\n",
    "        name=sa.name + \"_difference\",\n",
    "        data=diff,\n",
    "        units=sa.units,\n",
    "        metadata=sa.metadata.copy(),\n",
    "    )\n",
    "\n",
    "    # update metadata\n",
    "    updated_metadata = sa.metadata.copy()\n",
    "    try:\n",
    "        updated_metadata[\"long_name\"] = updated_metadata[\"long_name\"] + \" difference\"\n",
    "    except KeyError:\n",
    "        pass\n",
    "    result.set_metadata(metadata=updated_metadata)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def ak_last(sa: supersdata.SupersAttribute) -> supersdata.SupersAttribute:\n",
    "    \"\"\"\n",
    "    This function only keeps the last value along axis 1. The rest will be replaced by\n",
    "    nans.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function is designed to work with awkward arrays\n",
    "    - It is intended to be used on relatively regular arrays, where the last axis has at least 1 value or best 2 values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sa : supersdata.SupersAttribute\n",
    "        The attribute, which should be lasted.\n",
    "        Assuming it has the shape (N, M, var), the last values is kept along the last axis.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    supersdata.SupersAttribute\n",
    "        The lasted attribute.\n",
    "        The output has the same shape as the input, but the last value along the last axis is nan.\n",
    "        The new name of the attribute is the old name with \"_last\" appended.\n",
    "        All metadata is copied and the long_name is appended with \"last\".\n",
    "    \"\"\"\n",
    "\n",
    "    data = sa.get_data()\n",
    "\n",
    "    # in order to remove all values except the last one, we need to create a new array with the same shape\n",
    "    # data = [\n",
    "    #     [1, 2, 3, 4],\n",
    "    #     [5, 6, 7, 8],\n",
    "    #    ]\n",
    "    # after concatenate\n",
    "    # data = [\n",
    "    #     [n, n, n, n, 1],\n",
    "    #     [n, n, n, n, 1],\n",
    "    #    ]\n",
    "    # after multiplication\n",
    "    # data = [\n",
    "    #     [n, n, n, n, 4],\n",
    "    #     [n, n, n, n, 8],\n",
    "    #    ]\n",
    "    # after the slice, the result is\n",
    "    # data = [\n",
    "    #     [n, n, n, 4],\n",
    "    #     [n, n, n, 8],\n",
    "    #    ]\n",
    "\n",
    "    last = (ak.concatenate([data * np.nan, 1], axis=-1) * data[..., -1])[..., 1:]\n",
    "    # create a new attribute\n",
    "    result = supersdata.SupersAttribute(\n",
    "        name=sa.name + \"_last\",\n",
    "        data=last,\n",
    "        units=sa.units,\n",
    "        metadata=sa.metadata.copy(),\n",
    "    )\n",
    "\n",
    "    # update metadata\n",
    "    updated_metadata = sa.metadata.copy()\n",
    "    try:\n",
    "        updated_metadata[\"long_name\"] = updated_metadata[\"long_name\"] + \" last\"\n",
    "    except KeyError:\n",
    "        pass\n",
    "    result.set_metadata(metadata=updated_metadata)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_inflow_outflow_reservoir_dataset(\n",
    "    dataset: supersdata.SupersDataNew,\n",
    "    dim0_name: str = \"time\",\n",
    "    dim1_name: str = \"sdgbxindex\",\n",
    "    attribute_names: Union[Tuple[str], None, str] = None,\n",
    ") -> Tuple[\n",
    "    supersdata.SupersDataSimple,\n",
    "    supersdata.SupersDataSimple,\n",
    "    supersdata.SupersDataSimple,\n",
    "]:\n",
    "\n",
    "    # use only the Superdroplets, which are in more than one timestep!\n",
    "    # For this, the ak.num > 1\n",
    "    # An example would be this array:\n",
    "    # [\n",
    "    #      [0,1,2,3],   -> usable\n",
    "    #      [0,1],       -> usable\n",
    "    #      [0],         -> UNUSABLE\n",
    "    #      [3, 4, 5],   -> usable\n",
    "    #  ]\n",
    "    data = dataset[dim0_name].data\n",
    "    mask = ak.num(data, axis=-1) > 1\n",
    "\n",
    "    # create the empty dataset for the inflow, outflow and reservoir\n",
    "    dataset_inflow = supersdata.SupersDataSimple([])\n",
    "    dataset_outflow = supersdata.SupersDataSimple([])\n",
    "    dataset_reservoir = supersdata.SupersDataSimple([])\n",
    "\n",
    "    # if no attribute names are given, compute all attributes\n",
    "    if isinstance(attribute_names, (str,)):\n",
    "        attribute_names = (attribute_names,)\n",
    "\n",
    "    if attribute_names is None:\n",
    "        attribute_names = tuple(dataset.attributes.keys())\n",
    "\n",
    "    # iterate over all attributes and create the inflow, outflow and reservoir\n",
    "    # also iterate over the dimensions to have them avaiable for the indexing\n",
    "    for key in set(attribute_names + (dim0_name, dim1_name)):\n",
    "        # logging.info(f\"Processing variable {key}\")\n",
    "        attribute = dataset[key]\n",
    "        data = attribute.data\n",
    "        data = data[mask]\n",
    "\n",
    "        # The inflow is the second value of the array, because the first is the initialisation!\n",
    "        # The first value of the array would be in the cloud gridbox\n",
    "        inflow_array = data[:, 1]\n",
    "        # The outflow of the data is the last value along the SD-Id dimension\n",
    "        outflow_array = data[:, -1]\n",
    "        # The reservoir is the data without the first and last value of the dataset\n",
    "        reservoir_data = data[:, 1:-1]\n",
    "        reservoir_data = ak.flatten(reservoir_data, axis=-1)\n",
    "\n",
    "        dataset_inflow.set_attribute(\n",
    "            supersdata.SupersAttribute(\n",
    "                name=key, data=inflow_array, units=attribute.units, metadata=attribute.metadata\n",
    "            )\n",
    "        )\n",
    "        dataset_outflow.set_attribute(\n",
    "            supersdata.SupersAttribute(\n",
    "                name=key, data=outflow_array, units=attribute.units, metadata=attribute.metadata\n",
    "            )\n",
    "        )\n",
    "        dataset_reservoir.set_attribute(\n",
    "            supersdata.SupersAttribute(\n",
    "                name=key, data=reservoir_data, units=attribute.units, metadata=attribute.metadata\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # # logging.info(f\"Indexing the datasets\")\n",
    "    # dataset_inflow.set_attribute(dataset_inflow[dim0_name].attribute_to_indexer_unique())\n",
    "    # dataset_inflow.index_by_indexer(dataset_inflow[dim0_name])\n",
    "\n",
    "    # dataset_outflow.set_attribute(dataset_outflow[dim0_name].attribute_to_indexer_unique())\n",
    "    # dataset_outflow.index_by_indexer(dataset_outflow[dim0_name])\n",
    "\n",
    "    # dataset_reservoir.set_attribute(dataset_reservoir[dim0_name].attribute_to_indexer_unique())\n",
    "    # dataset_reservoir.set_attribute(dataset_reservoir[dim1_name].attribute_to_indexer_unique())\n",
    "    # dataset_reservoir.index_by_indexer(dataset_reservoir[dim0_name])\n",
    "    # dataset_reservoir.index_by_indexer(dataset_reservoir[dim1_name])\n",
    "\n",
    "    return dataset_inflow, dataset_outflow, dataset_reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Superdrop Properties -----\n",
      "RHO_L = 998.203 Kg/m^3\n",
      "RHO_SOL = 2016.5 Kg/m^3\n",
      "MR_SOL = 0.05844277 Kg/mol\n",
      "IONIC = 2.0\n",
      "-------------------------------\n",
      "supers dataset path:  /home/m/m301096/CLEO/data/output_v4.0/coalbure_condensation_large/cluster_141/eurec4a1d_sol.zarr\n",
      "Attribute coord1 not found in dataset\n",
      "Attribute coord2 not found in dataset\n"
     ]
    }
   ],
   "source": [
    "sd_eulerian = supersdata.SupersDataNew(\n",
    "    dataset=zarr_path,\n",
    "    consts=consts,\n",
    ")\n",
    "sd_eulerian.flatten()\n",
    "\n",
    "# ============\n",
    "# 1. Create the necessary indexes and pass if they already exist\n",
    "# ============\n",
    "# make time an indexer which corresponsd_eulerian to the unique values of the time attribute\n",
    "try:\n",
    "    sd_eulerian.set_attribute(sd_eulerian[\"time\"].attribute_to_indexer_unique())\n",
    "except KeyError:\n",
    "    pass\n",
    "try:\n",
    "    sd_eulerian.set_attribute(sd_eulerian[\"sdId\"].attribute_to_indexer_unique())\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "# ============\n",
    "# 2. Create the Lagrangian view to calculate the mass change\n",
    "# ============\n",
    "\n",
    "# bin by the superdroplet id and calcuate the difference of the mass\n",
    "sd_eulerian.index_by_indexer(index=sd_eulerian[\"sdId\"])\n",
    "\n",
    "time_diff = ak_differentiate(sd_eulerian[\"time\"])\n",
    "time_diff.set_metadata(\n",
    "    metadata={\n",
    "        \"long_name\": \"Time difference per timestep\",\n",
    "    }\n",
    ")\n",
    "time_diff.set_name(\"time_difference\")\n",
    "time_diff.set_units(\"s\")\n",
    "\n",
    "# calculate total mass which left domain\n",
    "\n",
    "sa = sd_eulerian[\"mass_represented\"]\n",
    "\n",
    "\n",
    "data = sa.get_data()\n",
    "\n",
    "# in order to remove all values except the last one, we need to create a new array with the same shape\n",
    "# data = [\n",
    "#     [1, 2, 3, 4],\n",
    "#     [5, 6, 7, 8],\n",
    "#    ]\n",
    "# after concatenate\n",
    "# data = [\n",
    "#     [n, n, n, n, 1],\n",
    "#     [n, n, n, n, 1],\n",
    "#    ]\n",
    "# after multiplication\n",
    "# data = [\n",
    "#     [n, n, n, n, 4],\n",
    "#     [n, n, n, n, 8],\n",
    "#    ]\n",
    "# after the slice, the result is\n",
    "# data = [\n",
    "#     [n, n, n, 4],\n",
    "#     [n, n, n, 8],\n",
    "#    ]\n",
    "\n",
    "last = (ak.concatenate([data * np.nan, 1], axis=-1) * data[..., -1])[..., 1:]\n",
    "# create a new attribute\n",
    "result = supersdata.SupersAttribute(\n",
    "    name=sa.name + \"_last\",\n",
    "    data=last,\n",
    "    units=sa.units,\n",
    "    metadata=sa.metadata.copy(),\n",
    ")\n",
    "\n",
    "# update metadata\n",
    "updated_metadata = sa.metadata.copy()\n",
    "try:\n",
    "    updated_metadata[\"long_name\"] = updated_metadata[\"long_name\"] + \" last\"\n",
    "except KeyError:\n",
    "    pass\n",
    "result.set_metadata(metadata=updated_metadata)\n",
    "\n",
    "mass_left = result\n",
    "mass_left.set_name(\"mass_left\")\n",
    "mass_left.set_metadata(\n",
    "    metadata={\n",
    "        \"long_name\": \"mass which left domain\",\n",
    "        \"note\": r\"this is the last represented mass which a super droplet has during the simulation.\\nMass represented by a superdroplet: $m = \\xi \\cdot m_{sd}$\",\n",
    "    }\n",
    ")\n",
    "mass_left.set_units(\"kg\")\n",
    "sd_eulerian.set_attribute(mass_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_eulerian.set_attribute(sd_eulerian[\"sdgbxindex\"].attribute_to_indexer_unique())\n",
    "sd_eulerian.set_attribute(sd_eulerian[\"time\"].attribute_to_indexer_unique())\n",
    "sd_eulerian.set_attribute(sd_eulerian[\"sdId\"].attribute_to_indexer_unique())\n",
    "sd_eulerian.set_attribute(\n",
    "    sd_eulerian[\"radius\"].attribute_to_indexer_binned(\n",
    "        bins=np.geomspace(10, 4e3, 151), new_name=\"radius_bins\"\n",
    "    )\n",
    ")\n",
    "\n",
    "sd_eulerian.flatten()\n",
    "sd_eulerian.index_by_indexer(sd_eulerian[\"time\"])\n",
    "sd_eulerian.index_by_indexer(sd_eulerian[\"sdgbxindex\"])\n",
    "sd_eulerian.index_by_indexer(sd_eulerian[\"radius_bins\"])\n",
    "\n",
    "da_sd_eulerian = sd_eulerian.attribute_to_DataArray_reduction(\n",
    "    attribute_name=\"mass_left\",\n",
    "    reduction_func=ak.nansum,\n",
    ")\n",
    "da_sd_eulerian_nan = sd_eulerian.attribute_to_DataArray_reduction(\n",
    "    attribute_name=\"mass_left\",\n",
    "    reduction_func=ak.sum,\n",
    ")\n",
    "sd_eulerian.flatten()\n",
    "sd_eulerian.index_by_indexer(sd_eulerian[\"sdId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Superdrop Properties -----\n",
      "RHO_L = 998.203 Kg/m^3\n",
      "RHO_SOL = 2016.5 Kg/m^3\n",
      "MR_SOL = 0.05844277 Kg/mol\n",
      "IONIC = 2.0\n",
      "-------------------------------\n",
      "supers dataset path:  /home/m/m301096/CLEO/data/output_v4.0/coalbure_condensation_large/cluster_141/eurec4a1d_sol.zarr\n",
      "Attribute coord1 not found in dataset\n",
      "Attribute coord2 not found in dataset\n",
      "Attributes:\n",
      "--------------\n",
      "time (s)\n",
      "144225 * float64\n",
      "sdgbxindex ()\n",
      "144225 * uint32\n",
      "mass_represented (kg)\n",
      "144225 * float64\n",
      "sdId ()\n",
      "144225 * uint32\n",
      "\n",
      "Indexes:\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sd_conservation = supersdata.SupersDataNew(\n",
    "    dataset=zarr_path,\n",
    "    consts=consts,\n",
    ")\n",
    "# Use the SupersDataNew class to read the dataset\n",
    "sd_conservation.set_attribute(sd_conservation[\"sdId\"].attribute_to_indexer_unique())\n",
    "sd_conservation.set_attribute(sd_conservation[\"time\"].attribute_to_indexer_unique())\n",
    "\n",
    "sd_conservation.index_by_indexer(sd_conservation[\"sdId\"])\n",
    "\n",
    "inflow, outflow, dt_reservoir = create_inflow_outflow_reservoir_dataset(\n",
    "    dataset=sd_conservation,\n",
    "    dim0_name=\"time\",\n",
    "    dim1_name=\"sdgbxindex\",\n",
    "    attribute_names=(\"mass_represented\", \"sdId\"),\n",
    ")\n",
    "print(outflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes:\n",
      "--------------\n",
      "time (s)\n",
      "coord: [64, 66, 68, 70, 72, 74, ..., 3.59e+03, 3.59e+03, 3.6e+03, 3.6e+03, 3.6e+03]\n",
      "144225 * var * float64\n",
      "144225 * var * int64\n",
      "sdgbxindex ()\n",
      "coord: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ..., 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "144225 * var * uint32\n",
      "144225 * var * int64\n",
      "mass_represented (kg)\n",
      "144225 * var * float64\n",
      "sdId ()\n",
      "coord: [169, 216, 314, 352, 401, 425, ..., 1843164, 1843182, 1843190, 1843196, 1843198]\n",
      "144225 * var * uint32\n",
      "144225 * var * int64\n",
      "\n",
      "Indexes:\n",
      "--------------\n",
      "sdId\n",
      "[169, 216, 314, 352, 401, 425, ..., 1843164, 1843182, 1843190, 1843196, 1843198]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outflow.set_attribute(outflow[\"sdId\"].attribute_to_indexer_unique())\n",
    "outflow.set_attribute(outflow[\"time\"].attribute_to_indexer_unique())\n",
    "outflow.set_attribute(outflow[\"sdgbxindex\"].attribute_to_indexer_unique())\n",
    "outflow.flatten()\n",
    "outflow.index_by_indexer(outflow[\"sdId\"])\n",
    "print(outflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "firstly it seems, that the data is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "144225\n",
      "144225\n"
     ]
    }
   ],
   "source": [
    "mask = ak.num(sd_eulerian[\"sdId\"].data) > 1\n",
    "\n",
    "print(ak.sum(ak.mean(sd_eulerian[\"sdId\"].data[mask], axis=1) != ak.flatten(outflow[\"sdId\"].data)))\n",
    "print(\n",
    "    ak.sum(\n",
    "        ak.nansum(sd_eulerian[\"mass_left\"].data[mask], axis=1)\n",
    "        != ak.flatten(outflow[\"mass_represented\"].data)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    ak.sum(\n",
    "        ak.mean(sd_eulerian[\"sdgbxindex\"].data[mask], axis=1) != ak.flatten(outflow[\"sdgbxindex\"].data)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    ak.sum(\n",
    "        ak.mean(sd_eulerian[\"mass_left\"].data[mask], axis=1)\n",
    "        != ak.flatten(outflow[\"mass_represented\"].data)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdId\n",
      "sdgbxindex\n",
      "xi\n",
      "radius\n",
      "msol\n",
      "coord3\n",
      "time\n",
      "mass\n",
      "mass_represented\n",
      "mass_left\n",
      "radius_bins\n"
     ]
    }
   ],
   "source": [
    "same_sdid_attrs_list = []\n",
    "diff_sdid_attrs_list = []\n",
    "\n",
    "same_data = sd_eulerian[\"mass_left\"].data[mask]\n",
    "same_mask = ~ak.is_none(ak.nan_to_none(same_data), axis=-1)\n",
    "\n",
    "diff_data = sd_eulerian[\"mass_left\"].data[~mask]\n",
    "diff_mask = ~ak.is_none(ak.nan_to_none(diff_data), axis=-1)\n",
    "\n",
    "\n",
    "for key in sd_eulerian.attributes.keys():\n",
    "    print(key)\n",
    "    sa = sd_eulerian[key]\n",
    "    same_sdid_attrs_list.append(\n",
    "        supersdata.SupersAttribute(\n",
    "            name=key,\n",
    "            data=sa.data[mask],\n",
    "            units=sa.units,\n",
    "            metadata=sa.metadata,\n",
    "        )\n",
    "    )\n",
    "    diff_sdid_attrs_list.append(\n",
    "        supersdata.SupersAttribute(\n",
    "            name=key,\n",
    "            data=sa.data[~mask],\n",
    "            units=sa.units,\n",
    "            metadata=sa.metadata,\n",
    "        )\n",
    "    )\n",
    "\n",
    "same_sd_eulerian = supersdata.SupersDataSimple(same_sdid_attrs_list)\n",
    "diff_sd_eulerian = supersdata.SupersDataSimple(diff_sdid_attrs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_sd_eulerian.flatten()\n",
    "same_sd_eulerian.flatten()\n",
    "outflow.flatten()\n",
    "\n",
    "for sd, name in zip(\n",
    "    [diff_sd_eulerian, same_sd_eulerian, outflow],\n",
    "    [\"diff_sd_eulerian\", \"same_sd_eulerian\", \"outflow\"],\n",
    "):\n",
    "    print(name)\n",
    "    print(sd)\n",
    "    sd.set_attribute(sd[\"sdId\"].attribute_to_indexer_unique())\n",
    "    sd.set_attribute(sd[\"time\"].attribute_to_indexer_unique())\n",
    "    sd.set_attribute(sd[\"sdgbxindex\"].attribute_to_indexer_unique())\n",
    "    sd.index_by_indexer(sd[\"time\"])\n",
    "    sd.index_by_indexer(sd[\"sdgbxindex\"])\n",
    "    print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_diff_sd_eulerian = diff_sd_eulerian.attribute_to_DataArray_reduction(\n",
    "    attribute_name=\"mass_left\",\n",
    "    reduction_func=ak.nansum,\n",
    ")\n",
    "da_diff_sd_eulerian.name = \"diff\"\n",
    "da_same_sd_eulerian = same_sd_eulerian.attribute_to_DataArray_reduction(\n",
    "    attribute_name=\"mass_left\",\n",
    "    reduction_func=ak.nansum,\n",
    ")\n",
    "da_same_sd_eulerian.name = \"same\"\n",
    "da_same_sd_eulerian_nan = same_sd_eulerian.attribute_to_DataArray_reduction(\n",
    "    attribute_name=\"mass_left\",\n",
    "    reduction_func=ak.sum,\n",
    ")\n",
    "da_same_sd_eulerian_nan.name = \"same_nan\"\n",
    "da_outflow = outflow.attribute_to_DataArray_reduction(\n",
    "    attribute_name=\"mass_represented\",\n",
    "    reduction_func=ak.nansum,\n",
    ")\n",
    "da_outflow.name = \"outflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = xr.merge([da_diff_sd_eulerian, da_same_sd_eulerian, da_same_sd_eulerian_nan, da_outflow])\n",
    "\n",
    "total[\"eulerian\"] = da_sd_eulerian\n",
    "total[\"eulerian_nan\"] = da_sd_eulerian_nan\n",
    "\n",
    "total = total.fillna(0)\n",
    "total = total.swap_dims({\"sdgbxindex\": \"gridbox\"})\n",
    "total[\"time\"] = np.round(total[\"time\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.testing.assert_allclose(\n",
    "    total[\"same\"],\n",
    "    total[\"outflow\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.0, 550.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total[\"eulerian\"] - total[\"eulerian_nan\"]).sum(\"radius_bins\", skipna=False).plot()\n",
    "plt.ylim(500, 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffe2b97dac0>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (total['eulerian'].sum('radius_bins', skipna = False) - total['outflow']).sel(gridbox = 0).plot()\n",
    "# (total['same'] - total['outflow']).sel(gridbox = 0).plot()\n",
    "(total[\"eulerian\"]).sum(\"radius_bins\").sel(gridbox=0).plot()\n",
    "(total[\"outflow\"]).sel(gridbox=0).plot()\n",
    "(total[\"same\"]).sel(gridbox=0).plot()\n",
    "(total[\"eulerian_nan\"]).sum(\"radius_bins\").sel(gridbox=0).plot()\n",
    "ds[\"mass_left\"].sum(\"radius_bins\").sel(gridbox=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-ds_conservation[\"outflow\"]) == total[\"outflow\"].sum(\"gridbox\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdm_pysd_python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
